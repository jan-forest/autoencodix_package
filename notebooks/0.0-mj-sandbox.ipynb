{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODIX PACKAGE HANDBOOK\n",
    "This notebook demonstrates the usage of the autoencodix package.\n",
    "For now it serves as an internal guideline with the goal to:\n",
    "- test the package from a user perspective\n",
    "- serve as a first draft of user documentation\n",
    "- serve a developer guideline \n",
    "  - developer guide will be derrived from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Generate mock data\n",
    "We provide a variable for example data that can be imported easily. Later we show how to use your own data and what do keep in mind when doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/notebooks\n",
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(notebook_dir)\n",
    "os.chdir(notebook_dir)\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "# os.chdir(os.path.join(notebook_dir, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 General Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import DefaultConfig, DataCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --------------------------------------------\n",
    "### INITIALIZATION ### --------------------------\n",
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "van = acx.Vanillix(user_data=raw_sc, config=config)\n",
    "# ------------------------------------------------\n",
    "### DATA PROCESSING ### --------------------------\n",
    "# job of old make data\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# ------------------------------------------------\n",
    "### MODEL TRAINING ### --------------------------\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (model, losses, etc)\n",
    "van.fit()\n",
    "# ------------------------------------------------\n",
    "### PREDICTION ### -------------------------------\n",
    "# job of old make predict\n",
    "# if no data is passed, used the test split from preprocessing\n",
    "# otherwise, uses the data passed, and preprocesses it\n",
    "# updates self.result attribute with predictions (latent space, reconstructions, etc)\n",
    "van.predict()\n",
    "# ------------------------------------------------\n",
    "### EVALUATION ### -------------------------------\n",
    "# job of old make ml_task\n",
    "# populates self.result attribute with ml task results\n",
    "van.evaluate()  # not implemented yet\n",
    "# ------------------------------------------------\n",
    "### VISUALIZATION ### ---------------------------\n",
    "# job of old make visualize\n",
    "# populates self.result attribute with visualizations\n",
    "van.visualize()\n",
    "# show visualizations for notebook use\n",
    "van.show_result()\n",
    "# --------------------------\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "result = van.result\n",
    "rec = result.reconstructions.get(split=\"test\", epoch=-1)\n",
    "print(rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = van._preprocessor\n",
    "recon_package = processor.format_reconstruction(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor._dataset_container[\"test\"].data.shape\n",
    "print(recon_package.multi_sc)\n",
    "\n",
    "\n",
    "# len(processor._reverse_mapping_multi_bulk[\"test\"][\"transcriptomics\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor._datapackage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(van._preprocessor.sc_general_genes_to_keep[\"rna\"]))\n",
    "van.save(file_path=\"van.pkl\")\n",
    "van2 = acx.Vanillix.load(\"van.pkl\")\n",
    "print(len(van2._preprocessor.sc_general_genes_to_keep[\"rna\"]))\n",
    "# output: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, split_data in processor._datapackage_dict.items():\n",
    "    if split_data[\"data\"] is None:\n",
    "        print(f\"Split {split} has no data.\")\n",
    "    print(split_data[\"data\"])\n",
    "#     if split_data[\"data\"] is not None and len(split_data[\"data\"]) == n_samples:\n",
    "#         return split\n",
    "# raise ValueError(\n",
    "#     f\"Cannot find matching split for {n_samples} samples in the dataset.\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van2.result.model == van.result.model\n",
    "import torch\n",
    "\n",
    "model1_state_dict = van.result.model.state_dict()\n",
    "model2_state_dict = van2.result.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van2.result.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "recon = van.decode(latent=torch.zeros((10, 16)))\n",
    "recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.result.datasets.test.sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = van.decode(latent=van.result.adata_latent)\n",
    "print(recon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or run all steps in one command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "van = acx.Vanillix(user_data=raw_sc, config=config)\n",
    "\n",
    "result = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = result.reconstructions.get(split=\"train\", epoch=2)\n",
    "recons_val = result.reconstructions.get(split=\"valid\", epoch=2)\n",
    "recons_test = result.reconstructions.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(f\"Training reconstruction shape: {recons.shape} (samples x features)\")\n",
    "print(f\"Validation reconstruction shape: {recons_val.shape} (samples x features)\")\n",
    "print(f\"Test reconstruction shape: {recons_test.shape} (samples x features)\")\n",
    "print(\n",
    "    f\"Total reconstructed samples: {recons.shape[0] + recons_val.shape[0] + recons_test.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = result.latentspaces.get(split=\"train\", epoch=2)\n",
    "latents_val = result.latentspaces.get(split=\"valid\", epoch=2)\n",
    "latents_test = result.latentspaces.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(\n",
    "    f\"Training latent representations: {latents.shape} (n_samples={latents.shape[0]}, latent_dim={latents.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation latent representations: {latents_val.shape} (n_samples={latents_val.shape[0]}, latent_dim={latents_val.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test latent representations: {latents_test.shape} (n_samples={latents_test.shape[0]}, latent_dim={latents_test.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Total encoded samples: {latents.shape[0] + latents_val.shape[0] + latents_test.shape[0]}\"\n",
    ")\n",
    "print(f\"Latent space dimensionality: {latents.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a custom train, test, valid split\n",
    "When you pass the data to the pipeline, autoencodix, internally splits the data for you based on the train,test, valid ratios provided in the config (defaults are 70%/10%/20% train/valid/test).\n",
    "You can either pass custom ratios (see next section) or provide the indices directly as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autoencodix.utils.default_config import DataCase\n",
    "\n",
    "sample_data = np.random.rand(100, 10)\n",
    "custom_train_indices = np.arange(75)  # we won't allow overlap between splits\n",
    "custom_valid_indices = np.arange(75, 80)\n",
    "custom_test_indices = np.arange(80, 100)\n",
    "\n",
    "# the custom split needs to be a dictionary with keys \"train\", \"valid\", and \"test\" and indices of the samples to be included in each split as numpy arrays\n",
    "custom_split = {\n",
    "    \"train\": custom_train_indices,\n",
    "    \"valid\": custom_valid_indices,\n",
    "    \"test\": custom_test_indices,\n",
    "}\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = acx.Vanillix(user_data=raw_bulk, custom_splits=custom_split, config=config)\n",
    "van.preprocess()\n",
    "van.fit(epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass empty splits, but depending on how you'll use the autoencodix pipeline, this will throw an error at some point. So it is possible to call `fit` with only training data, but if you want to call `predict` and don't provide new data, this won't work without a data in the test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predict with new data\n",
    "The standard case is to train the model with the train data and then predict with the test split.\n",
    "However, it is possible to pass new data to the predict method to perform inference on this data with the already trained model.\n",
    "\n",
    "Here you have two options:\n",
    "1. Provide a fully processed dataset (similiar to `EXAMPLE_PROCESSED_DATA`) See the section `Work with you own data` for details.\n",
    "2. Provide raw data, which will be processed before predicting (also see `Work with your own data`)\n",
    "\n",
    "You pass the data with the keyword argument `data`, and depending on the datatype, the pipeline knows whether to preprocess or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume new data\n",
    "new_data = raw_bulk\n",
    "van.predict(data=new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the result of the pipeline\n",
    "Each step in the pipeline writes its results in the result object of the Vanillix instance.\n",
    "In this section we explore how to access and make sense of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = van.result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TrainingDynamics object in result\n",
    "The training dynamics object has the followinf form:\n",
    "<epoch><split><data>\n",
    "So if you want to access the train loss for the 5th epoch, you would:\n",
    "`result.lossss.get(epoch=5, split=\"train\")`\n",
    "\n",
    "##### The `.get()` Method Explained\n",
    "\n",
    "The `reconstructions.get()` method provides flexible access to reconstruction data stored during training. It can retrieve data for specific epochs, specific splits, or any combination of these parameters.\n",
    "\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "- **`epoch`** (Optional[int]): \n",
    "  - Positive integer (e.g., `2`): Get reconstructions from that specific epoch\n",
    "  - Negative integer (e.g., `-1`): Get the latest epoch (-1), second-to-last (-2), etc.\n",
    "  - `None`: Return data for all epochs\n",
    "\n",
    "- **`split`** (Optional[str]):\n",
    "  - Valid values: \"train\", \"valid\", \"test\"\n",
    "  - `None`: Return data for all splits\n",
    "\n",
    "##### Return Value Behavior:\n",
    "\n",
    "The method returns different types depending on the parameters:\n",
    "\n",
    "1. **Both `epoch` and `split` specified**:\n",
    "   - Returns a NumPy array for that specific epoch and split\n",
    "   - Example: `get(epoch=2, split=\"train\")` → `array([...])` \n",
    "\n",
    "2. **Only `epoch` specified**:\n",
    "   - Returns a dictionary of all splits for that epoch\n",
    "   - Example: `get(epoch=2)` → `{\"train\": array([...]), \"valid\": array([...]), ...}`\n",
    "\n",
    "3. **Only `split` specified**:\n",
    "   - Returns a NumPy array containing data for that split across all epochs\n",
    "   - Example: `get(split=\"train\")` → `array([[...], [...], ...])` (first dimension represents epochs)\n",
    "\n",
    "4. **Neither specified**:\n",
    "   - Returns the complete nested dictionary structure\n",
    "   - Example: `get()` → `{0: {\"train\": array([...])}, 1: {...}, ...}`\n",
    "\n",
    "##### Special Handling:\n",
    "\n",
    "- If an invalid split is provided, a `KeyError` is raised\n",
    "- Negative epoch indices work like Python list indexing (-1 is the last epoch)\n",
    "- If an epoch doesn't exist, an empty array or dictionary is returned\n",
    "\n",
    "##### Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_ep2 = result.losses.get(epoch=2, split=\"train\")\n",
    "print(loss_train_ep2)\n",
    "valid_loss = result.losses.get(split=\"valid\")\n",
    "print(valid_loss)\n",
    "print(result.losses.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    # EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "# raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this schema works for every TrainingDynamics instance in the results object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Pipeline usage with custom parameters\n",
    "Here we show how to customize the above shown pipeline with a user config or with keyword arguments.\n",
    "Alternatively, we can read the config parameters from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "van = acx.Vanillix(user_data=processed_data)\n",
    "# job of old make data\n",
    "# populates self._features attrbute with torch tensor\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (losses, etc)\n",
    "# van.fit()\n",
    "\"\"\" \n",
    "Each step can be run separately, with custom parameters, these parameters\n",
    "can be passed as keyword arguments, or as a Config object\n",
    "\"\"\"\n",
    "van.fit(learning_rate=0.01, batch_size=32, epochs=5)  # or like this:\n",
    "my_config = DefaultConfig(learning_rate=130.0, batch_size=32, epochs=5)\n",
    "van.fit(config=my_config)  # config has to be an keyword argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.1  How to relevant keyword arguments for pipeline methods\n",
    "It can be hard to know what keyword arguments are valid for each step,\n",
    "so we show:\n",
    "- how to get a list of allowed keyword arguments\n",
    "- what happens if you pass non-allowed keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# for each config method, we can call a valid_params method\n",
    "van = acx.Vanillix(user_data=processed_data)\n",
    "\n",
    "# returns a set of keyword arguments that are actually used in the fit method\n",
    "fit_params = van.fit.valid_params\n",
    "\n",
    "pprint.pprint(fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get even more verbose info about the keyword args, you can run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you want to have more info about the params, you can get type hints from the config object\n",
    "my_config = DefaultConfig()\n",
    "conig_values = my_config.get_params()\n",
    "my_config.print_schema(filter_params=fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass not supported parameters you get a warning and we fall back to default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use an unsupported keyword argument, you will get a warning\n",
    "# as you see the default value from the DefaultConfig is not overwritten and the training will take 100 epochs (not 10)\n",
    "van.preprocess()\n",
    "van.fit(epochds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2 How to get information about the default config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see what config parameters are used in the default config you can do it like:\n",
    "default_config = DefaultConfig()\n",
    "default_config.print_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02.3 Documentation Config class\n",
    "You can update the config with your own values by:\n",
    "- passing arguments as:\n",
    "    - dict\n",
    "    - single arguments\n",
    "- passing a file (sample configs and data can be found [here](https://cloud.scadsai.uni-leipzig.de/index.php/s/54aL6E6QebHDXPy))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# METHOD 1: override the default config with a dictionary\n",
    "my_args = {\"learning_rate\": 0.0234, \"batch_size\": 13, \"epochs\": 12}\n",
    "my_config = DefaultConfig(**my_args)\n",
    "# METHOD 2: override signle parameters\n",
    "my_new_conig = DefaultConfig(latent_dim=23, n_gpus=13)\n",
    "\n",
    "# METHOD 3: from a file:\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Use the Varix model\n",
    "Now we show how easy it is to use a variational autoencoder instead of a vanilla version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from autoencodix.utils.default_config import DataCase\n",
    "import autoencodix as acx\n",
    "\n",
    "my_config = DefaultConfig(learning_rate=0.001, epochs=3, checkpoint_interval=1)\n",
    "my_config.data_case = DataCase.MULTI_BULK\n",
    "van = acx.Varix(user_data=processed_data, config=my_config)\n",
    "result = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.datasets.train.feature_ids)\n",
    "print(my_config.data_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine Variational result\n",
    "Here, we have more info in our results object than in the Vanillix case. We have the learned paramters mu and logvar of the normal distirbution, in addition to the losses and reconstructions. We provide also the sampled latentspaces at each epoch and split.\n",
    "\n",
    "You can resample new latenspaces (shown in next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not train for the test split, so we don't need to pass an epoch\n",
    "# technically the epoch is -1\n",
    "mu_test_ep_last = result.latentspaces.get(split=\"test\")\n",
    "print(mu_test_ep_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different loss types\n",
    "For our variation autoencoder, the total loss consists of a reconstruction loss and a distribution loss i.e. kl-divergence. To investigate these losses, the result_obj has the attribute `sub_losses`. This is a `LossRegistry` withe the name of the loss as key and the value is of class `TrainingDynamics` and can be accessed as shown for the Vanillix part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_losses = result.sub_losses\n",
    "print(f\"keys: {sub_losses.keys()}\")\n",
    "recon_dyn = sub_losses.get(key=\"recon_loss\")\n",
    "print(recon_dyn.get(split=\"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample new latentspaces\n",
    "You might want to use the trained model and the fitted parameters mu, and logvar to sample latentspaces. Therefore, the Varix pipeline has the additional method `sample_latent_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = van.sample_latent_space()\n",
    "\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also select a specific epoch and split to sample from (default is last epoch and test split)\n",
    "sampled = van.sample_latent_space(epoch=2, split=\"valid\")\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or sample multiple times\n",
    "for _ in range(5):\n",
    "    sampled = van.sample_latent_space()\n",
    "    print(sampled[:3, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Work with your own data\n",
    "In the above steps we showed how to use `Autoencodix` with mock data. Nowe we demonstrate how to use real-world data. There are three main use cases:\n",
    "1. Use data from raw files and define the path and metainfo via the config (file or DefaultConfig class).\n",
    "2. Provide the raw data directly in Python and pass it to our `DataPackage` structure. This `DataPackage` then can be passed to to our Pipeline where it will pre preprocessed.\n",
    "3. Take care of the preprocessing yourself and pass the `DatasetContainer` to our pipeline. We show how to fill this `DatasetContainer` object with your preprocsedded data.\n",
    "\n",
    "### 04.1 Working with data from files\n",
    "Here we specialize on different kind of omics data. We cover:\n",
    "1. combining multi-omics data from bulk sequencing (e.g. mRNA and methylation).\n",
    "2. combining multi-omics data from single cell sequencing.\n",
    "3. \"Translating\" between multi-omics data e.g. scRNA <-> scATAC, or bulkmRNA <-> bulkmiRNA\n",
    "4. Working with image data\n",
    "5. \"translating\" between data-modalities\n",
    "  - one bulk-omics modality to another\n",
    "  - omics to image an vice versa\n",
    "\n",
    "#### 04.1.1 Combining mulit-omics data from bulk-sequencing\n",
    "First we need to prepare our config object. We can (a) directly provide an object in python, or (b) provide an YAML file. We show both\n",
    "\n",
    "##### YAML config\n",
    "Assume we have the file in `./config.yaml`.\n",
    "We can keep the yaml file structure to define our input data like:\n",
    "```yaml\n",
    "data_config: # has to be named data_config\n",
    "  data_info: # has to be named data_infor\n",
    "   RNA: # name can be chosen by user\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   METHYLATION: # can be chosen by user\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   CLINICAL: # can be chosen by user\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\" # default NUMERIC (as for RNA and METHYLATION)\n",
    "```\n",
    "ATTENTION:\n",
    "If you use `.txt` or `.csv` files, it is best practice to add the `sep` parameter. If none is given, the reader will try to auto-detect the separator, which is error prone.\n",
    "This would loke like:\n",
    "```YAML\n",
    "    RNA:\n",
    "      ...\n",
    "      sep: \"\\t\" # for tab, \";\" or \",\" would be also possible (as in pandas)\n",
    "\n",
    "```\n",
    "**IMPORTANT**\n",
    "\n",
    "For all your bulk data files, we expect the first column to be some kind of unique sample id. Please prepare the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# this fills the data_config attribute of the DefaultConfig object\n",
    "# we can also change the default values in the config.yaml file\n",
    "# or via the DefaultConfig object\n",
    "bulk_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text())\n",
    ")\n",
    "# this bulk_config object can then be passed to a Pipeline (Varix, Vanillix, etc)\n",
    "var_bulk = acx.Varix(config=bulk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = var_bulk.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overwrite or add values to our config from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with custom values\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create DataConfig in Python\n",
    "Instead of reading the config from the file, we can also create it directly in Ptyon\n",
    "We will only use one way of config creation for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "root_dir = os.path.join(\"data/raw\")\n",
    "meth_file = \"data_methylation_per_gene_formatted.parquet\"\n",
    "mrna_file = \"data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "clin_file = \"data_clinical_formatted.parquet\"\n",
    "\n",
    "bulk_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"RNA\": DataInfo(file_path=os.path.join(root_dir, mrna_file)),\n",
    "            \"METHYLATION\": DataInfo(file_path=os.path.join(root_dir, meth_file)),\n",
    "            \"CLINICAL\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, clin_file), data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.2 Working with single cell data from different sequencing processes\n",
    "First we define our config again, then we use the reader object to build the MuData object (this will look more familar for single cell practioners)\n",
    "\n",
    "We can provide a config yaml like:\n",
    "```yaml\n",
    "# config.yaml\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\" # we request h5ad files\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "scconfig = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/largesc.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "\n",
    "sc_van = acx.Vanillix(config=scconfig)\n",
    "\n",
    "sc_van.preprocess()\n",
    "# result = sc_van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van.fit(device=\"cpu\", epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "filepath = \"data/raw/Sc-2-mini.h5ad\"\n",
    "adata = sc.read(filepath)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van._datasets.test.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van._datasets.train.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can pass the `scconfig` to our Pipeline as shown with the bulk example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.3 Translating between omics data\n",
    "We only allow bulk to bulk and single-cell to single cell. The config is almost identical to the case before, we only add the direction of the translation like:\n",
    "```YAML\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "     translate_direction: \"FROM\"\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     translate_direction: \"TO\"\n",
    "\n",
    "```\n",
    "\n",
    "For the bulk case we can keep annotation data without including it in the translation like:\n",
    "```YAML\n",
    "# config.yaml\n",
    "data_config:\n",
    "  data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"FROM\"\n",
    "   METHYLATION:\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"TO\"\n",
    "   CLINICAL:\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\"\n",
    "     # default translate_direction is  NONE, so we don't need to specify it here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.4 Working with images\n",
    "When working with images, we need have two cases:\n",
    "- pure image, without translating\n",
    "- translating between omics and images\n",
    "\n",
    "In the first case we need to provide the folder path of the images. In the second case we need to provide the folder path of the images and an annotation file that maps the metadata for the images to the image filenames. In this file we also need to map the sample_ids of the other data modality to the image filename and metadata. Later we will add support for an unpaired case, where we only provide image metadata without mapping to the other data modality.\n",
    "The file should look like this:\n",
    "**important**: this file needs to contain the columns `sample_ids` and `img_paths`\n",
    "```text\n",
    "sample_ids\timg_paths\tMETADATA1\tMETADATA2\n",
    "TCGA-05-4244-01\t0_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4249-01\t1_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4250-01\t2_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4382-01\t3_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4384-01\t4_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4389-01\t5_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4390-01\t6_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4395-01\t7_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4396-01\t8_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image only case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(file_path=\"data/raw/images/tcga_fake\", data_type=\"IMG\"),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\", data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Images and omics data\n",
    "If you want to translate between image and another data modality you need to provide the same files as above. For the Annotation files you have two possibilities: (a) you provide one annotation file (as shown above), in this file you match the metadata of the two data modalites, by an shared sample_id / mapping of sample_id and image_path and other metadata. (b) you can have supply an extra annotation file for the images with the attribute `img_anno_file`. If None is given, we will use the shared file. This is only allowed for unpaired translation.\n",
    "So for the unpaired translation the `DataConfig` should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "\n",
    "imgreader = ImageDataReader()\n",
    "imgdata = imgreader.read_data(config=img_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgdata.keys())\n",
    "print(f\"Number of images: {len(imgdata['IMG'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unpaired case\n",
    "This case is not implemented in the old version of `autoencodix` and will be added after the other translating features, we still show how the config can look like:\n",
    "```python\n",
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake.txt\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\"\n",
    "                extra_anno_file=\"path/to/file\"\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\"\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data_clinical_formatted.parquet\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1 How to use raw data \n",
    "If you don't want to provide files via config, you can create a DataPackage directly in Python. First you need to decide what kind of data you use. We currently support the following cases:\n",
    "- Multi-Bulk (or any other numeric data)\n",
    "- Multi-SingleCell (or standard Single Cell)\n",
    "- Bulk-to-Bulk translation\n",
    "- SingleCell-to-SingleCell translation\n",
    "- Image-Bulk translation or vice versa\n",
    "- SingleCell-Image translation or vice versa\n",
    "\n",
    "With Multi-Bulk (Multi-Numeric) we mean combining different types of  sequencing data e.g. mRNA and ATAC. We define Multi-Single-Cell analogous. \n",
    "Now we show how to prepare the data in Python. While we will perform basic preprocessing like NaN removal, and scaling and filtering (if specified), we expect a certain amount of preprocessing for omics data:\n",
    "**For Bulk**:\n",
    "- TODO\n",
    "- TODO\n",
    "\n",
    "**For Single Cell**\n",
    "- TODO \n",
    "- TODO\n",
    "\n",
    "##### Multi-Bulk / Multi-Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.utils.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "\n",
    "# Create fake methylation data\n",
    "# you would normally load your data here\n",
    "meth_data = pd.DataFrame(\n",
    "    np.random.rand(100, 50),  # 100 samples, 50 features\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"Meth_Feature_{j}\" for j in range(50)],\n",
    ")\n",
    "\n",
    "# Create fake RNA data\n",
    "# you would normally load your data here\n",
    "rna_data = pd.DataFrame(\n",
    "    np.random.rand(100, 100),  # TODO align\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"RNA_Feature_{j}\" for j in range(100)],\n",
    ")\n",
    "\n",
    "# Create fake clinical annotations\n",
    "# you would normally load your data here\n",
    "clinical_annotations = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample_ID\": [f\"Sample_{i}\" for i in range(100)],\n",
    "        \"Age\": np.random.randint(20, 80, size=100),\n",
    "        \"Gender\": np.random.choice([\"Male\", \"Female\"], size=100),\n",
    "        \"Disease_Status\": np.random.choice([\"Healthy\", \"Diseased\"], size=100),\n",
    "    }\n",
    ").set_index(\"Sample_ID\")\n",
    "\n",
    "# multi_bulk is a dict with \"name/identifier\" of the dataset as key\n",
    "# the key for annotation needs to be \"paired\" if only one annotation is given, otherwise it has to have the same keys as multi_bulk\n",
    "my_data = DataPackage(\n",
    "    multi_bulk={\"RNA\": rna_data, \"METH\": meth_data},\n",
    "    annotation={\"paired\": clinical_annotations},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pass this data to our Autoencodix. \n",
    "\n",
    "**IMPORTANT**: In you config you need specify the usecase (see code) \n",
    "The preprocessing will be done according to the values in the DefaultConfig. We show how to adjust this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = Vanillix(config=config, user_data=my_data)\n",
    "# USE ONE OF THESE FOR data_case\n",
    "for case in DataCase:\n",
    "    print(case.name, case.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = van.result.datasets\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Single-Cell case\n",
    "Here you can provide one MuData object an don't need an extra annotation file, because the annotation info is stored in `obs` of the modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mudata\n",
    "\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "# IMPORTANT specify datacase\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "# Number of samples and features\n",
    "n_samples = 100\n",
    "n_rna_features = 200\n",
    "n_atac_features = 50\n",
    "\n",
    "# Create sparse matrices instead of dense arrays\n",
    "rna_X = sparse.csr_matrix(np.random.rand(n_samples, n_rna_features))\n",
    "atac_X = sparse.csr_matrix(np.random.rand(n_samples, n_atac_features))\n",
    "\n",
    "# Create observation and variable DataFrames\n",
    "obs_df = pd.DataFrame(index=[f\"Sample_{i}\" for i in range(n_samples)])\n",
    "rna_var_df = pd.DataFrame(index=[f\"Gene_{i}\" for i in range(n_rna_features)])\n",
    "atac_var_df = pd.DataFrame(index=[f\"ATAC_Feature_{i}\" for i in range(n_atac_features)])\n",
    "\n",
    "# Try creating AnnData objects with sparse matrices\n",
    "rna_adata = ad.AnnData(X=rna_X, obs=obs_df, var=rna_var_df, dtype=np.float32)\n",
    "\n",
    "atac_adata = ad.AnnData(\n",
    "    X=atac_X,\n",
    "    obs=obs_df,\n",
    "    var=atac_var_df,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "# Create MuData object\n",
    "mdata = mudata.MuData({\"RNA\": rna_adata, \"ATAC\": atac_adata})\n",
    "\n",
    "dp = DataPackage(multi_sc={\"multi_sc\": mdata})\n",
    "# Print the object\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix import Varix\n",
    "\n",
    "van = Varix(user_data=dp, config=config)\n",
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translation between modalities.\n",
    "If you want to translate between modalties i.e. mRNA to ATAC, you can populate the `from_modality` and `to_modality` attributes of the DataPackage. For the `annotation` attribute you need to add at leas one annotation file for the bulk/numeric case. Details see code:\n",
    "\n",
    "As of March 2025, we've not implemented models that support Translation in the new package, so we only show how to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.utils.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "\n",
    "dp = DataPackage()\n",
    "data_info = {\n",
    "    \"RNA\": DataInfo(translate_direction=\"from\"),\n",
    "    \"METH\": DataInfo(translate_direction=\"to\"),\n",
    "}\n",
    "config = DefaultConfig(\n",
    "    paired_translation=True,  # we want to have matched samples in this case\n",
    "    data_case=DataCase.BULK_TO_BULK,\n",
    "    data_config=DataConfig(data_info=data_info),\n",
    ")\n",
    "\n",
    "dp.from_modality = {\"from_modality\": rna_data}\n",
    "dp.to_modality = {\"to_modality\": meth_data}\n",
    "dp.annotation = {\n",
    "    \"paired\": clinical_annotations\n",
    "}  # here we can also provide {RNA: rna_anno, MEth: meth_anno} if we have two anno files\n",
    "\n",
    "van = Vanillix(user_data=dp, config=config)\n",
    "van.preprocess()\n",
    "datasets = van.result.datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with Images\n",
    "When you want to use images for our pipelines, it is the easiest to pass the folder and annotations files via config params as shown above. For some usecases, however users want to. Therefore you need create a list of ImgData objects and pass them to the DataPackage.img attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._imgdataclass import ImgData\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "import numpy as np\n",
    "\n",
    "imgdata = [ImgData(img=np.array(1), sample_id=\"myImg\", annotation=pd.DataFrame())]\n",
    "dp = DataPackage({\"IMG\": imgdata})\n",
    "# in real applications this will be a longer list of images\n",
    "# you probably also would add other data modalites to the datapackge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.3 Working with Processed data\n",
    "If you do all your processing yourself, you can just pass the torch tensor and metadata to our `DatasetContainer` data structure. The  DatasetContainer hold a dataset for each split (train, test, valid). This will skip our internal preprocessing. Here you need to know which Dataset (Pytorch Dataset child), you need for which Autoencodix. For now we only support Varix and Vanillix, which uses the class `NumericDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from autoencodix.data._datasetcontainer import DatasetContainer\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from autoencodix import Varix\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "container = DatasetContainer()\n",
    "# fill the attributes with your data\n",
    "ds = NumericDataset(\n",
    "    data=torch.tensor(1), config=DefaultConfig(), sample_ids=[], metadata=pd.DataFrame()\n",
    ")\n",
    "container.train = ds\n",
    "container.valid = ds  # your valid data\n",
    "\n",
    "# if you want to run the predict step, you need to also fill the test attribute of\n",
    "container.test = ds  # your test data\n",
    "\n",
    "# now you can just pass the container as user data\n",
    "van = Varix(user_data=container)\n",
    "# valls var.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add example (see already existing configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 How to add a new architecture\n",
    "### High level workflow\n",
    "To add a new autoencoder architecture, you need to at least code two things:\n",
    "- the model architecture itself in  `src/autoencodix/modeling/` - anlogous to `_varix_architecture.py`\n",
    "- the pipeline itself in `src/autoencodix/` - analgous to `varix.py`\n",
    "Depending on the complexity and data requirements you might also want to provide the following:\n",
    "- a new custom dataset class in `src/autoencodix/data` - analogous to `numeric_dataset.py`\n",
    "- a new custom preprocessor in `src/autoencodix/data` - as in `preprocessor.py`\n",
    "- a new custom trainer in `src/autoencodix/trainers` - as in `_general_trainer.py`\n",
    "  - including a custom predict method of your trainer\n",
    "- a custom loss for your model\n",
    "- a custom visualizer (no example implemented yet)\n",
    "- a custom evaluator for downstream tasks (no example implemented yet)\n",
    "- a custom tuner (not sure if this will be part of the package)\n",
    "### High level structure\n",
    "- Each autoencodix model in our family is based on our base classes in `src/autoencodix/base`. Here we have (often abstract) classes that define the general structure of each step (preprocess, fit, predict, evaluate, visualize) in our pipeline, as well as additional classes e.g. losses.\n",
    "- In these base classes we've implemented shared functionalities, like calling the corresponding trainer, or preprocessor.\n",
    "- The base classes also guide you to the structure of your new class. The methods of the base classes should not be changed. Rather overwrite the method in the implementation of your child class in case you need to make changes.\n",
    "\n",
    "### Must-do files details\n",
    "We'll illustrate this by an example. We want to add the new architecture with the name MySpecial to our package. First we add the actual architecture:\n",
    "- create the file `src/autoencodix/modeling/_myspecialix_architecture.py` (note files that should not be imported at end-user lever have a leading underscore).\n",
    "- for each newly created file, add the classes to the `__init__.py` in the corresponding folder. Example for the pipeline file in  `src/autoencodix`:\n",
    "```python\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "try:\n",
    "    __version__ = version(\"autoencodix\")\n",
    "except PackageNotFoundError:\n",
    "    __version__ = \"unknown\"\n",
    "\n",
    "# Import key classes to make them directly accessible\n",
    "from .vanillix import Vanillix\n",
    "from .varix import Varix\n",
    "from .stackix import Stackix\n",
    "# NEW: -------------------------------------\n",
    "from .MyNewSpecialix imiport MyNewSpecialix\n",
    "# -----------------------------------------\n",
    "\n",
    "__all__ = [\"Vanillix\", \"Varix\", \"Stackix\"] # TODO add \"MyNewSpecialx\"\n",
    "```\n",
    "\n",
    "- create the file `tests/test_modelling/test_myspecialix_architecture`\n",
    "- we write the class itself that might look like:\n",
    "```python\n",
    "from autoencodix.base._base_autoencoder import BaseAutoencoder\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "\n",
    "# needs to inherit from BaseAutoencoder\n",
    "class MySpecialArchitecture(BaseAutoencoder):\n",
    "    \"\"\"\n",
    "    MySpecial implementation accroding to (cite paper, yourself, etc)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.input_dim : int\n",
    "        number of input features\n",
    "    self.config: DefaultConfig\n",
    "        Configuration object containing model architecture parameters\n",
    "    self._encoder: nn.Module\n",
    "        Encoder network of the autoencoder\n",
    "    self._decoder: nn.Module\n",
    "        Decoder network of the autoencoder\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    my_super_special_method():\n",
    "        does cool stuff\n",
    "    _build_network()\n",
    "        Construct the encoder and decoder networks via the LayerFactory\n",
    "    encode(x: torch.Tensor) -> torch.Tensor\n",
    "        Encode the input tensor x\n",
    "    decode(x: torch.Tensor) -> torch.Tensor\n",
    "        Decode the latent tensor x\n",
    "    forward(x: torch.Tensor) -> ModelOutput\n",
    "        Forward pass of the model, fills in the reconstruction and latentspace attributes of ModelOutput class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, config: Optional[Union[None, DefaultConfig]], input_dim: int\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = DefaultConfig()\n",
    "        self._config = config\n",
    "        super().__init__(config, input_dim)\n",
    "        self.input_dim = input_dim # we always base the input dimension (usually number of features in your dataset)\n",
    "\n",
    "        # populate self.encoder and self.decoder\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Construct the encoder and decoder networks.\n",
    "        See your _layer_factory.py file that could help you here.\n",
    "        Also check other implementation to see how to use _layer_factory.py\n",
    "        \"\"\"\n",
    "        self._encoder = TODO\n",
    "        self._decoder = TODO\n",
    "\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encode the input tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Encoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        encoded = self._encoder(x)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode the latent tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Latent tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Decoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        return self._decoder(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> ModelOutput:\n",
    "        \"\"\"\n",
    "        Forward pass of the model, fill\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelOutput\n",
    "            ModelOutput object containing the reconstructed tensor and latent tensor\n",
    "\n",
    "        \"\"\"\n",
    "        latent = self.encode(x)\n",
    "        x_hat = self.decode(z)\n",
    "        # fill model output arcodding to your needs (we need reconstruction and a latentspace, see ModelOuput class for required output)\n",
    "        return ModelOutput(\n",
    "            reconstruction=x_hat,\n",
    "            latentspace=latent\n",
    "            latent_mean=None,\n",
    "            latent_logvar=None,\n",
    "            additional_info=None,\n",
    "        )\n",
    "\n",
    "```\n",
    "- adjust the `__init__.py` in `src/autoencodix/modelling` to import `MySpecialArchitecture\n",
    "- next we write tests for the newly created file in the test file\n",
    "- lastly, we need to create the pipeline file:\n",
    "  - create `src/autoencodix/myspecialix.py`\n",
    "  - create `tests/test_myspecialix.py`\n",
    "- the `myspecialix.py` might look like this\n",
    "```python\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "class MySpecialix(BasePipeline): # must inherit from BasePipeline\n",
    "    \"\"\"\n",
    "    MySpecialix specific version of the BasePipeline class.\n",
    "    Inherits preprocess, fit, predict, evaluate, and visualize methods from BasePipeline.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_data : Optional[Union[DatasetContainer, DataPackage]]\n",
    "        Input data from the user\n",
    "    config : Optional[Union[None, DefaultConfig]]\n",
    "        Configuration object containing customizations for the pipeline\n",
    "    _preprocessor_type : BasePreprocessor\n",
    "        Preprocessor object to preprocess the input data (custom for Vanillix)\n",
    "    _visualizer_type : Visualizer\n",
    "        Visualizer object to visualize the model output (custom for Vanillix)\n",
    "    _trainer_type : BaseTrainer\n",
    "        Trainer object that trains the model (custom for Vanillix)\n",
    "    _evaluator : Evaluator\n",
    "        Evaluator object that evaluates the model performance or downstream tasks (custom for Vanillix)\n",
    "    result : Result\n",
    "        Result object to store the pipeline results\n",
    "    _datasets : Optional[DatasetContainer]\n",
    "        Container for train, validation, and test datasets (preprocessed)\n",
    "    data_splitter : DataSplitter\n",
    "        DataSplitter object to split the data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[np.ndarray, AnnData, pd.DataFrame],\n",
    "        # this can be also a custom Type like MySpecialixDataset\n",
    "        dataset_type: Type[BaseDataset] = NumericDataset,\n",
    "        # This will be the Type MySpecialixArchitecture that we created before\n",
    "        model_type: Type[BaseAutoencoder] = MySpecialixArchitecture,\n",
    "        # This can be a custom Loss class, or an exisiting one see _losses.py\n",
    "        loss_type: Type[BaseLoss] = VanillixLoss,\n",
    "        preprocessor: Optional[Preprocessor] = None,\n",
    "        visualizer: Optional[BaseVisualizer] = None,\n",
    "        evaluator: Optional[Evaluator] = None,\n",
    "        result: Optional[Result] = None,\n",
    "        datasplitter_type: Type[DataSplitter] = DataSplitter,\n",
    "        custom_splits: Optional[Dict[str, np.ndarray]] = None,\n",
    "        config: Optional[DefaultConfig] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize MySpecialix pipeline with customizable components.\n",
    "\n",
    "        Some components are passed as types rather than instances because they require\n",
    "        data that is only available after preprocessing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "            Input data to be processed\n",
    "        trainer_type : Type[BaseTrainer]\n",
    "            Type of trainer to be instantiated during fit step, default is GeneralTrainer\n",
    "        dataset_type : Type[BaseDataset]\n",
    "            Type of dataset to be instantiated post-preprocessing, default is NumericDataset\n",
    "        loss_type : Type[BaseLoss], which loss to use for Vanillix, default is VanillaAutoencoderLoss\n",
    "        preprocessor : Optional[Preprocessor]\n",
    "            For data preprocessing, default creates new Preprocessor\n",
    "        visualizer : Optional[Visualizer]\n",
    "            For result visualization, default creates new Visualizer\n",
    "        evaluator : Optional[Evaluator]\n",
    "            For model evaluation, default creates new Evaluator\n",
    "        result : Optional[Result]\n",
    "            Container for pipeline results, default creates new Result\n",
    "        datasplitter_type : Type[DataSplitter], optional\n",
    "            Type of splitter to be instantiated during preprocessing, default is DataSplitter\n",
    "        custom_splits : Optional[Dict[str, np.ndarray]]\n",
    "            Custom train/valid/test split indices\n",
    "        config : Optional[DefaultConfig]\n",
    "            Configuration for all pipeline components\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            dataset_type=dataset_type,\n",
    "            trainer_type=trainer_type,\n",
    "            model_type=model_type,\n",
    "            loss_type=loss_type,\n",
    "            preprocessor=preprocessor or Preprocessor(),\n",
    "            visualizer=visualizer or Visualizer(),\n",
    "            evaluator=evaluator or Evaluator(),\n",
    "            result=result or Result(),\n",
    "            datasplitter_type=datasplitter_type,\n",
    "            config=config or DefaultConfig(),\n",
    "            custom_split=custom_splits,\n",
    "        )\n",
    "\n",
    "```\n",
    "##### More explaination to the passing of Types instead of classes:\n",
    "Most functionality of the pipeline comes from the BasePipeline. To make the methods custom to our specific architecture that we use in our `MySpecial` pipeline, we need to pass our specializes subclasses. Since we don't have all required parameters for this subclasses when calling the init method of the parent class, we pass only the type of the subclasses. These types need to be childs of the corresponding base class. Inside the BasePipeline we instantiate the specific classes with the required paramters as soon as we have them\n",
    "### Optional files details\n",
    "The optional files work from the same principle as the mandatory files, so we can always create a special class based on the baseclass and then we pass the type of our special class to our MySpecialix Pipeline e.g MySpecialTrainer n the init mehtod of MySpecialix (same as we did with MySpecialArchitecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- show how to update and work with the config object (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANDBOX \n",
    "testing Varix and losses, especially sub_losses in result_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tests after pre-postsplit refactor\n",
    "\n",
    "- same modality\n",
    "    - bulkconfig (multi_bulk):\n",
    "        - technical: works\n",
    "        - biological: TODO\n",
    "    - scconfig (multi_sc)\n",
    "        - technical: workds\n",
    "        - biological: TODO\n",
    "\n",
    "- paired:\n",
    "    - bulk-bulk:\n",
    "        -technical: workds\n",
    "        -biological: TODO\n",
    "    - sc-sc:\n",
    "        -TODO\n",
    "    - IMG-IMG:\n",
    "        -TODO\n",
    "    - BULK-IMG:\n",
    "        -TODO\n",
    "    - SC-IMG:\n",
    "        -TODO\n",
    "\n",
    "- unpaired\n",
    "    - bulk-bulk:\n",
    "        -technical: workds\n",
    "        -biological: TODO\n",
    "    - sc-sc:\n",
    "        -TODO\n",
    "    - IMG-IMG:\n",
    "        -TODO\n",
    "    - BULK-IMG:\n",
    "        -TODO\n",
    "    - SC-IMG:\n",
    "        -TODO\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### config paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stackix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "\n",
    "stackix = acx.Stackix(\n",
    "    user_data=raw_bulk,\n",
    "    config=DefaultConfig(\n",
    "        data_case=DataCase.MULTI_BULK,\n",
    "        latent_dim=16,\n",
    "        epochs=1,\n",
    "        batch_size=32,\n",
    "        learning_rate=0.001,\n",
    "    ),\n",
    ")\n",
    "stackix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_path = \"configs/largebulk.yaml\"\n",
    "scpath = \"configs/largesc.yaml\"\n",
    "tranpath = \"configs/sc_img_tran_config.yaml\"\n",
    "unpaired_path = \"configs/bulk_img_up.yaml\"\n",
    "bulk_bulk_path = \"configs/bulk_bulk_tran_config.yaml\"\n",
    "sc_sc_path = \"configs/sc_sc_tran_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_config = DefaultConfig.model_validate(yaml.safe_load(Path(bulk_path).read_text()))\n",
    "scconfig = DefaultConfig.model_validate(yaml.safe_load(Path(scpath).read_text()))\n",
    "tranconfig = DefaultConfig.model_validate(yaml.safe_load(Path(tranpath).read_text()))\n",
    "unpaired_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(unpaired_path).read_text())\n",
    ")\n",
    "bulk_bulk_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(bulk_bulk_path).read_text())\n",
    ")\n",
    "sc_sc_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(sc_sc_path).read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test multi_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van = acx.Vanillix(config=scconfig)\n",
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test sc-sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van = acx.Vanillix(config=sc_sc_config)\n",
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid confgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = os.path.join(\"configs/invalid\")\n",
    "invalid_configs = [\n",
    "    \"invalid_modalities_config.yaml\",\n",
    "    \"invalid_one_config.yaml\",\n",
    "    \"invalid_sc_bulk_config.yaml\",\n",
    "    \"invalid_three_config.yaml\",\n",
    "]\n",
    "invalid_config_objects = []\n",
    "for i, c in enumerate(invalid_configs):\n",
    "    print(c)\n",
    "    try:\n",
    "        data_info = DefaultConfig.model_validate(\n",
    "            yaml.safe_load(Path(os.path.join(base_path, c)).read_text())\n",
    "        )\n",
    "        invalid_config_objects.append(data_info)\n",
    "    except Exception as e:\n",
    "        print(invalid_configs[i])\n",
    "        print(e)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data in nanremover: multi_sc:\n",
      "  multi_sc: 1000 samples × 700 features\n",
      "multi_sc in nanremover: {'multi_sc': MuData object with n_obs × n_vars = 1000 × 700\n",
      "  2 modalities\n",
      "    rna:\t1000 x 500\n",
      "      obs:\t'cell_type', 'batch', 'donor', 'cell_cycle'\n",
      "    protein:\t1000 x 200\n",
      "      obs:\t'cell_type', 'batch', 'donor', 'cell_cycle'}\n",
      "datapacke in _split_data_package: multi_sc:\n",
      "  multi_sc: 1000 samples × 700 features\n",
      "{1000}\n",
      "in _split_data_package\n",
      "key: multi_sc, type: <class 'dict'>\n",
      "in multi_sc\n",
      "key: multi_bulk, type: <class 'NoneType'>\n",
      "key: annotation, type: <class 'NoneType'>\n",
      "key: img, type: <class 'NoneType'>\n",
      "key: from_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: from_modality\n",
      "key: to_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: to_modality\n",
      "in _split_data_package\n",
      "key: multi_sc, type: <class 'dict'>\n",
      "in multi_sc\n",
      "key: multi_bulk, type: <class 'NoneType'>\n",
      "key: annotation, type: <class 'NoneType'>\n",
      "key: img, type: <class 'NoneType'>\n",
      "key: from_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: from_modality\n",
      "key: to_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: to_modality\n",
      "in _split_data_package\n",
      "key: multi_sc, type: <class 'dict'>\n",
      "in multi_sc\n",
      "key: multi_bulk, type: <class 'NoneType'>\n",
      "key: annotation, type: <class 'NoneType'>\n",
      "key: img, type: <class 'NoneType'>\n",
      "key: from_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: from_modality\n",
      "key: to_modality, type: <class 'dict'>\n",
      "in dict case\n",
      " attribute name: to_modality\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (700, 10)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (700, 10)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (700, 10)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (700, 10)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 10)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 10)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (200, 10)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (200, 10)\n",
      "scaler: StandardScaler()\n",
      "building dataset_dict\n",
      "combine layers\n",
      "layer: X\n",
      "combine layers\n",
      "layer: X\n",
      "building dataset_dict\n",
      "combine layers\n",
      "layer: X\n",
      "combine layers\n",
      "layer: X\n",
      "building dataset_dict\n",
      "combine layers\n",
      "layer: X\n",
      "combine layers\n",
      "layer: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    }
   ],
   "source": [
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL, epochs=1)\n",
    "stackix = acx.Stackix( user_data=raw_sc, config=config)\n",
    "stackix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataInfo(file_path='', data_type='NUMERIC', scaling='STANDARD', filtering='VAR', sep=None, extra_anno_file=None, is_single_cell=False, min_cells=0.05, min_genes=0.02, selected_layers=['X'], is_X=False, normalize_counts=True, log_transform=True, k_filter=20, img_root=None, img_width_resize=None, img_height_resize=None, translate_direction=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data_config.data_info[\"multi_sc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rna', 'protein'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = stackix._datasets.train.dataset_dict.keys()\n",
    "ds\n",
    "# ds.datasets_dict[\"transcriptomics\"].data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training each modality model...\n",
      "Training modality: rna\n",
      "Training modality: rna\n",
      "cpu not relevant here\n",
      "[10, 16, 16, 16, 16]\n",
      "Epoch: 0, Loss: 35.09440732002258\n",
      "Training modality: protein\n",
      "Training modality: protein\n",
      "cpu not relevant here\n",
      "[20, 16, 16, 16, 16]\n",
      "Epoch: 0, Loss: 32.07981622219086\n",
      "finished training each modality model\n",
      "cpu not relevant here\n",
      "[32, 16, 16, 16, 16]\n",
      "Epoch: 0, Loss: 46.30750370025635\n"
     ]
    }
   ],
   "source": [
    "stackix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5701, -0.3502,  0.9715,  ...,  0.8260, -1.6661, -1.4931],\n",
       "        [ 0.7499, -0.6635,  0.6253,  ..., -2.3203,  0.0160,  0.6265],\n",
       "        [-0.5254,  1.8789,  3.3066,  ..., -1.4017,  1.1724, -0.1838],\n",
       "        ...,\n",
       "        [-1.5769,  1.2661,  0.9751,  ...,  0.6127,  2.2010, -2.5016],\n",
       "        [ 1.6128, -1.4457, -0.9560,  ...,  0.0044, -0.0482, -1.0969],\n",
       "        [-2.5398, -0.1654,  1.2427,  ..., -0.6250, -0.3186,  0.9877]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackix.sample_latent_space(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = stackix._datasets.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.result.datasets.test.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"transcriptomics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix._datasets.test.dataset_dict[\"transcriptomics\"].data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stackix._datasets.test.dataset_dict[\"transcriptomics\"].data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config.k_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stackix.result.final_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
