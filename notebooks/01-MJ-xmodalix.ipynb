{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c97c74",
   "metadata": {},
   "source": [
    "## XModalix Port First Milestone: ImageVAE + Loader\n",
    "\n",
    "\n",
    "### Outcome\n",
    "- Have a image loader and image VAE\n",
    "- Train this in a notebook\n",
    "    - With c. elegans and MNIST images\n",
    "\n",
    "\n",
    "### Checks\n",
    "- Check loss curves\n",
    "- Check image recons\n",
    "- \n",
    "\n",
    "\n",
    "### Steps\n",
    "- Prepare datasets\n",
    "    - Maybe already done in 00 notebook\n",
    "- Prepare config\n",
    "- Write ImageDataset Class\n",
    "- Write / port ImageVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1992a8",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efd521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/notebooks\n",
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autoencodix.utils.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "import autoencodix as acx\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(notebook_dir)\n",
    "os.chdir(notebook_dir)\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a5632",
   "metadata": {},
   "source": [
    "#### GLOBALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581dd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGROOT = os.path.join(\"data/images/ALY-2_SYS721/\")\n",
    "IMGMAPPING = os.path.join(\"data/ALY-2_SYS721_mappings.txt\")\n",
    "NUMFILE = os.path.join(\"data/AM3_NO2_raw_cell.tsv\")\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        epochs=50,\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=IMGROOT,\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=NUMFILE,\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"RNA2\": DataInfo(\n",
    "                file_path=NUMFILE,\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=IMGMAPPING,\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22a6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data type: IMG\n",
      "Found image type in config\n",
      "current data info: file_path='data/images/ALY-2_SYS721/' data_type='IMG' scaling='STANDARD' filtering='VAR' sep=None extra_anno_file=None is_single_cell=False min_cells=0.05 min_genes=0.02 selected_layers=['X'] is_X=False normalize_counts=True log_transform=True k_filter=20 img_root=None img_width_resize=64 img_height_resize=64 translate_direction='to'\n",
      "Checking data type: RNA\n",
      "Checking data type: RNA2\n",
      "Checking data type: ANNO\n",
      "Given image size is possible, rescaling images to: 64x64\n",
      "reading annotation file: data/ALY-2_SYS721_mappings.txt\n",
      " n_samples: {'multi_sc': {'multi_sc': 0}, 'multi_bulk': {'RNA': 260, 'RNA2': 260}, 'annotation': {'paired': 260}, 'img': {'IMG': 260}, 'from_modality': {}, 'to_modality': {}, 'paired_count': {'paired_count': 260}}\n",
      "Converting 182 images to torch.float32 tensors...\n",
      "Converting 52 images to torch.float32 tensors...\n",
      "Converting 26 images to torch.float32 tensors...\n",
      "key: train, type: <class 'dict'>\n",
      "key: valid, type: <class 'dict'>\n",
      "key: test, type: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_imgreader.py:251: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  annotation = pd.read_csv(anno_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "xmodalix = acx.XModalix(config=img_config)\n",
    "ds = xmodalix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dade5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(xmodalix.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ef6079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dbd4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['multi_bulk.RNA', 'multi_bulk.RNA2', 'img.IMG'])\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'metadata', 'sample_ids', 'sampled_index'])\n"
     ]
    }
   ],
   "source": [
    "print(batch.keys())\n",
    "print(type(batch[list(batch.keys())[0]]))\n",
    "print(batch[list(batch.keys())[0]].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde26e3e",
   "metadata": {},
   "source": [
    "### Old, maybe reuse code for getting stats, but seemd to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5566fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Simple statistics tracking - just build the dict in your training loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize stats dict once before training\u001b[39;00m\n\u001b[1;32m      4\u001b[0m stats \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modality \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrainset\u001b[49m\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      6\u001b[0m     stats[modality] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample_id \u001b[38;5;129;01min\u001b[39;00m trainset\u001b[38;5;241m.\u001b[39mdatasets[modality]\u001b[38;5;241m.\u001b[39msample_ids:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "# Simple statistics tracking - just build the dict in your training loop\n",
    "\n",
    "# Initialize stats dict once before training\n",
    "stats = {}\n",
    "for modality in trainset.datasets.keys():\n",
    "    stats[modality] = {}\n",
    "    for sample_id in trainset.datasets[modality].sample_ids:\n",
    "        stats[modality][sample_id] = 0\n",
    "print(stats)\n",
    "# Training loop\n",
    "epochs = 100\n",
    "\n",
    "# Add this to your training loop\n",
    "for epoch in range(100):  # Just test first 5 epochs\n",
    "    batch_count = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        batch_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch}: {batch_count} batches processed\")\n",
    "\n",
    "    # Also check sampler length\n",
    "    print(f\"Sampler length: {len(sampler)}\")\n",
    "    print(f\"Dataset length: {len(trainset)}\")\n",
    "    print(f\"Paired samples: {len(trainset.paired_sample_ids)}\")\n",
    "    print(f\"Unpaired samples: {len(trainset.unpaired_sample_ids)}\")\n",
    "    # # Reset stats for new epoch\n",
    "    # for modality in stats:\n",
    "    #     for sample_id in stats[modality]:\n",
    "    #         stats[modality][sample_id] = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        # Update stats with current batch\n",
    "        for modality, data in batch.items():\n",
    "            if \"sample_ids\" in data:\n",
    "                for sample_id in data[\"sample_ids\"]:\n",
    "                    if sample_id in stats[modality]:\n",
    "                        stats[modality][sample_id] += 1\n",
    "\n",
    "        # Your training code here\n",
    "        # for modality, data in batch.items():\n",
    "        #     if data[\"data\"] is not None:\n",
    "        #         outputs = models[modality](data[\"data\"])\n",
    "\n",
    "    # Print simple summary at end of epoch\n",
    "    print(\"\\nSampling Stats:\")\n",
    "    for modality in stats:\n",
    "        counts = list(stats[modality].values())\n",
    "        seen = sum(1 for c in counts if c > 0)\n",
    "        total = len(counts)\n",
    "        avg = sum(counts) / len(counts) if counts else 0\n",
    "        print(f\"  {modality}: {seen}/{total} samples seen, avg: {avg:.2f}\")\n",
    "\n",
    "    # Optional: Print unseen samples\n",
    "    print(\"\\nUnseen samples:\")\n",
    "    for modality in stats:\n",
    "        unseen = [sid for sid, count in stats[modality].items() if count == 0]\n",
    "        if unseen:\n",
    "            print(\n",
    "                f\"  {modality}: {len(unseen)} unseen - {unseen[:5]}{'...' if len(unseen) > 5 else ''}\"\n",
    "            )\n",
    "\n",
    "# Access raw stats anytime:\n",
    "# stats = {\n",
    "#     \"img.IMG\": {\"T_98\": 3, \"T_138\": 2, \"T_183\": 1, ...},\n",
    "#     \"multi_bulk.RNA\": {\"T_98\": 4, \"T_138\": 3, \"T_173\": 2, ...},\n",
    "#     ...\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
