{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac45b37d",
   "metadata": {},
   "source": [
    "- read config from file\n",
    "- define config\n",
    "- config per pipeline\n",
    "- config params\n",
    "  - in code\n",
    "  - in markdown (print_schema to chatgpt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271f9b8",
   "metadata": {},
   "source": [
    "# Config Deep Dive\n",
    "Our config class is the central point to customize our  `AUTOENCODIX` pipelines. This notebook is more a reference document than a tutorial as we mainly will list config parameters with explanations and default values and only have a few coding parts.\n",
    "\n",
    "**IMPORTANT**\n",
    "> This tutorial explains specific concepts of our config class. If you're unfamilar with general concepts,  \n",
    "> we recommend to follow the `Getting Started - Vanillix` Tutorial first.\n",
    "\n",
    "## What You'll Learn\n",
    "We'll cover the following points:\n",
    "- The two ways to provide a config:\n",
    "  - as instance of our config class\n",
    "  - as a `YAML` file\n",
    "- Which config parameters you should set\n",
    "- The two parts of our config:\n",
    "  - main config\n",
    "  - data config\n",
    "- Pipeline specific config parameters\n",
    "- Default onfig reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b65fae",
   "metadata": {},
   "source": [
    "## 1) How to Provide a Config\n",
    "The main way is to pass an instance of our `DefaultConfig` class to the pipeline object as you've seen many times in the pipeline tutorials.\n",
    "#### 1.1 Provide Config as a Class Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebce55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in handle_direct_user_data with data: <class 'autoencodix.data.datapackage.DataPackage'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:189: UserWarning: Your config is of type: <class 'autoencodix.configs.default_config.DefaultConfig'>, for this pipeline the default params of: <class 'autoencodix.configs.varix_config.VarixConfig'> work best\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.configs.default_config import DefaultConfig, DataCase\n",
    "from autoencodix.utils.example_data import EXAMPLE_MULTI_BULK\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config = DefaultConfig(\n",
    "    latent_dim=8, scaling=\"MINMAX\", data_case=DataCase.MULTI_BULK, epochs=10\n",
    ")\n",
    "varix = acx.Varix(config=config, data=EXAMPLE_MULTI_BULK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bf77e",
   "metadata": {},
   "source": [
    "#### 1.2 Provide the Config as a YAML file\n",
    "In our GitHub repo, we prepared a directory called `configs` with sample yaml files.  \n",
    "We can easily load the values into our config class with the `model_validate` method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b32c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: /Users/maximilianjoas/development/autoencodix_package\n",
      "reading parquet: data/raw/mini/bulk/clinical_sample_data.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:189: UserWarning: Your config is of type: <class 'autoencodix.configs.default_config.DefaultConfig'>, for this pipeline the default params of: <class 'autoencodix.configs.varix_config.VarixConfig'> work best\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anno key: paired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_trainer.py:126: UserWarning: increased batch_size to 33 for validset, to avoid dropping samples and having batches (makes trainingdynamics messy with missing samples per epoch) of size one (fails for Models with BachNorm)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 31.4416\n",
      "Sub-losses: recon_loss: 31.4414, var_loss: 0.0002, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 6103076175872.0000\n",
      "Sub-losses: recon_loss: 6103076175872.0000, var_loss: 66080.3906, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 355.1007\n",
      "Sub-losses: recon_loss: 31.8294, var_loss: 323.2712, anneal_factor: 0.0344, effective_beta_factor: 0.0344\n",
      "Epoch 2 - Valid Loss: 210153668608.0000\n",
      "Sub-losses: recon_loss: 210128601088.0000, var_loss: 25069478.0000, anneal_factor: 0.0344, effective_beta_factor: 0.0344\n",
      "Epoch 3 - Train Loss: 89.9097\n",
      "Sub-losses: recon_loss: 23.5348, var_loss: 66.3749, anneal_factor: 0.9656, effective_beta_factor: 0.9656\n",
      "Epoch 3 - Valid Loss: 2088455503872.0000\n",
      "Sub-losses: recon_loss: 2087284375552.0000, var_loss: 1171138688.0000, anneal_factor: 0.9656, effective_beta_factor: 0.9656\n"
     ]
    }
   ],
   "source": [
    "# first be sure to be in root\n",
    "import os\n",
    "\n",
    "p = os.getcwd()\n",
    "d = \"autoencodix_package\"\n",
    "if d not in p:\n",
    "    raise FileNotFoundError(f\"'{d}' not found in path: {p}\")\n",
    "os.chdir(os.sep.join(p.split(os.sep)[: p.split(os.sep).index(d) + 1]))\n",
    "print(f\"Changed to: {os.getcwd()}\")\n",
    "\n",
    "# now we can load the config\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")\n",
    "# and pass to a pipeline\n",
    "varix = acx.Varix(config=custom_config)\n",
    "r = varix.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6fe79",
   "metadata": {},
   "source": [
    "**Note** \n",
    "> We got a warning that our config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7cf6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved config to /Users/maximilianjoas/development/autoencodix_package/Tutorials/DeepDives/default_config.yaml\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"default_config.yaml\")\n",
    "\n",
    "# Convert to plain Python dict first\n",
    "config_dict = config.model_dump()\n",
    "# Write YAML with nice formatting\n",
    "with output_path.open(\"w\") as f:\n",
    "    yaml.dump(config_dict, f, sort_keys=False, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úÖ Saved config to {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec11183",
   "metadata": {},
   "source": [
    "\n",
    "# üß© DefaultConfig ‚Äî Configuration Parameters\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Configuration**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `data_config` | `autoencodix.configs.default_config.DataConfig` | `data_info={} require_common_cells=False annotation_columns=None` | No description available |\n",
    "| `img_path_col` | `str` | `img_paths` | When working with images, defines the column name containing image paths per sample |\n",
    "| `requires_paired` | `Optional[bool]` | *PydanticUndefined* | Indicates whether samples for xmodalix are paired (based on sample ID) |\n",
    "| `data_case` | `Optional[DataCase]` | *PydanticUndefined* | Data case for the model (auto-determined) |\n",
    "| `k_filter` | `Optional[int]` | `20` | Number of features to keep |\n",
    "| `scaling` | `Literal['STANDARD', 'MINMAX', 'ROBUST', 'MAXABS', 'NONE']` | `STANDARD` | Global scaling setting (can be overridden per modality) |\n",
    "| `skip_preprocessing` | `bool` | `False` | Skip scaling, filtering, and cleaning |\n",
    "| `class_param` | `Optional[str]` | `None` | No description available |\n",
    "\n",
    "---\n",
    "\n",
    "## **Model Architecture**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `latent_dim` | `int` | `16` | Dimension of the latent space |\n",
    "| `n_layers` | `int` | `3` | Number of encoder/decoder layers (excluding latent layer) |\n",
    "| `enc_factor` | `int` | `4` | Encoder dimension scaling factor |\n",
    "| `input_dim` | `int` | `10000` | Input feature dimension |\n",
    "| `drop_p` | `float` | `0.1` | Dropout probability |\n",
    "| `save_memory` | `bool` | `False` | Skip storing `TrainingDynamics` to save memory |\n",
    "\n",
    "---\n",
    "\n",
    "## **Training Hyperparameters**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `learning_rate` | `float` | `0.001` | Learning rate for optimization |\n",
    "| `batch_size` | `int` | `32` | Samples per batch (>1 required due to BatchNorm) |\n",
    "| `epochs` | `int` | `3` | Number of training epochs |\n",
    "| `weight_decay` | `float` | `0.01` | L2 regularization factor |\n",
    "| `reconstruction_loss` | `Literal['mse', 'bce']` | `mse` | Type of reconstruction loss |\n",
    "| `default_vae_loss` | `Literal['kl', 'mmd']` | `kl` | Type of VAE loss |\n",
    "| `loss_reduction` | `Literal['sum', 'mean']` | `sum` | Loss reduction mode in PyTorch |\n",
    "| `beta` | `float` | `1` | Œ≤ weight for VAE loss |\n",
    "| `beta_mi` | `float` | `1` | Œ≤ weight for mutual information term |\n",
    "| `beta_tc` | `float` | `1` | Œ≤ weight for total correlation term |\n",
    "| `beta_dimKL` | `float` | `1` | Œ≤ weight for dimension-wise KL |\n",
    "| `use_mss` | `bool` | `True` | Use minibatch stratified sampling for disentangled VAE loss |\n",
    "| `gamma` | `float` | `10.0` | Œ≥ weight for adversarial loss (XModalix classifier) |\n",
    "| `delta_pair` | `float` | `5.0` | Œ¥ weight for paired loss (XModalix training) |\n",
    "| `delta_class` | `float` | `5.0` | Œ¥ weight for class loss (XModalix training) |\n",
    "| `anneal_function` | `Literal['5phase-constant', '3phase-linear', '3phase-log', 'logistic-mid', 'logistic-early', 'logistic-late', 'no-annealing']` | `logistic-mid` | Annealing function strategy for VAE loss |\n",
    "| `pretrain_epochs` | `int` | `0` | Pretraining epochs (can differ per modality) |\n",
    "\n",
    "---\n",
    "\n",
    "## **Device & Performance**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `device` | `Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']` | `auto` | Compute device |\n",
    "| `n_gpus` | `int` | `1` | Number of GPUs to use |\n",
    "| `n_workers` | `int` | `0` | Data loader workers |\n",
    "| `checkpoint_interval` | `int` | `10` | Checkpoint save interval |\n",
    "| `float_precision` | `Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16']` | `32` | Floating-point precision |\n",
    "| `gpu_strategy` | `Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']` | `auto` | GPU parallelization strategy |\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Splits & Reproducibility**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `train_ratio` | `float` | `0.7` | Training split ratio |\n",
    "| `test_ratio` | `float` | `0.2` | Test split ratio |\n",
    "| `valid_ratio` | `float` | `0.1` | Validation split ratio |\n",
    "| `min_samples_per_split` | `int` | `1` | Minimum samples per split |\n",
    "| `reproducible` | `bool` | `False` | Ensure reproducibility |\n",
    "| `global_seed` | `int` | `1` | Global random seed |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f4512",
   "metadata": {},
   "source": [
    "# üß¨ DataConfig ‚Äî Configuration Parameters\n",
    "\n",
    "---\n",
    "\n",
    "## **DataConfig**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `data_info` | `Dict[str, DataInfo]` | *Required* | Dictionary mapping modality names (e.g. `\"RNA\"`, `\"IMG\"`) to their `DataInfo` configuration |\n",
    "| `require_common_cells` | `Optional[bool]` | `False` | Whether to require that all data modalities share a common set of cells/samples |\n",
    "| `annotation_columns` | `Optional[List[str]]` | `None` | List of column names from the annotation file to include as metadata |\n",
    "\n",
    "---\n",
    "\n",
    "## **DataInfo**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `file_path` | `str` | `\"\"` | Path to the raw data file |\n",
    "| `data_type` | `Literal['NUMERIC', 'CATEGORICAL', 'IMG', 'ANNOTATION']` | `NUMERIC` | Type of data modality |\n",
    "| `scaling` | `Literal['STANDARD', 'MINMAX', 'ROBUST', 'MAXABS', 'NONE', 'NOTSET']` | `NOTSET` | Overrides the globally set scaling method for this modality |\n",
    "| `filtering` | `Literal['VAR', 'MAD', 'CORR', 'VARCORR', 'NOFILT', 'NONZEROVAR']` | `VAR` | Feature filtering method |\n",
    "| `sep` | `Optional[str]` | `None` | Delimiter for CSV/TSV input files (passed to `pandas.read_csv`) |\n",
    "| `extra_anno_file` | `Optional[str]` | `None` | Path to an additional annotation file |\n",
    "\n",
    "---\n",
    "\n",
    "## **Single-Cell Specific Parameters**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `is_single_cell` | `bool` | `False` | Whether the dataset represents single-cell data |\n",
    "| `min_cells` | `float` | `0.05` | Minimum fraction of cells in which a gene must be expressed to be kept (filters rare genes) |\n",
    "| `min_genes` | `float` | `0.02` | Minimum fraction of genes a cell must express to be kept (filters low-quality cells) |\n",
    "| `selected_layers` | `List[str]` | `['X']` | Layers to include from the single-cell dataset; must always include `\"X\"` |\n",
    "| `is_X` | `bool` | `False` | Whether the data originates from the `\"X\"` matrix only |\n",
    "| `normalize_counts` | `bool` | `True` | Whether to normalize single-cell counts by total expression per cell |\n",
    "| `log_transform` | `bool` | `True` | Whether to apply `log1p` transformation after normalization |\n",
    "| `k_filter` | `Optional[int]` | `20` | Automatically set based on global config; do not override manually |\n",
    "\n",
    "---\n",
    "\n",
    "## **Image-Specific Parameters**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `img_width_resize` | `Optional[int]` | `64` | Target width for image resizing (must equal height) |\n",
    "| `img_height_resize` | `Optional[int]` | `64` | Target height for image resizing (must equal width) |\n",
    "\n",
    "---\n",
    "\n",
    "## **XModalix & Translation Parameters**\n",
    "\n",
    "| **Parameter** | **Type** | **Default** | **Description** |\n",
    "|----------------|-----------|--------------|-----------------|\n",
    "| `translate_direction` | `Optional[Literal['from', 'to']]` | `None` | Defines translation direction in cross-modal (XModalix) training |\n",
    "| `pretrain_epochs` | `int` | `0` | Number of pretraining epochs specific to this modality (overrides global pretraining setting) |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è **Validation Rules**\n",
    "\n",
    "- `selected_layers` must always contain `\"X\"`.  \n",
    "- `img_width_resize` and `img_height_resize` must be **positive integers** and **equal** (enforces square resizing).  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencodix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
