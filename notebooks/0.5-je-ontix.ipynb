{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewald/Github/autoencodix_package/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import DefaultConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ont_lvl1 = dict()\n",
    "ont_lvl2 = dict()\n",
    "\n",
    "ont_lvl1[\"pwy-1\"] = [\"sub-pwy-1\", \"sub-pwy-2\"]\n",
    "ont_lvl1[\"pwy-2\"] = [\"sub-pwy-3\", \"sub-pwy-2\"]\n",
    "# first third of feature ids in processed_data.train.feature_ids\n",
    "ont_lvl2[\"sub-pwy-1\"] = processed_data.train.feature_ids[: int(len(processed_data.train.feature_ids) / 3)]\n",
    "# second third of feature ids in processed_data.train.feature_ids\n",
    "ont_lvl2[\"sub-pwy-2\"] = processed_data.train.feature_ids[\n",
    "\tint(len(processed_data.train.feature_ids) / 3) : int(2 * len(processed_data.train.feature_ids) / 3)\n",
    "]\n",
    "# last third of feature ids in processed_data.train.feature_ids\n",
    "ont_lvl2[\"sub-pwy-3\"] = processed_data.train.feature_ids[\n",
    "\tint(2 * len(processed_data.train.feature_ids) / 3) : int(len(processed_data.train.feature_ids))\n",
    "]\n",
    "\n",
    "# ont_lvl2[\"sub-pwy-1\"] = [\"gene-1\", \"gene-2\"]\n",
    "# ont_lvl2[\"sub-pwy-2\"] = [\"gene-3\", \"gene-4\"]\n",
    "# ont_lvl2[\"sub-pwy-3\"] = [\"gene-2\", \"gene-6\"]\n",
    "\n",
    "ontology_tuple = ( ont_lvl1, ont_lvl2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varix = acx.Varix(config=DefaultConfig(), user_data=processed_data)\n",
    "# varix.preprocess()\n",
    "# varix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varix.preprocessed_data.train.feature_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontix = acx.Ontix(ontologies=ontology_tuple, config=DefaultConfig(), user_data=processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ont_lvl1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pwy-1': ['sub-pwy-1', 'sub-pwy-2'], 'pwy-2': ['sub-pwy-3', 'sub-pwy-2']},\n",
       " {'sub-pwy-1': ['feature_0',\n",
       "   'feature_1',\n",
       "   'feature_2',\n",
       "   'feature_3',\n",
       "   'feature_4',\n",
       "   'feature_5',\n",
       "   'feature_6',\n",
       "   'feature_7',\n",
       "   'feature_8',\n",
       "   'feature_9'],\n",
       "  'sub-pwy-2': ['feature_10',\n",
       "   'feature_11',\n",
       "   'feature_12',\n",
       "   'feature_13',\n",
       "   'feature_14',\n",
       "   'feature_15',\n",
       "   'feature_16',\n",
       "   'feature_17',\n",
       "   'feature_18',\n",
       "   'feature_19'],\n",
       "  'sub-pwy-3': ['feature_20',\n",
       "   'feature_21',\n",
       "   'feature_22',\n",
       "   'feature_23',\n",
       "   'feature_24',\n",
       "   'feature_25',\n",
       "   'feature_26',\n",
       "   'feature_27',\n",
       "   'feature_28',\n",
       "   'feature_29']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontix.result.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "Mask layer 0 with shape torch.Size([3, 2]) and 4.0 connections\n",
      "Mask layer 1 with shape torch.Size([30, 3]) and 30.0 connections\n",
      "Latent Dim: 2\n",
      "[30, 7, 2, 2, 2]\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=3, out_features=30, bias=True)\n",
      ")\n",
      "torch.Size([32, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43montix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/autoencodix_package/src/autoencodix/utils/_utils.py:128\u001b[0m, in \u001b[0;36mconfig_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter must be of type DefaultConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m     config \u001b[38;5;241m=\u001b[39m user_config\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/autoencodix_package/src/autoencodix/base/_base_pipeline.py:370\u001b[0m, in \u001b[0;36mBasePipeline.fit\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m     ontologies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_type(\n\u001b[1;32m    362\u001b[0m     trainset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[1;32m    363\u001b[0m     validset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mvalid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     ontologies\u001b[38;5;241m=\u001b[39montologies, \u001b[38;5;66;03m# Ontix\u001b[39;00m\n\u001b[1;32m    369\u001b[0m )\n\u001b[0;32m--> 370\u001b[0m trainer_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mupdate(trainer_result)\n",
      "File \u001b[0;32m~/Github/autoencodix_package/src/autoencodix/trainers/_general_trainer.py:95\u001b[0m, in \u001b[0;36mGeneralTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmasks):\n\u001b[0;32m---> 95\u001b[0m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m### ------------------------------------ ###\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "ontix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of ontix:\n",
      "_abc_impl\n",
      "_data_splitter\n",
      "_dataset_type\n",
      "_datasets\n",
      "_evaluator\n",
      "_fill_data_info\n",
      "_loss_type\n",
      "_model_type\n",
      "_preprocessor\n",
      "_preprocessor_type\n",
      "_trainer_type\n",
      "_validate_config_data\n",
      "_validate_container\n",
      "_validate_raw_user_data\n",
      "_validate_user_data\n",
      "_visualizer\n",
      "config\n",
      "evaluate\n",
      "fit\n",
      "ontologies\n",
      "predict\n",
      "preprocess\n",
      "preprocessed_data\n",
      "raw_user_data\n",
      "result\n",
      "run\n",
      "sample_latent_space\n",
      "show_result\n",
      "visualize\n"
     ]
    }
   ],
   "source": [
    "# Print all available attributes of ontix\n",
    "print(\"Attributes of ontix:\")\n",
    "for attr in dir(ontix):\n",
    "\tif not attr.startswith(\"__\"):\n",
    "\t\tprint(attr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
