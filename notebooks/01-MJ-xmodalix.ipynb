{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c97c74",
   "metadata": {},
   "source": [
    "## XModalix Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1992a8",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b466fc88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DefaultConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultConfig\u001b[49m()\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m XModalixConfig()\n\u001b[1;32m      3\u001b[0m xmodalix_c \u001b[38;5;241m=\u001b[39m XModalixConfig()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DefaultConfig' is not defined"
     ]
    }
   ],
   "source": [
    "config = DefaultConfig()\n",
    "config = XModalixConfig()\n",
    "xmodalix_c = XModalixConfig()\n",
    "isinstance(config, type(xmodalix_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efd521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/notebooks\n",
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autoencodix.configs.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "from autoencodix.configs.xmodalix_config import XModalixConfig\n",
    "import autoencodix as acx\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(notebook_dir)\n",
    "os.chdir(notebook_dir)\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a5632",
   "metadata": {},
   "source": [
    "#### GLOBALS\n",
    "**ATTENTION**\n",
    "Be sure to have the appropriate files, or adjust paths and make your own config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581dd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGROOT = os.path.join(\"data/images/ALY-2_SYS721/\")\n",
    "IMGMAPPING = os.path.join(\"data/ALY-2_SYS721_mappings.txt\")\n",
    "NUMFILE = os.path.join(\"data/AM3_NO2_raw_cell.tsv\")\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    checkpoint_interval=25,\n",
    "\tloss_reduction = \"sum\",\n",
    "    class_param=\"early\",\n",
    "    epochs=5,\n",
    "\tbeta = 0.01,\n",
    "\tgamma= 2,\n",
    "\tdelta_class= 0.0,\n",
    "\tdelta_pair = 3,\n",
    "\tlearning_rate=0.001,\n",
    "\tk_filter=1000,\n",
    "\tlatent_dim=8,\n",
    "    batch_size=32,\n",
    "    # blablabla=\"\",\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=IMGROOT,\n",
    "                data_type=\"IMG\",\n",
    "\t\t\t\tscaling=\"MINMAX\",\n",
    "                translate_direction=\"to\",\n",
    "                pretrain_epochs=30\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=NUMFILE,\n",
    "                data_type=\"NUMERIC\",\n",
    "\t\t\t\tscaling = \"MINMAX\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"RNA2\": DataInfo(\n",
    "                file_path=NUMFILE,\n",
    "                data_type=\"NUMERIC\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=IMGMAPPING,\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e694c6e",
   "metadata": {},
   "source": [
    "### Run Xmodalix with defined config\n",
    "- .run() does not work yet, because we dont have a visualizer, so we run it step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30749e8e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:175: UserWarning: Your config is of type: <class 'autoencodix.configs.default_config.DefaultConfig'>, for this pipeline the default params of: <class 'autoencodix.configs.xmodalix_config.XModalixConfig'> work best\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_imgreader.py:251: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  annotation = pd.read_csv(anno_file, sep=sep)\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/data/_filter.py:96: UserWarning: WARNING: k is None or greater than number of columns, keeping all features.\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/data/_filter.py:96: UserWarning: WARNING: k is None or greater than number of columns, keeping all features.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "Checking data type: IMG\n",
      "Found image type in config\n",
      "current data info: file_path='data/images/ALY-2_SYS721/' data_type='IMG' scaling='MINMAX' filtering='VAR' sep=None extra_anno_file=None is_single_cell=False min_cells=0.05 min_genes=0.02 selected_layers=['X'] is_X=False normalize_counts=True log_transform=True k_filter=20 img_root=None img_width_resize=64 img_height_resize=64 translate_direction='to' pretrain_epochs=30\n",
      "Checking data type: RNA\n",
      "Checking data type: RNA2\n",
      "Checking data type: ANNO\n",
      "Given image size is possible, rescaling images to: 64x64\n",
      "reading annotation file: data/ALY-2_SYS721_mappings.txt\n",
      "Successfully loaded 260 images for IMG\n",
      " n_samples: {'multi_sc': {'multi_sc': 0}, 'multi_bulk': {'RNA': 260, 'RNA2': 260}, 'annotation': {'paired': 260, 'IMG': 260}, 'img': {'IMG': 260}, 'from_modality': {}, 'to_modality': {}, 'paired_count': {'paired_count': 260}}\n",
      "Converting 182 images to torch.float32 tensors...\n",
      "Converting 52 images to torch.float32 tensors...\n",
      "Converting 26 images to torch.float32 tensors...\n",
      "key: train, type: <class 'dict'>\n",
      "key: valid, type: <class 'dict'>\n",
      "key: test, type: <class 'dict'>\n",
      "Check if we need to pretrain: multi_bulk.RNA\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.RNA\n",
      "Check if we need to pretrain: multi_bulk.RNA2\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.RNA2\n",
      "Check if we need to pretrain: img.IMG\n",
      "pretrain epochs : 30\n",
      "Starting Pretraining for: img.IMG with <class 'autoencodix.trainers._general_trainer.GeneralTrainer'>\n",
      "Epoch 1 - Train Loss: 87380.1709\n",
      "Sub-losses: recon_loss: 85946.4482, var_loss: 3158125554.8366, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 12775.2471\n",
      "Sub-losses: recon_loss: 12775.2471, var_loss: 8.8378, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 101159.3560\n",
      "Sub-losses: recon_loss: 63065.9854, var_loss: 1540605518.8144, anneal_factor: 0.0025, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 10232.1875\n",
      "Sub-losses: recon_loss: 10232.1865, var_loss: 26.1285, anneal_factor: 0.0025, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 44435.3730\n",
      "Sub-losses: recon_loss: 44426.4663, var_loss: 7471.7927, anneal_factor: 0.1192, effective_beta_factor: 0.0012\n",
      "Epoch 3 - Valid Loss: 6890.8892\n",
      "Sub-losses: recon_loss: 6890.8604, var_loss: 24.0438, anneal_factor: 0.1192, effective_beta_factor: 0.0012\n",
      "Epoch 4 - Train Loss: 32486.0234\n",
      "Sub-losses: recon_loss: 32398.8042, var_loss: 9902.3322, anneal_factor: 0.8808, effective_beta_factor: 0.0088\n",
      "Epoch 4 - Valid Loss: 4636.2515\n",
      "Sub-losses: recon_loss: 4636.0737, var_loss: 20.1806, anneal_factor: 0.8808, effective_beta_factor: 0.0088\n",
      "Epoch 5 - Train Loss: 24865.1953\n",
      "Sub-losses: recon_loss: 24744.6230, var_loss: 12087.1450, anneal_factor: 0.9975, effective_beta_factor: 0.0100\n",
      "Epoch 5 - Valid Loss: 3730.5127\n",
      "Sub-losses: recon_loss: 3730.1987, var_loss: 31.4757, anneal_factor: 0.9975, effective_beta_factor: 0.0100\n",
      "Epoch 6 - Train Loss: 18984.1132\n",
      "Sub-losses: recon_loss: 18845.0715, var_loss: 13904.7759, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 6 - Valid Loss: 3305.8828\n",
      "Sub-losses: recon_loss: 3304.9758, var_loss: 90.6972, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 7 - Train Loss: 14635.6937\n",
      "Sub-losses: recon_loss: 14492.4718, var_loss: 14322.1987, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 7 - Valid Loss: 3080.5789\n",
      "Sub-losses: recon_loss: 3078.5188, var_loss: 206.0076, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 8 - Train Loss: 11547.7579\n",
      "Sub-losses: recon_loss: 11408.3593, var_loss: 13939.8799, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 8 - Valid Loss: 2953.3018\n",
      "Sub-losses: recon_loss: 2949.6819, var_loss: 361.9768, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 9 - Train Loss: 9161.6658\n",
      "Sub-losses: recon_loss: 9025.5704, var_loss: 13609.5419, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 9 - Valid Loss: 2844.0466\n",
      "Sub-losses: recon_loss: 2838.6812, var_loss: 536.5428, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 10 - Train Loss: 7433.0639\n",
      "Sub-losses: recon_loss: 7302.5724, var_loss: 13049.1429, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 10 - Valid Loss: 2741.4043\n",
      "Sub-losses: recon_loss: 2734.3833, var_loss: 702.0883, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 11 - Train Loss: 6354.9498\n",
      "Sub-losses: recon_loss: 6229.5735, var_loss: 12537.6331, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 11 - Valid Loss: 2637.7363\n",
      "Sub-losses: recon_loss: 2629.1724, var_loss: 856.3933, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 12 - Train Loss: 5477.0369\n",
      "Sub-losses: recon_loss: 5353.8520, var_loss: 12318.4993, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 12 - Valid Loss: 2431.4663\n",
      "Sub-losses: recon_loss: 2421.5107, var_loss: 995.5610, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 13 - Train Loss: 4788.9567\n",
      "Sub-losses: recon_loss: 4667.8781, var_loss: 12107.8654, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 13 - Valid Loss: 2165.2639\n",
      "Sub-losses: recon_loss: 2154.3652, var_loss: 1089.8562, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 14 - Train Loss: 4248.0107\n",
      "Sub-losses: recon_loss: 4128.0832, var_loss: 11992.7397, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 14 - Valid Loss: 1848.0800\n",
      "Sub-losses: recon_loss: 1836.5352, var_loss: 1154.4835, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 15 - Train Loss: 3878.8237\n",
      "Sub-losses: recon_loss: 3760.4869, var_loss: 11833.6849, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 15 - Valid Loss: 1315.3219\n",
      "Sub-losses: recon_loss: 1303.3680, var_loss: 1195.3816, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 16 - Train Loss: 3644.8923\n",
      "Sub-losses: recon_loss: 3527.8995, var_loss: 11699.2795, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 16 - Valid Loss: 944.7650\n",
      "Sub-losses: recon_loss: 932.6890, var_loss: 1207.6025, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 17 - Train Loss: 3581.2748\n",
      "Sub-losses: recon_loss: 3463.3673, var_loss: 11790.7556, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 17 - Valid Loss: 733.0197\n",
      "Sub-losses: recon_loss: 720.7100, var_loss: 1230.9709, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 18 - Train Loss: 3433.8466\n",
      "Sub-losses: recon_loss: 3315.9317, var_loss: 11791.4924, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 18 - Valid Loss: 543.3792\n",
      "Sub-losses: recon_loss: 531.0452, var_loss: 1233.4020, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 19 - Train Loss: 3287.3076\n",
      "Sub-losses: recon_loss: 3169.4883, var_loss: 11781.9255, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 19 - Valid Loss: 543.3677\n",
      "Sub-losses: recon_loss: 531.2030, var_loss: 1216.4644, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 20 - Train Loss: 3090.4440\n",
      "Sub-losses: recon_loss: 2973.4396, var_loss: 11700.4410, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 20 - Valid Loss: 470.2634\n",
      "Sub-losses: recon_loss: 458.2514, var_loss: 1201.2001, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 21 - Train Loss: 3100.1545\n",
      "Sub-losses: recon_loss: 2983.5522, var_loss: 11660.2308, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 21 - Valid Loss: 466.7065\n",
      "Sub-losses: recon_loss: 454.7653, var_loss: 1194.1185, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 22 - Train Loss: 2939.6694\n",
      "Sub-losses: recon_loss: 2823.9197, var_loss: 11574.9696, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 22 - Valid Loss: 462.1249\n",
      "Sub-losses: recon_loss: 450.4268, var_loss: 1169.8070, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 23 - Train Loss: 3084.3141\n",
      "Sub-losses: recon_loss: 2969.2240, var_loss: 11509.0090, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 23 - Valid Loss: 456.9805\n",
      "Sub-losses: recon_loss: 445.5555, var_loss: 1142.4933, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 24 - Train Loss: 2924.2489\n",
      "Sub-losses: recon_loss: 2810.2042, var_loss: 11404.4690, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 24 - Valid Loss: 442.9265\n",
      "Sub-losses: recon_loss: 431.7719, var_loss: 1115.4573, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 25 - Train Loss: 2857.1440\n",
      "Sub-losses: recon_loss: 2744.8410, var_loss: 11230.3016, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 25 - Valid Loss: 437.8522\n",
      "Sub-losses: recon_loss: 426.9775, var_loss: 1087.4722, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 26 - Train Loss: 2838.0822\n",
      "Sub-losses: recon_loss: 2727.9276, var_loss: 11015.4634, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 26 - Valid Loss: 439.5024\n",
      "Sub-losses: recon_loss: 428.8657, var_loss: 1063.6788, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 27 - Train Loss: 3010.3391\n",
      "Sub-losses: recon_loss: 2900.8848, var_loss: 10945.4342, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 27 - Valid Loss: 428.7980\n",
      "Sub-losses: recon_loss: 417.8584, var_loss: 1093.9623, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 28 - Train Loss: 2779.8015\n",
      "Sub-losses: recon_loss: 2667.7578, var_loss: 11204.3726, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 28 - Valid Loss: 436.3705\n",
      "Sub-losses: recon_loss: 425.3303, var_loss: 1104.0168, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 29 - Train Loss: 2797.8780\n",
      "Sub-losses: recon_loss: 2684.8571, var_loss: 11302.0844, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 29 - Valid Loss: 412.0294\n",
      "Sub-losses: recon_loss: 401.1675, var_loss: 1086.1964, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 30 - Train Loss: 2689.8177\n",
      "Sub-losses: recon_loss: 2575.8591, var_loss: 11395.8556, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "Epoch 30 - Valid Loss: 421.8903\n",
      "Sub-losses: recon_loss: 410.9971, var_loss: 1089.3185, anneal_factor: 1.0000, effective_beta_factor: 0.0100\n",
      "--- Epoch 1/5 ---\n",
      "split: train, n_samples: 1341\n",
      "Epoch 1/5 - Train Loss: 54.0808\n",
      "split: valid, n_samples: 132\n",
      "Epoch 1/5 - Valid Loss: 48.5224\n",
      "--- Epoch 2/5 ---\n",
      "split: train, n_samples: 1352\n",
      "Epoch 2/5 - Train Loss: 49.0896\n",
      "split: valid, n_samples: 135\n",
      "Epoch 2/5 - Valid Loss: 46.0033\n",
      "--- Epoch 3/5 ---\n",
      "split: train, n_samples: 1340\n",
      "Epoch 3/5 - Train Loss: 47.0699\n",
      "split: valid, n_samples: 130\n",
      "Epoch 3/5 - Valid Loss: 44.2705\n",
      "--- Epoch 4/5 ---\n",
      "split: train, n_samples: 1312\n",
      "Epoch 4/5 - Train Loss: 44.0845\n",
      "split: valid, n_samples: 131\n",
      "Epoch 4/5 - Valid Loss: 48.1625\n",
      "--- Epoch 5/5 ---\n",
      "split: train, n_samples: 1303\n",
      "Epoch 5/5 - Train Loss: 42.9745\n",
      "split: valid, n_samples: 130\n",
      "Epoch 5/5 - Valid Loss: 42.7207\n",
      "Storing checkpoint for epoch 4...\n",
      "Prediction complete.\n",
      "Processing latent space results into a single AnnData object...\n",
      "Identified source modality for latent space: 'multi_bulk.RNA'\n",
      "  - Added 279 source feature IDs to .uns\n",
      "Finished processing latent results.\n"
     ]
    }
   ],
   "source": [
    "xmodalix = acx.XModalix(config=img_config)\n",
    "xmodalix.preprocess()\n",
    "xmodalix.fit()\n",
    "result = xmodalix.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6de6b",
   "metadata": {},
   "source": [
    "### Loading and Saving XModalix\n",
    "- works like for other pipelines too, can be used to run another predict pairing also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16994eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodalix.save(\"xmodalix.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodalix = acx.XModalix.load(\"xmodalix.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eca5c",
   "metadata": {},
   "source": [
    "### Inspect X-Modalix Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10592499",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = xmodalix.result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad3c2a",
   "metadata": {},
   "source": [
    "Trainingdynamics in result are a dict with keys for each datamodality, the get interface works like for the other pipelines.\n",
    "We have the special keys:\n",
    "- translation which is the actual translated reconstruction or the from_latent space for the latentspace dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.reconstructions.get(epoch=-1, split=\"test\").keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2cb7c7",
   "metadata": {},
   "source": [
    "We have latentspaces for the test set for each modality, not only for the translation pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f943c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.latentspaces.get(epoch=-1, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828780f",
   "metadata": {},
   "source": [
    "We also provide the andata interface for the translate latentspace (from_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.adata_latent.obs_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7dd642",
   "metadata": {},
   "source": [
    "And we also support the final_reconstruction attribute that returns the same datastructure as the input data, but switches the actual data with the translated reconstruction (for the translted modality, the rest is the same as the input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cc208",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rec = r.final_reconstruction.datasets[\"img.IMG\"]\n",
    "inputimg = xmodalix.result.datasets.test.datasets[\"img.IMG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27a8bf",
   "metadata": {},
   "source": [
    "## Vis 2D aligned latent development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from old autoecodix framework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_translate_latent(\n",
    "    # cfg, -> removed\n",
    "    embedding,\n",
    "    color_param,\n",
    "    style_param=None,\n",
    "    save_fig=\"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a 2D visualization of the 2D embedding of the latent space.\n",
    "    ARGS:\n",
    "        cfg (dict): config dictionary\n",
    "        embedding (pd.DataFrame): embedding on which is visualized. Assumes prior 2D dimension reduction.\n",
    "        color_param (str): Clinical parameter to color scatter plot\n",
    "        style_param (str): Parameter e.g. \"Translate\" to facet scatter plot\n",
    "        save_fig (str): File path for saving the plot. Use appropriate file\n",
    "                        endings to specify image type (e.g. '*.png')\n",
    "    RETURNS:\n",
    "        fig (seaborn.FacetGrid): Figure handle\n",
    "\n",
    "    \"\"\"\n",
    "    labels = embedding[color_param]\n",
    "    # logger = getlogger(cfg)\n",
    "    numeric = False\n",
    "    if not (type(labels[0]) is str):\n",
    "        if len(np.unique(labels)) > 3:\n",
    "            # if not cfg[\"PLOT_NUMERIC\"]:\n",
    "            # print(\n",
    "            #     f\"The provided label column is numeric and converted to categories.\"\n",
    "            # )\n",
    "            # labels = pd.qcut(\n",
    "            #     labels, q=4, labels=[\"1stQ\", \"2ndQ\", \"3rdQ\", \"4thQ\"]\n",
    "            # ).astype(str)\n",
    "            # else:\n",
    "            numeric = True\n",
    "        else:\n",
    "            labels = [str(x) for x in labels]\n",
    "\n",
    "    # check if label or embedding is longerm and duplicate the shorter one\n",
    "    if len(labels) < embedding.shape[0]:\n",
    "        print(\n",
    "            \"Given labels do not have the same length as given sample size. Labels will be duplicated.\"\n",
    "        )\n",
    "        labels = [\n",
    "            label for label in labels for _ in range(embedding.shape[0] // len(labels))\n",
    "        ]\n",
    "    elif len(labels) > embedding.shape[0]:\n",
    "        labels = list(set(labels))\n",
    "\n",
    "    if not style_param == None:\n",
    "        embedding[color_param] = labels\n",
    "        if numeric:\n",
    "            palette = \"bwr\"\n",
    "        else:\n",
    "            palette = None\n",
    "        plot = sns.relplot(\n",
    "            data=embedding,\n",
    "            x=\"DIM1\",\n",
    "            y=\"DIM2\",\n",
    "            hue=color_param,\n",
    "            palette=palette,\n",
    "            col=style_param,\n",
    "            style=style_param,\n",
    "            markers=True,\n",
    "            alpha=0.4,\n",
    "            ec=\"black\",\n",
    "            height=10,\n",
    "            aspect=1,\n",
    "            s=150,\n",
    "        )\n",
    "\n",
    "    if len(save_fig) > 0:\n",
    "        plot.savefig(save_fig, bbox_inches=\"tight\")\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect all metadata and latent spaces from datasets\n",
    "clin_data = []\n",
    "latent_data = []\n",
    "\n",
    "for split in [\"train\", \"test\", \"valid\"]:\n",
    "\tsplit_ds = getattr(r.datasets, split, None)\n",
    "\tif split_ds is not None:\n",
    "\t\tfor key, ds in split_ds.datasets.items():\n",
    "\t\t\tdf_latent = r.get_latent_df(epoch=-1, split=split, modality=key)\n",
    "\t\t\tdf_latent[\"modality\"] = key\n",
    "\t\t\tdf_latent[\"sample_ids\"] = df_latent.index # Each sample can occur multiple times in latent space\n",
    "\t\t\tlatent_data.append(df_latent)\n",
    "\t\t\tif hasattr(ds, \"metadata\") and ds.metadata is not None:\n",
    "\t\t\t\tdf = ds.metadata.copy()\n",
    "\t\t\t\t# Add sample_ids as a column if it's the index\n",
    "\t\t\t\tif df.index.name == \"sample_ids\" and \"sample_ids\" not in df.columns:\n",
    "\t\t\t\t\tprint(key)\n",
    "\t\t\t\t\tprint(df)\n",
    "\t\t\t\t\tdf = df.reset_index()\n",
    "\t\t\t\tdf[\"split\"] = split\n",
    "\t\t\t\tdf[\"modality\"] = key\n",
    "\t\t\t\tclin_data.append(df)\n",
    "\n",
    "if latent_data and clin_data:\n",
    "\tlatent_data = pd.concat(latent_data, axis=0, ignore_index=True)\n",
    "\tclin_data = pd.concat(clin_data, axis=0, ignore_index=True)\n",
    "\tif \"sample_ids\" in clin_data.columns:\n",
    "\t\tclin_data = clin_data.drop_duplicates(subset=\"sample_ids\").set_index(\"sample_ids\")\n",
    "else:\n",
    "\tlatent_data = pd.DataFrame()\n",
    "\tclin_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "## Make 2D Embedding with UMAP\n",
    "if latent_data.drop(columns=[\"sample_ids\", \"modality\"]).shape[1] > 2:\n",
    "\treducer = UMAP(n_components=2)\n",
    "\tembedding = pd.DataFrame(reducer.fit_transform(latent_data.drop(columns=[\"sample_ids\", \"modality\"])))\n",
    "\tembedding.columns = [\"DIM1\", \"DIM2\"]\n",
    "\tembedding[\"sample_ids\"] = latent_data[\"sample_ids\"]\n",
    "\tembedding[\"modality\"] = latent_data[\"modality\"]\n",
    "else:\n",
    "\tembedding = latent_data\n",
    "\n",
    "# Merge with clinical data via sample_ids\n",
    "embedding = embedding.merge(clin_data.drop(columns=[\"modality\"]), on=\"sample_ids\", how=\"left\")\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = \"extra_class_labels\"\n",
    "sns.set_theme(font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plot = plot_translate_latent(\n",
    "\tembedding=embedding,\n",
    "\tcolor_param=param,\n",
    "\tstyle_param=\"modality\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a7bcd",
   "metadata": {},
   "source": [
    "## Vis (new) Ridgeline alignment -> ridge per data modality, not grouped by clinic param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = acx.visualize.Visualizer.plot_latent_ridge(\n",
    "\tlat_space=latent_data.drop(columns=[\"sample_ids\", \"modality\"]),\n",
    "\tlabels= list(latent_data[\"modality\"]),\n",
    "\tparam=\"modality\"\n",
    ")\n",
    "\n",
    "fig.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "def plot_latent_ridge_multi(\n",
    "\tlat_space: pd.DataFrame,\n",
    "\tmodality: Optional[str] = None,\n",
    "\tlabels: Optional[Union[list, pd.Series, None]] = None,\n",
    "\tparam: Optional[Union[str, None]] = None,\n",
    ") -> sns.FacetGrid:\n",
    "\t\"\"\"\n",
    "\tCreates a ridge line plot of latent space dimension where each row shows the density of a latent dimension and groups (ridges).\n",
    "\tARGS:\n",
    "\t\tlat_space (pd.DataFrame): DataFrame containing the latent space intensities for samples (rows) and latent dimensions (columns)\n",
    "\t\tlabels (list): List of labels for each sample. If None, all samples are considered as one group.\n",
    "\t\tparam (str): Clinical parameter to create groupings and coloring of ridges. Must be a column name (str) of clin_data\n",
    "\tRETURNS:\n",
    "\t\tg (sns.FacetGrid): FacetGrid object containing the ridge line plot\n",
    "\t\"\"\"\n",
    "\tsns.set_theme(\n",
    "\t\tstyle=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}\n",
    "\t)  ## Necessary to enforce overplotting\n",
    "\n",
    "\tdf = pd.melt(lat_space,id_vars=modality, var_name=\"latent dim\", value_name=\"latent intensity\")\n",
    "\t# print(df)\n",
    "\tdf[\"sample\"] = len(lat_space.drop(columns=modality).columns) * list(lat_space.index)\n",
    "\n",
    "\tif labels is None:\n",
    "\t\tparam = \"all\"\n",
    "\t\tlabels = [\"all\"] * len(df)\n",
    "\n",
    "\t# print(labels[0])\n",
    "\tif not isinstance(labels[0], str):\n",
    "\t\tif len(np.unique(labels)) > 3:\n",
    "\t\t\tlabels = pd.qcut(\n",
    "\t\t\t\tx=pd.Series(labels),\n",
    "\t\t\t\tq=4,\n",
    "\t\t\t\tlabels=[\"1stQ\", \"2ndQ\", \"3rdQ\", \"4thQ\"],\n",
    "\t\t\t).astype(str)\n",
    "\t\telse:\n",
    "\t\t\tlabels = [str(x) for x in labels]\n",
    "\n",
    "\tdf[param] = len(lat_space.drop(columns=modality).columns) * labels  # type: ignore\n",
    "\n",
    "\texclude_missing_info = (df[param] == \"unknown\") | (df[param] == \"nan\")\n",
    "\n",
    "\n",
    "\txmin = (\n",
    "\t\tdf.loc[~exclude_missing_info, [\"latent intensity\", \"latent dim\", param]]\n",
    "\t\t.groupby([param, \"latent dim\"], observed=False)\n",
    "\t\t.quantile(0.05)\n",
    "\t\t.min()\n",
    "\t)\n",
    "\txmax = (\n",
    "\t\tdf.loc[~exclude_missing_info, [\"latent intensity\", \"latent dim\", param]]\n",
    "\t\t.groupby([param, \"latent dim\"], observed=False)\n",
    "\t\t.quantile(0.9)\n",
    "\t\t.max()\n",
    "\t)\n",
    "\n",
    "\tif len(np.unique(df[param])) > 8:\n",
    "\t\tcat_pal = sns.husl_palette(len(np.unique(df[param])))\n",
    "\telse:\n",
    "\t\tcat_pal = sns.color_palette(n_colors=len(np.unique(df[param])))\n",
    "\n",
    "\tg = sns.FacetGrid(\n",
    "\t\tdf[~exclude_missing_info],\n",
    "\t\trow=\"latent dim\",\n",
    "\t\tcol=modality,\n",
    "\t\thue=param,\n",
    "\t\taspect=12,\n",
    "\t\theight=0.8,\n",
    "\t\txlim=(xmin.iloc[0], xmax.iloc[0]),\n",
    "\t\tpalette=cat_pal,\n",
    "\t)\n",
    "\n",
    "\tg.map_dataframe(\n",
    "\t\tsns.kdeplot,\n",
    "\t\t\"latent intensity\",\n",
    "\t\tbw_adjust=0.5,\n",
    "\t\tclip_on=True,\n",
    "\t\tfill=True,\n",
    "\t\talpha=0.5,\n",
    "\t\twarn_singular=False,\n",
    "\t\tec=\"k\",\n",
    "\t\tlw=1,\n",
    "\t)\n",
    "\n",
    "\tdef label(data, color, label, text=\"latent dim\"):\n",
    "\t\tax = plt.gca()\n",
    "\t\tlabel_text = data[text].unique()[0]\n",
    "\t\tax.text(\n",
    "\t\t\t0.0,\n",
    "\t\t\t0.2,\n",
    "\t\t\tlabel_text,\n",
    "\t\t\tfontweight=\"bold\",\n",
    "\t\t\tha=\"right\",\n",
    "\t\t\tva=\"center\",\n",
    "\t\t\ttransform=ax.transAxes,\n",
    "\t\t)\n",
    "\n",
    "\tg.map_dataframe(label, text=\"latent dim\")\n",
    "\n",
    "\tg.set(xlim=(xmin.iloc[0], xmax.iloc[0]))\n",
    "\t# Set the subplots to overlap\n",
    "\tg.figure.subplots_adjust(hspace=-0.5)\n",
    "\n",
    "\t# Remove axes details that don't play well with overlap\n",
    "\tg.set_titles(\"\")\n",
    "\tg.set(yticks=[], ylabel=\"\")\n",
    "\tg.despine(bottom=True, left=True)\n",
    "\n",
    "\tfor i, m in enumerate(df[modality].unique()):\n",
    "\t\tg.fig.get_axes()[i].set_title(m)\n",
    "\n",
    "\tg.add_legend()\n",
    "\n",
    "\tplt.close()\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative show each ridgeline plot as subplots\n",
    "\n",
    "# Merge clin_data with latent_data\n",
    "latent_data_with_clin = latent_data.merge(clin_data.drop(columns=[\"modality\"]), on=\"sample_ids\", how=\"left\")\n",
    "\n",
    "param = \"early\"\n",
    "labels = latent_data_with_clin.loc[:, param].tolist()\n",
    "\n",
    "fig = plot_latent_ridge_multi(lat_space=latent_data.drop(columns=[\"sample_ids\"]),\n",
    "\tlabels=labels,\n",
    "\tmodality=\"modality\",\n",
    "\tparam=param\n",
    ")\n",
    "fig.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5262c",
   "metadata": {},
   "source": [
    "## Vis Loss plot absolute and relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d17fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df_melt = acx.visualize.Visualizer.make_loss_format(result=xmodalix.result, config=xmodalix.config)\n",
    "\n",
    "\n",
    "# Filter loss terms which are specific for each modality VAE\n",
    "# Plot only combined loss terms as in old autoencodix framework\n",
    "loss_df_melt = loss_df_melt[\n",
    "    ~ loss_df_melt[\"Loss Term\"].str.startswith(\n",
    "        tuple(xmodalix.result.datasets.train.datasets.keys())\n",
    "    )\n",
    "]\n",
    "\n",
    "print(loss_df_melt)\n",
    "\n",
    "\n",
    "fig_loss = acx.visualize.Visualizer.make_loss_plot(\n",
    "            df_plot=loss_df_melt, plot_type=\"absolute\"\n",
    "        )\n",
    "\n",
    "fig_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_loss_relative = acx.visualize.Visualizer.make_loss_plot(\n",
    "\t\t\tdf_plot=loss_df_melt, plot_type=\"relative\"\n",
    "\t\t)\n",
    "\n",
    "fig_loss_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe0508",
   "metadata": {},
   "source": [
    "## Vis translate Grid (image case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = \"early\"\n",
    "n_sample_per_class = 3\n",
    "\n",
    "# Get n samples per class\n",
    "# Get metadata for test split and img.IMG modality\n",
    "meta = xmodalix.result.datasets.test.datasets['img.IMG'].metadata\n",
    "\n",
    "# Get possible class values\n",
    "class_values = meta[param].unique()\n",
    "\n",
    "# Build dictionary of sample_ids per class value (max n_sample_per_class per class)\n",
    "sample_per_class = {\n",
    "\tval: meta[meta[param] == val].sample(\n",
    "\t\tn=min(n_sample_per_class, (meta[param] == val).sum()), random_state=42\n",
    "\t).index.tolist()\n",
    "\tfor val in class_values\n",
    "}\n",
    "sample_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b50fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xmodalix.result.datasets.test.datasets[\"img.IMG\"].sample_ids))\n",
    "len(set(xmodalix.result.datasets.test.datasets[\"img.IMG\"].sample_ids) & set(xmodalix.result.datasets.test.datasets[\"img.IMG\"].metadata.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xmodalix.result.datasets.train.datasets[\"multi_bulk.RNA\"].metadata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xmodalix.result.datasets.test.datasets[\"img.IMG\"].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids_list = xmodalix.result.datasets.test.datasets['img.IMG'].sample_ids\n",
    "\n",
    "sample_idx_per_class = dict()\n",
    "\n",
    "for class_value in sample_per_class:\n",
    "\t# Get sample ids for the current class value\n",
    "\tsids = sample_per_class[class_value]\n",
    "\t# Get indices of these sample ids in the sample_ids_list\n",
    "\tindices = [sample_ids_list.index(sid) for sid in sids if sid in sample_ids_list]\n",
    "\t# Store the indices in the dictionary\n",
    "\tsample_idx_per_class[class_value] = indices\n",
    "\n",
    "sample_idx_per_class\n",
    "\n",
    "## PROBLEM: metadata and test.datasets do not have the same sample_ids but should have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodalix.result.reconstructions.get(epoch=-1, split=\"test\")[\"img.IMG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361dbdca",
   "metadata": {},
   "source": [
    "### Flexible Prediction\n",
    "We train the Xmodalix with multiple data modalities, out of all these modalities, we can build any pair for translation byt passing the keys (as defined in your config or datapackage) to the predict method like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff399221",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = xmodalix.predict(from_key=\"IMG\", to_key=\"IMG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743348c",
   "metadata": {},
   "source": [
    "### Inspecting losses\n",
    "We save all losses in our result object, see the keys here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sub_losses.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385d4fd",
   "metadata": {},
   "source": [
    "After selecting a subloss, this works like a standard TrainingDynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25aef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sub_losses.get(\"adver_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf5e4e",
   "metadata": {},
   "source": [
    "### Visualizing a sample output\n",
    "Note this is shown with only one epoch training, I've seen good results for 20 epochs of pretraining img and 30 epochs of normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = result.reconstructions.get(split=\"test\", epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ddb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = img[0, :, :, :].squeeze()\n",
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937fcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593346b2",
   "metadata": {},
   "source": [
    "### Getting Info about pretraining\n",
    "The pretraining is saved in sub_results in the result object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4733f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_res = result.sub_results\n",
    "sub_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1777d",
   "metadata": {},
   "source": [
    "## Xmodal_loss Visualization\n",
    "Vibe coded provisory loss visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sub_losses.keys()\n",
    "result.sub_losses.get(\"img.IMG.var_loss\").get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_losses(result):\n",
    "    \"\"\"\n",
    "    Generates and displays plots for all relevant losses from a Result object.\n",
    "\n",
    "    Args:\n",
    "        result: Your custom result object containing the sub_losses attribute.\n",
    "    \"\"\"\n",
    "    if not hasattr(result, \"sub_losses\"):\n",
    "        print(\n",
    "            \"Error: The provided result object does not have a 'sub_losses' attribute.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # 1. Get all loss keys and filter out the factors\n",
    "    all_loss_keys = result.sub_losses.keys()\n",
    "    keys_to_plot = [key for key in all_loss_keys if not key.endswith(\"_factor\")]\n",
    "\n",
    "    if not keys_to_plot:\n",
    "        print(\"No valid loss keys found to plot.\")\n",
    "        return\n",
    "\n",
    "    # 2. Iterate through each loss and create a plot\n",
    "    for loss_name in keys_to_plot:\n",
    "        try:\n",
    "            # Retrieve the nested dictionary for the current loss\n",
    "            loss_data = result.sub_losses.get(loss_name).get()\n",
    "\n",
    "            # 3. Unpack the data into lists for plotting\n",
    "            epochs = sorted(loss_data.keys())\n",
    "            train_losses = [loss_data[epoch][\"train\"] for epoch in epochs]\n",
    "\n",
    "            # Check if validation data exists before trying to plot it\n",
    "            has_valid_data = all(\"valid\" in loss_data[epoch] for epoch in epochs)\n",
    "            if has_valid_data:\n",
    "                valid_losses = [loss_data[epoch][\"valid\"] for epoch in epochs]\n",
    "\n",
    "            # 4. Create the plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(epochs, train_losses, \"o-\", label=f\"Train ({loss_name})\")\n",
    "            if has_valid_data:\n",
    "                plt.plot(epochs, valid_losses, \"x-\", label=f\"Validation ({loss_name})\")\n",
    "\n",
    "            plt.title(f\"Training and Validation Loss: {loss_name}\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        except (AttributeError, TypeError, KeyError) as e:\n",
    "            print(f\"Could not plot '{loss_name}'. Error retrieving data: {e}\")\n",
    "\n",
    "\n",
    "# This is a mock setup to demonstrate how to use the function.\n",
    "print(\"Generating plots from mock result object...\")\n",
    "plot_losses(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad54bb1",
   "metadata": {},
   "source": [
    "## Imagix\n",
    "If we want to use a standard image vae, we can use the Imagix pipeline. Note that only one image dataset is allowed here\n",
    "**NOTE**:\n",
    "set the datacase in config to DataCase.IMG_TO_IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e54b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    "    DataInfo,\n",
    ")\n",
    "import os\n",
    "\n",
    "IMGROOT = os.path.join(\"data/images/ALY-2_SYS721/\")\n",
    "IMGMAPPING = os.path.join(\"data/ALY-2_SYS721_mappings.txt\")\n",
    "NUMFILE = os.path.join(\"data/AM3_NO2_raw_cell.tsv\")\n",
    "\n",
    "img_config2 = DefaultConfig(\n",
    "    data_case=DataCase.IMG_TO_IMG,\n",
    "    checkpoint_interval=10,\n",
    "\tloss_reduction = \"sum\",\n",
    "    epochs=100,\n",
    "\tbeta = 0.1,\n",
    "\tlearning_rate=0.001,\n",
    "\tlatent_dim=16,\n",
    "    batch_size=32,\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=IMGROOT,\n",
    "\t\t\t\tscaling=\"MINMAX\",\n",
    "                data_type=\"IMG\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=IMGMAPPING,\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "\n",
    "imagix = acx.Imagix(config=img_config2)\n",
    "imagix.preprocess()\n",
    "imagix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2af91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagix.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dba08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = imagix.result\n",
    "r2.final_reconstruction\n",
    "sample_img = r2.final_reconstruction.data[0, :, :, :]\n",
    "sample_img = sample_img.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def35ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = r2.reconstructions.get(split=\"test\")\n",
    "sample_img = sample_img[0,0,:,:,:]\n",
    "sample_img = sample_img.squeeze()\n",
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cba61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
