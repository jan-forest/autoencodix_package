{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODIX PACKAGE HANDBOOK\n",
    "This notebook demonstrates the usage of the autoencodix package.\n",
    "For now it serves as an internal guideline with the goal to:\n",
    "- test the package from a user perspective\n",
    "- serve as a first draft of user documentation\n",
    "- serve a developer guideline \n",
    "  - developer guide will be derrived from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Generate mock data\n",
    "We provide a variable for example data that can be imported easily. Later we show how to use your own data and what do keep in mind when doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/notebooks\n",
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(notebook_dir)\n",
    "os.chdir(notebook_dir)\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "# os.chdir(os.path.join(notebook_dir, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mudata._core.mudata.MuData"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_sc.multi_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 General Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import DefaultConfig, DataCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data in nanremover: multi_sc: 1000 samples × 700 features\n",
      "multi_sc in nanremover: View of MuData object with n_obs × n_vars = 1000 × 700\n",
      "  2 modalities\n",
      "    rna:\t1000 x 500\n",
      "      obs:\t'cell_type', 'batch', 'donor', 'cell_cycle'\n",
      "    protein:\t1000 x 200\n",
      "      obs:\t'cell_type', 'batch', 'donor', 'cell_cycle'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'multi_sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m van \u001b[38;5;241m=\u001b[39m acx\u001b[38;5;241m.\u001b[39mVanillix(user_data\u001b[38;5;241m=\u001b[39mraw_sc, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m### DATA PROCESSING ### --------------------------\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# job of old make data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# populates self._datasets attribute with torch dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# (important for training with dataloader)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# possible to pass a custom Config object, or keyword arguments\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mvan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m### MODEL TRAINING ### --------------------------\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# job of old make model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calls self.Trainer class to init and train model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# populates self._model attribute with trained model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# populates self.result attribute with training results (model, losses, etc)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m van\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/utils/_utils.py:128\u001b[0m, in \u001b[0;36mconfig_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter must be of type DefaultConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m     config \u001b[38;5;241m=\u001b[39m user_config\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:306\u001b[0m, in \u001b[0;36mBasePipeline.preprocess\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_user_data()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mdatasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/data/general_preprocessor.py:219\u001b[0m, in \u001b[0;36mGeneralPreprocessor.preprocess\u001b[0;34m(self, raw_user_data, predict_new_data)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mExecutes the general preprocessing steps and returns the processed data package.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Dict[str, Any]: The processed data package.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_new_data \u001b[38;5;241m=\u001b[39m predict_new_data\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_general_preprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_new_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_new_data\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:111\u001b[0m, in \u001b[0;36mBasePreprocessor._general_preprocess\u001b[0;34m(self, raw_user_data, predict_new_data)\u001b[0m\n\u001b[1;32m    109\u001b[0m process_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_process_function(datacase\u001b[38;5;241m=\u001b[39mdatacase)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_function:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported data case: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatacase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:251\u001b[0m, in \u001b[0;36mBasePreprocessor._process_multi_single_cell\u001b[0;34m(self, raw_user_data)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpostsplit_processor\u001b[39m(\n\u001b[1;32m    245\u001b[0m     split_data: Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[1;32m    246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postsplit_multi_single_cell(\n\u001b[1;32m    248\u001b[0m         split_data\u001b[38;5;241m=\u001b[39msplit_data, datapackage_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_sc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     )\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data_case\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality_processors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_sc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresplit_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostsplit_processor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:184\u001b[0m, in \u001b[0;36mBasePreprocessor._process_data_case\u001b[0;34m(self, data_package, modality_processors)\u001b[0m\n\u001b[1;32m    182\u001b[0m     mock_split[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaired\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([])}}\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mock_split\n\u001b[0;32m--> 184\u001b[0m clean_package \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_nans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_package\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_package\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modality_key, (presplit_processor, _) \u001b[38;5;129;01min\u001b[39;00m modality_processors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    186\u001b[0m     modality_data \u001b[38;5;241m=\u001b[39m clean_package[modality_key]\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:833\u001b[0m, in \u001b[0;36mBasePreprocessor._remove_nans\u001b[0;34m(self, data_package)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03mRemove NaN values from the data package.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m    The DataPackage with NaN values removed.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    830\u001b[0m nanremover \u001b[38;5;241m=\u001b[39m NaNRemover(\n\u001b[1;32m    831\u001b[0m     relevant_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_config\u001b[38;5;241m.\u001b[39mannotation_columns\n\u001b[1;32m    832\u001b[0m )\n\u001b[0;32m--> 833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnanremover\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_package\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/data/_nanremover.py:118\u001b[0m, in \u001b[0;36mNaNRemover.remove_nan\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata in nanremover: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_sc in nanremover: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mmulti_sc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m mudata \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_sc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_sc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Process each modality\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod_name, mod_data \u001b[38;5;129;01min\u001b[39;00m mudata\u001b[38;5;241m.\u001b[39mmod\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:382\u001b[0m, in \u001b[0;36mMuData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMuData\u001b[39m\u001b[38;5;124m\"\u001b[39m, AnnData]:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MuData(\u001b[38;5;28mself\u001b[39m, as_view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39mindex)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'multi_sc'"
     ]
    }
   ],
   "source": [
    "#### --------------------------------------------\n",
    "### INITIALIZATION ### --------------------------\n",
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "van = acx.Vanillix(user_data=raw_sc, config=config)\n",
    "# ------------------------------------------------\n",
    "### DATA PROCESSING ### --------------------------\n",
    "# job of old make data\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# ------------------------------------------------\n",
    "### MODEL TRAINING ### --------------------------\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (model, losses, etc)\n",
    "van.fit()\n",
    "# ------------------------------------------------\n",
    "### PREDICTION ### -------------------------------\n",
    "# job of old make predict\n",
    "# if no data is passed, used the test split from preprocessing\n",
    "# otherwise, uses the data passed, and preprocesses it\n",
    "# updates self.result attribute with predictions (latent space, reconstructions, etc)\n",
    "van.predict()\n",
    "# ------------------------------------------------\n",
    "### EVALUATION ### -------------------------------\n",
    "# job of old make ml_task\n",
    "# populates self.result attribute with ml task results\n",
    "van.evaluate()  # not implemented yet\n",
    "# ------------------------------------------------\n",
    "### VISUALIZATION ### ---------------------------\n",
    "# job of old make visualize\n",
    "# populates self.result attribute with visualizations\n",
    "van.visualize()\n",
    "# show visualizations for notebook use\n",
    "van.show_result()\n",
    "# --------------------------\n",
    "# --------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mudata._core.mudata.MuData"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_sc.multi_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or run all steps in one command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape after filtering: (350, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (350, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (350, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (350, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (50, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (50, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 20)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': multi_bulk:\n",
      "  transcriptomics: 350 samples × 20 features\n",
      "  proteomics: 350 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 350 samples × 3 features\n",
      "  proteomics: 350 samples × 3 features, 'indices': {'paired': {'train': array([261, 452, 217,  40, 183, 439, 301,  51,  94,  22, 124,  82, 366,\n",
      "       194, 264, 299, 131, 288, 240, 166,  24, 364, 431, 460, 392, 486,\n",
      "       106, 169, 320, 212, 314, 286, 302, 488, 224, 351, 276,  21, 335,\n",
      "       400, 175, 209, 263,  26, 358, 190,  20, 262, 140, 158, 378, 352,\n",
      "       108, 341, 386, 136,  73, 368, 453, 409,   9, 468, 230, 176, 145,\n",
      "       236, 487, 355,  99, 255, 225,  53, 281, 134, 115, 292,  19, 423,\n",
      "       266,  37, 297, 333,  68,   2,   1, 321,  12,  70, 349, 395, 256,\n",
      "       229,   0, 455,  14,  61, 397, 101,  32, 436, 494, 238, 462, 222,\n",
      "       382,  43,  27, 375, 346, 303, 478, 198, 402, 470, 103, 232, 412,\n",
      "        56, 287, 278,  49, 133, 196, 149, 394, 273, 483, 373, 372, 191,\n",
      "        44, 327,  38, 156, 445, 421, 206, 328, 383, 204,  57,  97, 182,\n",
      "       174, 405, 466,  91, 357, 370, 207, 141, 407,  30,  25, 195,  80,\n",
      "        93, 258, 231, 446, 359, 122,  64,  60, 280,  81, 269, 325, 243,\n",
      "       283, 404, 482, 197, 497, 127, 363, 121, 148, 254, 448, 104, 331,\n",
      "       489, 227,  15,  95, 245, 318, 184,  87, 139,  41, 447, 228, 268,\n",
      "        39, 354, 390, 294, 132, 282, 435,   8, 234, 441, 279, 111, 296,\n",
      "       319, 459, 308, 461, 137, 242, 155, 369, 259,  79, 267, 123, 112,\n",
      "        74, 498, 387, 360, 113, 474, 473, 471, 226, 208, 205, 424, 253,\n",
      "       244, 157,  55, 167, 427,  63,  42, 391, 344, 210, 186, 219, 377,\n",
      "       172, 239, 451, 313, 469, 216, 171,  33,  69, 152, 393, 472, 252,\n",
      "       475, 298, 202, 130, 193,  84, 362,   7, 348,  28, 185,  54,  71,\n",
      "       120, 118, 188, 371,  10,  52, 150, 403, 125, 316, 481, 332, 275,\n",
      "       484, 408, 215,  88, 160,  77, 429, 290, 410, 426, 180, 151, 414,\n",
      "       336, 418, 496, 161, 291,  75,  58, 241,  23, 129, 456,  16, 138,\n",
      "       413, 199, 337, 177, 356, 438,  83, 159, 381, 126, 247, 246,  59,\n",
      "       465, 170, 309, 458,  13, 437, 220, 384, 353, 490, 211, 200, 114,\n",
      "        89, 433, 450, 109, 272, 399, 203, 338, 388,  72, 181, 454])}}}, 'valid': {'data': multi_bulk:\n",
      "  transcriptomics: 50 samples × 20 features\n",
      "  proteomics: 50 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 50 samples × 3 features\n",
      "  proteomics: 50 samples × 3 features, 'indices': {'paired': {'valid': array([235, 105, 367,  76, 251,   3,  48, 457,  46, 493, 271, 398, 411,\n",
      "       153, 265, 464,  50,  78, 218, 116, 428, 432, 178, 248,  18, 499,\n",
      "        86,  35, 317,  45, 420, 380, 100,  36, 379, 270,  98, 343, 396,\n",
      "       163,  96, 307, 154, 376, 237, 274, 144, 143, 443, 440])}}}, 'test': {'data': multi_bulk:\n",
      "  transcriptomics: 100 samples × 20 features\n",
      "  proteomics: 100 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 100 samples × 3 features\n",
      "  proteomics: 100 samples × 3 features, 'indices': {'paired': {'test': array([304, 340,  47,  67, 479, 485, 310,  31, 249,  90, 322, 168, 119,\n",
      "        66, 305, 189, 434, 289, 142, 146, 293, 312, 311, 492,  65, 374,\n",
      "        34, 342, 173, 201, 179, 306, 233, 442, 345, 128, 277,   4, 401,\n",
      "       361, 326, 430, 467, 213, 330, 329, 295, 416, 406, 102, 164, 214,\n",
      "         5, 419, 449,  62, 334, 300,  17, 350, 347,  85, 257, 365, 385,\n",
      "       315, 389, 339, 284, 162, 323, 324, 147,  29, 107, 463, 495, 425,\n",
      "       250, 135, 260, 117, 187, 415, 165, 223, 444, 285, 491, 476, 477,\n",
      "       480, 417,   6, 422,  11, 192,  92, 221, 110])}}}}\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 14.588472604751587\n",
      "Epoch: 1, Loss: 13.76898205280304\n",
      "Epoch: 2, Loss: 13.156720161437988\n",
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "# run all steps in the pipeline\n",
    "result = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reconstruction shape: (350, 40) (samples x features)\n",
      "Validation reconstruction shape: (50, 40) (samples x features)\n",
      "Test reconstruction shape: (100, 40) (samples x features)\n",
      "Total reconstructed samples: 500\n"
     ]
    }
   ],
   "source": [
    "recons = result.reconstructions.get(split=\"train\", epoch=2)\n",
    "recons_val = result.reconstructions.get(split=\"valid\", epoch=2)\n",
    "recons_test = result.reconstructions.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(f\"Training reconstruction shape: {recons.shape} (samples x features)\")\n",
    "print(f\"Validation reconstruction shape: {recons_val.shape} (samples x features)\")\n",
    "print(f\"Test reconstruction shape: {recons_test.shape} (samples x features)\")\n",
    "print(\n",
    "    f\"Total reconstructed samples: {recons.shape[0] + recons_val.shape[0] + recons_test.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training latent representations: (350, 16) (n_samples=350, latent_dim=16)\n",
      "Validation latent representations: (50, 16) (n_samples=50, latent_dim=16)\n",
      "Test latent representations: (100, 16) (n_samples=100, latent_dim=16)\n",
      "Total encoded samples: 500\n",
      "Latent space dimensionality: 16\n"
     ]
    }
   ],
   "source": [
    "latents = result.latentspaces.get(split=\"train\", epoch=2)\n",
    "latents_val = result.latentspaces.get(split=\"valid\", epoch=2)\n",
    "latents_test = result.latentspaces.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(\n",
    "    f\"Training latent representations: {latents.shape} (n_samples={latents.shape[0]}, latent_dim={latents.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation latent representations: {latents_val.shape} (n_samples={latents_val.shape[0]}, latent_dim={latents_val.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test latent representations: {latents_test.shape} (n_samples={latents_test.shape[0]}, latent_dim={latents_test.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Total encoded samples: {latents.shape[0] + latents_val.shape[0] + latents_test.shape[0]}\"\n",
    ")\n",
    "print(f\"Latent space dimensionality: {latents.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a custom train, test, valid split\n",
    "When you pass the data to the pipeline, autoencodix, internally splits the data for you based on the train,test, valid ratios provided in the config (defaults are 70%/10%/20% train/valid/test).\n",
    "You can either pass custom ratios (see next section) or provide the indices directly as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape after filtering: (350, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (350, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (350, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (350, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (50, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (50, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (100, 20)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': multi_bulk:\n",
      "  transcriptomics: 350 samples × 20 features\n",
      "  proteomics: 350 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 350 samples × 3 features\n",
      "  proteomics: 350 samples × 3 features, 'indices': {'paired': {'train': array([261, 452, 217,  40, 183, 439, 301,  51,  94,  22, 124,  82, 366,\n",
      "       194, 264, 299, 131, 288, 240, 166,  24, 364, 431, 460, 392, 486,\n",
      "       106, 169, 320, 212, 314, 286, 302, 488, 224, 351, 276,  21, 335,\n",
      "       400, 175, 209, 263,  26, 358, 190,  20, 262, 140, 158, 378, 352,\n",
      "       108, 341, 386, 136,  73, 368, 453, 409,   9, 468, 230, 176, 145,\n",
      "       236, 487, 355,  99, 255, 225,  53, 281, 134, 115, 292,  19, 423,\n",
      "       266,  37, 297, 333,  68,   2,   1, 321,  12,  70, 349, 395, 256,\n",
      "       229,   0, 455,  14,  61, 397, 101,  32, 436, 494, 238, 462, 222,\n",
      "       382,  43,  27, 375, 346, 303, 478, 198, 402, 470, 103, 232, 412,\n",
      "        56, 287, 278,  49, 133, 196, 149, 394, 273, 483, 373, 372, 191,\n",
      "        44, 327,  38, 156, 445, 421, 206, 328, 383, 204,  57,  97, 182,\n",
      "       174, 405, 466,  91, 357, 370, 207, 141, 407,  30,  25, 195,  80,\n",
      "        93, 258, 231, 446, 359, 122,  64,  60, 280,  81, 269, 325, 243,\n",
      "       283, 404, 482, 197, 497, 127, 363, 121, 148, 254, 448, 104, 331,\n",
      "       489, 227,  15,  95, 245, 318, 184,  87, 139,  41, 447, 228, 268,\n",
      "        39, 354, 390, 294, 132, 282, 435,   8, 234, 441, 279, 111, 296,\n",
      "       319, 459, 308, 461, 137, 242, 155, 369, 259,  79, 267, 123, 112,\n",
      "        74, 498, 387, 360, 113, 474, 473, 471, 226, 208, 205, 424, 253,\n",
      "       244, 157,  55, 167, 427,  63,  42, 391, 344, 210, 186, 219, 377,\n",
      "       172, 239, 451, 313, 469, 216, 171,  33,  69, 152, 393, 472, 252,\n",
      "       475, 298, 202, 130, 193,  84, 362,   7, 348,  28, 185,  54,  71,\n",
      "       120, 118, 188, 371,  10,  52, 150, 403, 125, 316, 481, 332, 275,\n",
      "       484, 408, 215,  88, 160,  77, 429, 290, 410, 426, 180, 151, 414,\n",
      "       336, 418, 496, 161, 291,  75,  58, 241,  23, 129, 456,  16, 138,\n",
      "       413, 199, 337, 177, 356, 438,  83, 159, 381, 126, 247, 246,  59,\n",
      "       465, 170, 309, 458,  13, 437, 220, 384, 353, 490, 211, 200, 114,\n",
      "        89, 433, 450, 109, 272, 399, 203, 338, 388,  72, 181, 454])}}}, 'valid': {'data': multi_bulk:\n",
      "  transcriptomics: 50 samples × 20 features\n",
      "  proteomics: 50 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 50 samples × 3 features\n",
      "  proteomics: 50 samples × 3 features, 'indices': {'paired': {'valid': array([235, 105, 367,  76, 251,   3,  48, 457,  46, 493, 271, 398, 411,\n",
      "       153, 265, 464,  50,  78, 218, 116, 428, 432, 178, 248,  18, 499,\n",
      "        86,  35, 317,  45, 420, 380, 100,  36, 379, 270,  98, 343, 396,\n",
      "       163,  96, 307, 154, 376, 237, 274, 144, 143, 443, 440])}}}, 'test': {'data': multi_bulk:\n",
      "  transcriptomics: 100 samples × 20 features\n",
      "  proteomics: 100 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 100 samples × 3 features\n",
      "  proteomics: 100 samples × 3 features, 'indices': {'paired': {'test': array([304, 340,  47,  67, 479, 485, 310,  31, 249,  90, 322, 168, 119,\n",
      "        66, 305, 189, 434, 289, 142, 146, 293, 312, 311, 492,  65, 374,\n",
      "        34, 342, 173, 201, 179, 306, 233, 442, 345, 128, 277,   4, 401,\n",
      "       361, 326, 430, 467, 213, 330, 329, 295, 416, 406, 102, 164, 214,\n",
      "         5, 419, 449,  62, 334, 300,  17, 350, 347,  85, 257, 365, 385,\n",
      "       315, 389, 339, 284, 162, 323, 324, 147,  29, 107, 463, 495, 425,\n",
      "       250, 135, 260, 117, 187, 415, 165, 223, 444, 285, 491, 476, 477,\n",
      "       480, 417,   6, 422,  11, 192,  92, 221, 110])}}}}\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 14.588472604751587\n",
      "Epoch: 1, Loss: 13.76898205280304\n",
      "Epoch: 2, Loss: 13.156720161437988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from autoencodix.utils.default_config import DataCase\n",
    "\n",
    "sample_data = np.random.rand(100, 10)\n",
    "custom_train_indices = np.arange(75)  # we won't allow overlap between splits\n",
    "custom_valid_indices = np.arange(75, 80)\n",
    "custom_test_indices = np.arange(80, 100)\n",
    "\n",
    "# the custom split needs to be a dictionary with keys \"train\", \"valid\", and \"test\" and indices of the samples to be included in each split as numpy arrays\n",
    "custom_split = {\n",
    "    \"train\": custom_train_indices,\n",
    "    \"valid\": custom_valid_indices,\n",
    "    \"test\": custom_test_indices,\n",
    "}\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = acx.Vanillix(user_data=raw_bulk, custom_splits=custom_split, config=config)\n",
    "van.preprocess()\n",
    "van.fit(epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass empty splits, but depending on how you'll use the autoencodix pipeline, this will throw an error at some point. So it is possible to call `fit` with only training data, but if you want to call `predict` and don't provide new data, this won't work without a data in the test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predict with new data\n",
    "The standard case is to train the model with the train data and then predict with the test split.\n",
    "However, it is possible to pass new data to the predict method to perform inference on this data with the already trained model.\n",
    "\n",
    "Here you have two options:\n",
    "1. Provide a fully processed dataset (similiar to `EXAMPLE_PROCESSED_DATA`) See the section `Work with you own data` for details.\n",
    "2. Provide raw data, which will be processed before predicting (also see `Work with your own data`)\n",
    "\n",
    "You pass the data with the keyword argument `data`, and depending on the datatype, the pipeline knows whether to preprocess or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (500, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (500, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (500, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (500, 20)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': None, 'indices': {'paired': array([], dtype=float64)}}, 'test': {'data': multi_bulk:\n",
      "  transcriptomics: 500 samples × 20 features\n",
      "  proteomics: 500 samples × 20 features\n",
      "annotation:\n",
      "  transcriptomics: 500 samples × 3 features\n",
      "  proteomics: 500 samples × 3 features, 'indices': {'paired': array([], dtype=float64)}}, 'valid': {'data': None, 'indices': {'paired': array([], dtype=float64)}}}\n"
     ]
    }
   ],
   "source": [
    "# assume new data\n",
    "new_data = raw_bulk\n",
    "van.predict(data=new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the result of the pipeline\n",
    "Each step in the pipeline writes its results in the result object of the Vanillix instance.\n",
    "In this section we explore how to access and make sense of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Object Public Attributes:\n",
      "------------------------------\n",
      "latentspaces: TrainingDynamics object\n",
      "reconstructions: TrainingDynamics object\n",
      "mus: TrainingDynamics object\n",
      "sigmas: TrainingDynamics object\n",
      "losses: TrainingDynamics object\n",
      "sub_losses: LossRegistry(_losses={'recon_loss': TrainingDynamics()})\n",
      "preprocessed_data: Tensor of shape (0,)\n",
      "model: _FabricModule\n",
      "model_checkpoints: TrainingDynamics object\n",
      "datasets: DatasetContainer(train=<autoencodix.data._numeric_dataset.NumericDataset object at 0x348dffeb0>, valid=<autoencodix.data._numeric_dataset.NumericDataset object at 0x348dfe1a0>, test=<autoencodix.data._numeric_dataset.NumericDataset object at 0x348dffe80>)\n"
     ]
    }
   ],
   "source": [
    "result = van.result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TrainingDynamics object in result\n",
    "The training dynamics object has the followinf form:\n",
    "<epoch><split><data>\n",
    "So if you want to access the train loss for the 5th epoch, you would:\n",
    "`result.lossss.get(epoch=5, split=\"train\")`\n",
    "\n",
    "##### The `.get()` Method Explained\n",
    "\n",
    "The `reconstructions.get()` method provides flexible access to reconstruction data stored during training. It can retrieve data for specific epochs, specific splits, or any combination of these parameters.\n",
    "\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "- **`epoch`** (Optional[int]): \n",
    "  - Positive integer (e.g., `2`): Get reconstructions from that specific epoch\n",
    "  - Negative integer (e.g., `-1`): Get the latest epoch (-1), second-to-last (-2), etc.\n",
    "  - `None`: Return data for all epochs\n",
    "\n",
    "- **`split`** (Optional[str]):\n",
    "  - Valid values: \"train\", \"valid\", \"test\"\n",
    "  - `None`: Return data for all splits\n",
    "\n",
    "##### Return Value Behavior:\n",
    "\n",
    "The method returns different types depending on the parameters:\n",
    "\n",
    "1. **Both `epoch` and `split` specified**:\n",
    "   - Returns a NumPy array for that specific epoch and split\n",
    "   - Example: `get(epoch=2, split=\"train\")` → `array([...])` \n",
    "\n",
    "2. **Only `epoch` specified**:\n",
    "   - Returns a dictionary of all splits for that epoch\n",
    "   - Example: `get(epoch=2)` → `{\"train\": array([...]), \"valid\": array([...]), ...}`\n",
    "\n",
    "3. **Only `split` specified**:\n",
    "   - Returns a NumPy array containing data for that split across all epochs\n",
    "   - Example: `get(split=\"train\")` → `array([[...], [...], ...])` (first dimension represents epochs)\n",
    "\n",
    "4. **Neither specified**:\n",
    "   - Returns the complete nested dictionary structure\n",
    "   - Example: `get()` → `{0: {\"train\": array([...])}, 1: {...}, ...}`\n",
    "\n",
    "##### Special Handling:\n",
    "\n",
    "- If an invalid split is provided, a `KeyError` is raised\n",
    "- Negative epoch indices work like Python list indexing (-1 is the last epoch)\n",
    "- If an epoch doesn't exist, an empty array or dictionary is returned\n",
    "\n",
    "##### Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1960654692216353\n",
      "[0.93471134 0.94884425 0.93897349]\n",
      "{0: {'train': array(1.32622478), 'valid': array(0.93471134)}, 1: {'train': array(1.25172564), 'valid': array(0.94884425)}, 2: {'train': array(1.19606547), 'valid': array(0.93897349)}}\n"
     ]
    }
   ],
   "source": [
    "loss_train_ep2 = result.losses.get(epoch=2, split=\"train\")\n",
    "print(loss_train_ep2)\n",
    "valid_loss = result.losses.get(split=\"valid\")\n",
    "print(valid_loss)\n",
    "print(result.losses.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    # EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "# raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this schema works for every TrainingDynamics instance in the results object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Pipeline usage with custom parameters\n",
    "Here we show how to customize the above shown pipeline with a user config or with keyword arguments.\n",
    "Alternatively, we can read the config parameters from a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 902.8508224487305\n",
      "Epoch: 1, Loss: 876.4703140258789\n",
      "Epoch: 2, Loss: 849.4972991943359\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 902.8508224487305\n",
      "Epoch: 1, Loss: 876.4703140258789\n",
      "Epoch: 2, Loss: 849.4972991943359\n"
     ]
    }
   ],
   "source": [
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "van = acx.Vanillix(user_data=processed_data)\n",
    "# job of old make data\n",
    "# populates self._features attrbute with torch tensor\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (losses, etc)\n",
    "# van.fit()\n",
    "\"\"\" \n",
    "Each step can be run separately, with custom parameters, these parameters\n",
    "can be passed as keyword arguments, or as a Config object\n",
    "\"\"\"\n",
    "van.fit(learning_rate=0.01, batch_size=32, epochs=5)  # or like this:\n",
    "my_config = DefaultConfig(learning_rate=130.0, batch_size=32, epochs=5)\n",
    "van.fit(config=my_config)  # config has to be an keyword argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.1  How to relevant keyword arguments for pipeline methods\n",
    "It can be hard to know what keyword arguments are valid for each step,\n",
    "so we show:\n",
    "- how to get a list of allowed keyword arguments\n",
    "- what happens if you pass non-allowed keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size',\n",
      " 'checkpoint_interval',\n",
      " 'config',\n",
      " 'device',\n",
      " 'epochs',\n",
      " 'global_seed',\n",
      " 'gpu_strategy',\n",
      " 'learning_rate',\n",
      " 'n_gpus',\n",
      " 'n_workers',\n",
      " 'reconstruction_loss',\n",
      " 'reproducible',\n",
      " 'weight_decay'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# for each config method, we can call a valid_params method\n",
    "van = acx.Vanillix(user_data=processed_data)\n",
    "\n",
    "# returns a set of keyword arguments that are actually used in the fit method\n",
    "fit_params = van.fit.valid_params\n",
    "\n",
    "pprint.pprint(fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get even more verbose info about the keyword args, you can run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Keyword Arguments:\n",
      "--------------------------------------------------\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "# when you want to have more info about the params, you can get type hints from the config object\n",
    "my_config = DefaultConfig()\n",
    "conig_values = my_config.get_params()\n",
    "my_config.print_schema(filter_params=fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass not supported parameters you get a warning and we fall back to default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: The following parameters are not valid for fit:\n",
      "Invalid parameters: epochds\n",
      "Valid parameters are: batch_size, checkpoint_interval, config, device, epochs, global_seed, gpu_strategy, learning_rate, n_gpus, n_workers, reconstruction_loss, reproducible, weight_decay\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 902.8508224487305\n",
      "Epoch: 1, Loss: 876.4703140258789\n",
      "Epoch: 2, Loss: 849.4972991943359\n"
     ]
    }
   ],
   "source": [
    "# if you use an unsupported keyword argument, you will get a warning\n",
    "# as you see the default value from the DefaultConfig is not overwritten and the training will take 100 epochs (not 10)\n",
    "van.preprocess()\n",
    "van.fit(epochds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2 How to get information about the default config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DefaultConfig Configuration Parameters:\n",
      "--------------------------------------------------\n",
      "\n",
      "data_config:\n",
      "  Type: <class 'autoencodix.utils.default_config.DataConfig'>\n",
      "  Default: data_info={} require_common_cells=False annotation_columns=None\n",
      "  Description: No description available\n",
      "\n",
      "paired_translation:\n",
      "  Type: typing.Optional[bool]\n",
      "  Default: PydanticUndefined\n",
      "  Description: Indicator if the samples for the xmodalix are paired, based on some sample id\n",
      "\n",
      "data_case:\n",
      "  Type: typing.Optional[autoencodix.utils.default_config.DataCase]\n",
      "  Default: PydanticUndefined\n",
      "  Description: Data case for the model, will be determined automatically\n",
      "\n",
      "latent_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 16\n",
      "  Description: Dimension of the latent space\n",
      "\n",
      "n_layers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of layers in encoder/decoder, without latent layer. If 0, is only the latent layer.\n",
      "\n",
      "enc_factor:\n",
      "  Type: <class 'int'>\n",
      "  Default: 4\n",
      "  Description: Scaling factor for encoder dimensions\n",
      "\n",
      "input_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 10000\n",
      "  Description: Input dimension\n",
      "\n",
      "drop_p:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Dropout probability\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "default_vae_loss:\n",
      "  Type: typing.Literal['kl', 'mmd']\n",
      "  Default: kl\n",
      "  Description: Type of VAE loss\n",
      "\n",
      "loss_reduction:\n",
      "  Type: typing.Literal['sum', 'mean']\n",
      "  Default: mean\n",
      "  Description: Loss reduction in PyTorch i.e in torch.nn.functional.binary_cross_entropy_with_logits(reduction=loss_reduction)\n",
      "\n",
      "beta:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Beta weighting factor for VAE loss\n",
      "\n",
      "min_samples_per_split:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Minimum number of samples per split\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "float_precision:\n",
      "  Type: typing.Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16']\n",
      "  Default: 32\n",
      "  Description: Floating point precision\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "train_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.7\n",
      "  Description: Ratio of data for training\n",
      "\n",
      "test_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.2\n",
      "  Description: Ratio of data for testing\n",
      "\n",
      "valid_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Ratio of data for validation\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "# if you want to see what config parameters are used in the default config you can do it like:\n",
    "default_config = DefaultConfig()\n",
    "default_config.print_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02.3 Documentation Config class\n",
    "You can update the config with your own values by:\n",
    "- passing arguments as:\n",
    "    - dict\n",
    "    - single arguments\n",
    "- passing a file (sample configs and data can be found [here](https://cloud.scadsai.uni-leipzig.de/index.php/s/54aL6E6QebHDXPy))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# METHOD 1: override the default config with a dictionary\n",
    "my_args = {\"learning_rate\": 0.0234, \"batch_size\": 13, \"epochs\": 12}\n",
    "my_config = DefaultConfig(**my_args)\n",
    "# METHOD 2: override signle parameters\n",
    "my_new_conig = DefaultConfig(latent_dim=23, n_gpus=13)\n",
    "\n",
    "# METHOD 3: from a file:\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Use the Varix model\n",
    "Now we show how easy it is to use a variational autoencoder instead of a vanilla version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "[30, 16, 16, 16, 16]\n",
      "Epoch: 0, Loss: 896.4594078063965\n",
      "Epoch: 1, Loss: 883.8003387451172\n",
      "Epoch: 2, Loss: 869.7563400268555\n",
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from autoencodix.utils.default_config import DataCase\n",
    "import autoencodix as acx\n",
    "\n",
    "my_config = DefaultConfig(learning_rate=0.001, epochs=3, checkpoint_interval=1)\n",
    "my_config.data_case =DataCase.MULTI_BULK\n",
    "varix = acx.Varix(user_data=processed_data, config=my_config)\n",
    "result = varix.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_303', 'feature_259', 'feature_717', 'feature_127', 'feature_576', 'feature_960', 'feature_492', 'feature_581', 'feature_359', 'feature_781', 'feature_684', 'feature_49', 'feature_936', 'feature_638', 'feature_975', 'feature_406', 'feature_213', 'feature_417', 'feature_24', 'feature_103', 'feature_899', 'feature_799', 'feature_556', 'feature_528', 'feature_769', 'feature_586', 'feature_370', 'feature_958', 'feature_554', 'feature_289', 'feature_214', 'feature_390', 'feature_561', 'feature_268', 'feature_851', 'feature_692', 'feature_594', 'feature_912', 'feature_235', 'feature_555', 'feature_705', 'feature_662', 'feature_434', 'feature_433', 'feature_477', 'feature_656', 'feature_892', 'feature_805', 'feature_565', 'feature_458', 'feature_411', 'feature_430', 'feature_679', 'feature_786', 'feature_623', 'feature_384', 'feature_531', 'feature_690', 'feature_176', 'feature_50', 'feature_878', 'feature_393', 'feature_257', 'feature_192', 'feature_900', 'feature_143', 'feature_981', 'feature_695', 'feature_283', 'feature_720', 'feature_355', 'feature_323', 'feature_598', 'feature_816', 'feature_978', 'feature_324', 'feature_20', 'feature_693', 'feature_30', 'feature_605', 'feature_432', 'feature_78', 'feature_504', 'feature_475', 'feature_649', 'feature_171', 'feature_470', 'feature_858', 'feature_186', 'feature_538', 'feature_659', 'feature_449', 'feature_269', 'feature_46', 'feature_597', 'feature_680', 'feature_523', 'feature_280', 'feature_59', 'feature_95', 'feature_445', 'feature_270', 'feature_44', 'feature_812', 'feature_488', 'feature_397', 'feature_195', 'feature_913', 'feature_476', 'feature_939', 'feature_260', 'feature_534', 'feature_897', 'feature_275', 'feature_635', 'feature_567', 'feature_71', 'feature_669', 'feature_911', 'feature_537', 'feature_467', 'feature_463', 'feature_325', 'feature_893', 'feature_27', 'feature_644', 'feature_923', 'feature_562', 'feature_418', 'feature_971', 'feature_622', 'feature_955', 'feature_291', 'feature_110', 'feature_167', 'feature_642', 'feature_346', 'feature_527', 'feature_655', 'feature_919', 'feature_545', 'feature_879', 'feature_327', 'feature_404', 'feature_202', 'feature_817', 'feature_728', 'feature_549', 'feature_761', 'feature_402', 'feature_989', 'feature_203', 'feature_266', 'feature_671', 'feature_388', 'feature_156', 'feature_801', 'feature_3', 'feature_753', 'feature_246', 'feature_548', 'feature_489', 'feature_116', 'feature_473', 'feature_595', 'feature_496', 'feature_652', 'feature_366', 'feature_226', 'feature_421', 'feature_358', 'feature_317', 'feature_302', 'feature_273', 'feature_16', 'feature_340', 'feature_860', 'feature_450', 'feature_412', 'feature_60', 'feature_119', 'feature_339', 'feature_193', 'feature_546', 'feature_856', 'feature_824', 'feature_887', 'feature_922', 'feature_34', 'feature_378', 'feature_839', 'feature_386', 'feature_547', 'feature_698', 'feature_517', 'feature_178', 'feature_861', 'feature_914', 'feature_783', 'feature_374', 'feature_574', 'feature_414', 'feature_600', 'feature_776', 'feature_552', 'feature_231', 'feature_67', 'feature_661', 'feature_570', 'feature_139', 'feature_298', 'feature_963', 'feature_37', 'feature_396', 'feature_702', 'feature_566', 'feature_666', 'feature_42', 'feature_442', 'feature_392', 'feature_292', 'feature_212', 'feature_106', 'feature_760', 'feature_446', 'feature_187', 'feature_4', 'feature_58', 'feature_724', 'feature_514', 'feature_345', 'feature_54', 'feature_976', 'feature_651', 'feature_288', 'feature_967', 'feature_810', 'feature_505', 'feature_866', 'feature_441', 'feature_719', 'feature_947', 'feature_643', 'feature_48', 'feature_855', 'feature_928', 'feature_942', 'feature_903', 'feature_484', 'feature_838', 'feature_603', 'feature_204', 'feature_670', 'feature_993', 'feature_94', 'feature_28', 'feature_657', 'feature_904', 'feature_503', 'feature_875', 'feature_894', 'feature_877', 'feature_529', 'feature_150', 'feature_508', 'feature_314', 'feature_316', 'feature_668', 'feature_806', 'feature_222', 'feature_185', 'feature_870', 'feature_125', 'feature_584', 'feature_85', 'feature_865', 'feature_758', 'feature_348', 'feature_516', 'feature_891', 'feature_197', 'feature_312', 'feature_849', 'feature_194', 'feature_611', 'feature_329', 'feature_201', 'feature_381', 'feature_322', 'feature_188', 'feature_172', 'feature_72', 'feature_511', 'feature_699', 'feature_219', 'feature_435', 'feature_626', 'feature_13', 'feature_128', 'feature_707', 'feature_147', 'feature_465', 'feature_825', 'feature_553', 'feature_130', 'feature_696', 'feature_872', 'feature_915', 'feature_376', 'feature_862', 'feature_1', 'feature_497', 'feature_536', 'feature_454', 'feature_53', 'feature_803', 'feature_673', 'feature_573', 'feature_371', 'feature_770', 'feature_765', 'feature_82', 'feature_992', 'feature_515', 'feature_313', 'feature_885', 'feature_286', 'feature_158', 'feature_792', 'feature_934', 'feature_136', 'feature_375', 'feature_902', 'feature_18', 'feature_779', 'feature_263', 'feature_592', 'feature_564', 'feature_126', 'feature_398', 'feature_798', 'feature_121', 'feature_557', 'feature_645', 'feature_362', 'feature_498', 'feature_407', 'feature_336', 'feature_423', 'feature_168', 'feature_408', 'feature_175', 'feature_632', 'feature_41', 'feature_383', 'feature_568', 'feature_762', 'feature_701', 'feature_944', 'feature_436', 'feature_558', 'feature_906', 'feature_535', 'feature_363', 'feature_109', 'feature_76', 'feature_137', 'feature_108', 'feature_634', 'feature_938', 'feature_206', 'feature_360', 'feature_490', 'feature_845', 'feature_290', 'feature_509', 'feature_311', 'feature_177', 'feature_274', 'feature_633', 'feature_811', 'feature_161', 'feature_744', 'feature_162', 'feature_711', 'feature_815', 'feature_519', 'feature_252', 'feature_21', 'feature_102', 'feature_306', 'feature_17', 'feature_676', 'feature_637', 'feature_144', 'feature_540', 'feature_521', 'feature_84', 'feature_279', 'feature_525', 'feature_491', 'feature_238', 'feature_347', 'feature_880', 'feature_927', 'feature_830', 'feature_217', 'feature_895', 'feature_721', 'feature_756', 'feature_31', 'feature_951', 'feature_766', 'feature_277', 'feature_617', 'feature_937', 'feature_426', 'feature_25', 'feature_342', 'feature_768', 'feature_620', 'feature_155', 'feature_757', 'feature_170', 'feature_990', 'feature_210', 'feature_785', 'feature_12', 'feature_613', 'feature_888', 'feature_115', 'feature_713', 'feature_453', 'feature_729', 'feature_961', 'feature_468', 'feature_767', 'feature_741', 'feature_182', 'feature_871', 'feature_790', 'feature_867', 'feature_138', 'feature_318', 'feature_625', 'feature_249', 'feature_973', 'feature_968', 'feature_373', 'feature_795', 'feature_123', 'feature_479', 'feature_550', 'feature_22', 'feature_343', 'feature_607', 'feature_569', 'feature_11', 'feature_725', 'feature_236', 'feature_588', 'feature_276', 'feature_166', 'feature_956', 'feature_575', 'feature_320', 'feature_141', 'feature_828', 'feature_847', 'feature_848', 'feature_52', 'feature_965', 'feature_730', 'feature_369', 'feature_988', 'feature_223', 'feature_709', 'feature_639', 'feature_287', 'feature_631', 'feature_122', 'feature_579', 'feature_940', 'feature_451', 'feature_427', 'feature_850', 'feature_559', 'feature_149', 'feature_495', 'feature_983', 'feature_196', 'feature_75', 'feature_954', 'feature_763', 'feature_301', 'feature_926', 'feature_833', 'feature_431', 'feature_788', 'feature_881', 'feature_382', 'feature_630', 'feature_485', 'feature_994', 'feature_952', 'feature_183', 'feature_718', 'feature_403', 'feature_92', 'feature_159', 'feature_349', 'feature_986', 'feature_780', 'feature_832', 'feature_577', 'feature_299', 'feature_278', 'feature_232', 'feature_723', 'feature_930', 'feature_530', 'feature_708', 'feature_793', 'feature_70', 'feature_715', 'feature_0', 'feature_771', 'feature_950', 'feature_654', 'feature_305', 'feature_97', 'feature_47', 'feature_200', 'feature_234', 'feature_953', 'feature_448', 'feature_998', 'feature_174', 'feature_319', 'feature_593', 'feature_691', 'feature_104', 'feature_982', 'feature_653', 'feature_612', 'feature_456', 'feature_660', 'feature_840', 'feature_416', 'feature_460', 'feature_154', 'feature_364', 'feature_599', 'feature_640', 'feature_641', 'feature_859', 'feature_199', 'feature_294', 'feature_712', 'feature_469', 'feature_394', 'feature_215', 'feature_890', 'feature_35', 'feature_740', 'feature_45', 'feature_560', 'feature_438', 'feature_399', 'feature_455', 'feature_797', 'feature_2', 'feature_61', 'feature_629', 'feature_800', 'feature_710', 'feature_901', 'feature_478', 'feature_977', 'feature_230', 'feature_265', 'feature_98', 'feature_969', 'feature_142', 'feature_610', 'feature_66', 'feature_837', 'feature_802', 'feature_36', 'feature_134', 'feature_853', 'feature_487', 'feature_501', 'feature_29', 'feature_242', 'feature_909', 'feature_241', 'feature_419', 'feature_754', 'feature_191', 'feature_685', 'feature_437', 'feature_65', 'feature_105', 'feature_738', 'feature_117', 'feature_88', 'feature_544', 'feature_282', 'feature_687', 'feature_63', 'feature_571', 'feature_589', 'feature_884', 'feature_864', 'feature_745', 'feature_945', 'feature_751', 'feature_921', 'feature_827', 'feature_500', 'feature_300', 'feature_253', 'feature_308', 'feature_310', 'feature_602', 'feature_551', 'feature_935', 'feature_101', 'feature_658', 'feature_466', 'feature_132', 'feature_474', 'feature_145', 'feature_619', 'feature_237', 'feature_264', 'feature_444', 'feature_457', 'feature_481', 'feature_328', 'feature_835', 'feature_113', 'feature_247', 'feature_8', 'feature_694', 'feature_69', 'feature_991', 'feature_387', 'feature_941', 'feature_886', 'feature_854', 'feature_281', 'feature_999', 'feature_714', 'feature_608', 'feature_23', 'feature_227', 'feature_809', 'feature_834', 'feature_335', 'feature_367', 'feature_216', 'feature_857', 'feature_228', 'feature_86', 'feature_326', 'feature_140', 'feature_368', 'feature_285', 'feature_62', 'feature_974', 'feature_541', 'feature_271', 'feature_133', 'feature_163', 'feature_74', 'feature_220', 'feature_480', 'feature_124', 'feature_842', 'feature_777', 'feature_353', 'feature_107', 'feature_334', 'feature_997', 'feature_129', 'feature_742', 'feature_678', 'feature_733', 'feature_582', 'feature_337', 'feature_100', 'feature_405', 'feature_578', 'feature_946', 'feature_284', 'feature_462', 'feature_391']\n",
      "DataCase.MULTI_BULK\n"
     ]
    }
   ],
   "source": [
    "print(result.datasets.train.feature_ids)\n",
    "print(my_config.data_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine Variational result\n",
    "Here, we have more info in our results object than in the Vanillix case. We have the learned paramters mu and logvar of the normal distirbution, in addition to the losses and reconstructions. We provide also the sampled latentspaces at each epoch and split.\n",
    "\n",
    "You can resample new latenspaces (shown in next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 201, 16)\n"
     ]
    }
   ],
   "source": [
    "# we did not train for the test split, so we don't need to pass an epoch\n",
    "# technically the epoch is -1\n",
    "mu_test_ep_last = result.latentspaces.get(split=\"test\")\n",
    "print(mu_test_ep_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different loss types\n",
    "For our variation autoencoder, the total loss consists of a reconstruction loss and a distribution loss i.e. kl-divergence. To investigate these losses, the result_obj has the attribute `sub_losses`. This is a `LossRegistry` withe the name of the loss as key and the value is of class `TrainingDynamics` and can be accessed as shown for the Vanillix part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: dict_keys(['recon_loss', 'var_loss'])\n",
      "[40.71245367 40.13542921 39.49522296]\n"
     ]
    }
   ],
   "source": [
    "sub_losses = result.sub_losses\n",
    "print(f\"keys: {sub_losses.keys()}\")\n",
    "recon_dyn = sub_losses.get(key=\"recon_loss\")\n",
    "print(recon_dyn.get(split=\"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample new latentspaces\n",
    "You might want to use the trained model and the fitted parameters mu, and logvar to sample latentspaces. Therefore, the Varix pipeline has the additional method `sample_latent_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3815,  0.0605,  0.0737, -0.5899,  0.9586, -0.5613,  0.6648,  0.6568,\n",
      "          0.5968,  2.1347, -1.2397, -1.3647, -0.8332,  1.4871, -1.2338, -0.2871],\n",
      "        [-0.8745, -1.8087, -1.1001, -2.1044, -0.4924,  0.0313, -1.0118,  1.0175,\n",
      "         -0.9504,  1.5237,  1.4555,  0.6733, -0.3959,  1.3795, -2.0161,  1.1900],\n",
      "        [ 1.1961, -0.4509,  0.0881,  0.0250, -0.7878,  0.3866, -0.5984,  1.3542,\n",
      "          0.5217, -0.9234,  0.0960, -0.1184,  3.1499,  0.0853, -1.4222,  1.2531],\n",
      "        [ 0.0435,  1.8601,  2.3153,  0.8313,  1.7955, -0.2479, -1.0111,  0.3796,\n",
      "          1.6390,  0.9053, -0.9798,  1.2234,  0.3115, -0.5283,  2.2437, -1.6342],\n",
      "        [ 0.9065,  0.7891, -0.6991,  0.8421, -0.9909, -0.9001,  1.1103, -0.8292,\n",
      "         -1.2215, -0.4107, -0.5272, -0.3176,  1.5901,  1.7986, -0.0936,  1.4206]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "sampled = varix.sample_latent_space()\n",
    "\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5700,  0.8758,  0.9141, -0.6604,  1.0592, -0.4484,  1.9340,  0.8800,\n",
      "          0.1392,  1.5425,  1.1866,  1.1662,  0.7115,  0.0068,  3.0569,  0.4558],\n",
      "        [ 0.2120,  0.9299, -1.6927,  1.0529,  2.0094, -1.5707, -0.1146, -0.8113,\n",
      "          0.4337,  1.3734,  0.0598,  4.8622,  2.5011,  2.2839,  0.2209,  1.0999],\n",
      "        [ 1.3187,  2.6637,  1.3148, -0.8652, -2.2424,  2.1532,  0.5025,  2.2731,\n",
      "          0.2291,  0.1469,  1.2588,  0.0867,  0.8309, -0.2264, -0.9445,  0.0722],\n",
      "        [-0.9690,  2.0278, -0.8018, -0.8929,  0.9704,  0.5589,  1.1102,  2.9140,\n",
      "          0.7758,  1.0506,  1.0099, -0.6375, -1.2596,  1.4819,  0.6696,  1.2880],\n",
      "        [ 0.3513, -0.4607, -1.4169, -0.3616,  0.5239, -0.1536, -2.5674,  0.4172,\n",
      "          1.4041,  1.1064, -0.2263,  1.1523, -0.2858,  1.2119, -1.6832, -0.7073]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# you can also select a specific epoch and split to sample from (default is last epoch and test split)\n",
    "sampled = varix.sample_latent_space(epoch=2, split=\"valid\")\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1316,  0.8674,  1.0452],\n",
      "        [ 0.9337,  0.0566,  0.4687],\n",
      "        [ 1.0547, -0.8719,  0.1045]], device='mps:0')\n",
      "tensor([[ 0.4005,  0.2328,  0.7930],\n",
      "        [ 0.3041,  0.0535, -0.4952],\n",
      "        [-0.4317,  0.3115, -1.7468]], device='mps:0')\n",
      "tensor([[ 2.1802, -1.3408,  0.7844],\n",
      "        [ 0.2504, -0.8375, -0.5194],\n",
      "        [ 1.3116,  0.4400, -1.6655]], device='mps:0')\n",
      "tensor([[ 1.8349,  1.8234, -0.7378],\n",
      "        [ 2.4539,  1.4715,  2.5609],\n",
      "        [ 1.8668,  1.6702,  0.3699]], device='mps:0')\n",
      "tensor([[ 0.2679, -0.9179,  0.5593],\n",
      "        [-0.2163, -0.2724,  1.6587],\n",
      "        [ 1.4239, -0.3327, -1.4850]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# or sample multiple times\n",
    "for _ in range(5):\n",
    "    sampled = varix.sample_latent_space()\n",
    "    print(sampled[:3, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Work with your own data\n",
    "In the above steps we showed how to use `Autoencodix` with mock data. Nowe we demonstrate how to use real-world data. There are three main use cases:\n",
    "1. Use data from raw files and define the path and metainfo via the config (file or DefaultConfig class).\n",
    "2. Provide the raw data directly in Python and pass it to our `DataPackage` structure. This `DataPackage` then can be passed to to our Pipeline where it will pre preprocessed.\n",
    "3. Take care of the preprocessing yourself and pass the `DatasetContainer` to our pipeline. We show how to fill this `DatasetContainer` object with your preprocsedded data.\n",
    "\n",
    "### 04.1 Working with data from files\n",
    "Here we specialize on different kind of omics data. We cover:\n",
    "1. combining multi-omics data from bulk sequencing (e.g. mRNA and methylation).\n",
    "2. combining multi-omics data from single cell sequencing.\n",
    "3. \"Translating\" between multi-omics data e.g. scRNA <-> scATAC, or bulkmRNA <-> bulkmiRNA\n",
    "4. Working with image data\n",
    "5. \"translating\" between data-modalities\n",
    "  - one bulk-omics modality to another\n",
    "  - omics to image an vice versa\n",
    "\n",
    "#### 04.1.1 Combining mulit-omics data from bulk-sequencing\n",
    "First we need to prepare our config object. We can (a) directly provide an object in python, or (b) provide an YAML file. We show both\n",
    "\n",
    "##### YAML config\n",
    "Assume we have the file in `./config.yaml`.\n",
    "We can keep the yaml file structure to define our input data like:\n",
    "```yaml\n",
    "data_config: # has to be named data_config\n",
    "  data_info: # has to be named data_infor\n",
    "   RNA: # name can be chosen by user\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   METHYLATION: # can be chosen by user\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   CLINICAL: # can be chosen by user\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\" # default NUMERIC (as for RNA and METHYLATION)\n",
    "```\n",
    "ATTENTION:\n",
    "If you use `.txt` or `.csv` files, it is best practice to add the `sep` parameter. If none is given, the reader will try to auto-detect the separator, which is error prone.\n",
    "This would loke like:\n",
    "```YAML\n",
    "    RNA:\n",
    "      ...\n",
    "      sep: \"\\t\" # for tab, \";\" or \",\" would be also possible (as in pandas)\n",
    "\n",
    "```\n",
    "**IMPORTANT**\n",
    "\n",
    "For all your bulk data files, we expect the first column to be some kind of unique sample id. Please prepare the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# this fills the data_config attribute of the DefaultConfig object\n",
    "# we can also change the default values in the config.yaml file\n",
    "# or via the DefaultConfig object\n",
    "bulk_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text())\n",
    ")\n",
    "# this bulk_config object can then be passed to a Pipeline (Varix, Vanillix, etc)\n",
    "var_bulk = acx.Varix(config=bulk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "WARNING: df is too small for filtering, needs to have at least 10\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (7, 16313)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "WARNING: df is too small for filtering, needs to have at least 10\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (7, 9228)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (1, 16313)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (1, 9228)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (2, 16313)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (2, 9228)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': multi_bulk:\n",
      "  RNA: 7 samples × 16313 features\n",
      "  METHYLATION: 7 samples × 9228 features\n",
      "annotation:\n",
      "  paired: 7 samples × 54 features, 'indices': {'paired': {'train': array([0, 4, 8, 6, 1, 3, 7])}}}, 'valid': {'data': multi_bulk:\n",
      "  RNA: 1 samples × 16313 features\n",
      "  METHYLATION: 1 samples × 9228 features\n",
      "annotation:\n",
      "  paired: 1 samples × 54 features, 'indices': {'paired': {'valid': array([5])}}}, 'test': {'data': multi_bulk:\n",
      "  RNA: 2 samples × 16313 features\n",
      "  METHYLATION: 2 samples × 9228 features\n",
      "annotation:\n",
      "  paired: 2 samples × 54 features, 'indices': {'paired': {'test': array([2, 9])}}}}\n",
      "cpu not relevant here\n",
      "[25541, 6385, 1596, 399, 16]\n",
      "Epoch: 0, Loss: 1.2789504528045654\n",
      "Epoch: 1, Loss: 1.705719232559204\n",
      "Epoch: 2, Loss: 1.50313401222229\n",
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "result = var_bulk.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overwrite or add values to our config from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with custom values\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create DataConfig in Python\n",
    "Instead of reading the config from the file, we can also create it directly in Ptyon\n",
    "We will only use one way of config creation for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "root_dir = os.path.join(\"data/raw\")\n",
    "meth_file = \"data_methylation_per_gene_formatted.parquet\"\n",
    "mrna_file = \"data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "clin_file = \"data_clinical_formatted.parquet\"\n",
    "\n",
    "bulk_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"RNA\": DataInfo(file_path=os.path.join(root_dir, mrna_file)),\n",
    "            \"METHYLATION\": DataInfo(file_path=os.path.join(root_dir, meth_file)),\n",
    "            \"CLINICAL\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, clin_file), data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.2 Working with single cell data from different sequencing processes\n",
    "First we define our config again, then we use the reader object to build the MuData object (this will look more familar for single cell practioners)\n",
    "\n",
    "We can provide a config yaml like:\n",
    "```yaml\n",
    "# config.yaml\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\" # we request h5ad files\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "scconfig = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/largesc.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DefaultConfig Configuration Parameters:\n",
      "--------------------------------------------------\n",
      "\n",
      "data_config:\n",
      "  Type: <class 'autoencodix.utils.default_config.DataConfig'>\n",
      "  Default: data_info={} require_common_cells=False annotation_columns=None\n",
      "  Description: No description available\n",
      "\n",
      "paired_translation:\n",
      "  Type: typing.Optional[bool]\n",
      "  Default: PydanticUndefined\n",
      "  Description: Indicator if the samples for the xmodalix are paired, based on some sample id\n",
      "\n",
      "data_case:\n",
      "  Type: typing.Optional[autoencodix.utils.default_config.DataCase]\n",
      "  Default: PydanticUndefined\n",
      "  Description: Data case for the model, will be determined automatically\n",
      "\n",
      "latent_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 16\n",
      "  Description: Dimension of the latent space\n",
      "\n",
      "n_layers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of layers in encoder/decoder, without latent layer. If 0, is only the latent layer.\n",
      "\n",
      "enc_factor:\n",
      "  Type: <class 'int'>\n",
      "  Default: 4\n",
      "  Description: Scaling factor for encoder dimensions\n",
      "\n",
      "input_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 10000\n",
      "  Description: Input dimension\n",
      "\n",
      "drop_p:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Dropout probability\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "default_vae_loss:\n",
      "  Type: typing.Literal['kl', 'mmd']\n",
      "  Default: kl\n",
      "  Description: Type of VAE loss\n",
      "\n",
      "loss_reduction:\n",
      "  Type: typing.Literal['sum', 'mean']\n",
      "  Default: mean\n",
      "  Description: Loss reduction in PyTorch i.e in torch.nn.functional.binary_cross_entropy_with_logits(reduction=loss_reduction)\n",
      "\n",
      "beta:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Beta weighting factor for VAE loss\n",
      "\n",
      "min_samples_per_split:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Minimum number of samples per split\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "float_precision:\n",
      "  Type: typing.Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16']\n",
      "  Default: 32\n",
      "  Description: Floating point precision\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "train_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.7\n",
      "  Description: Ratio of data for training\n",
      "\n",
      "test_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.2\n",
      "  Description: Ratio of data for testing\n",
      "\n",
      "valid_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Ratio of data for validation\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "scconfig.print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:449: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common cells: 4554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:283: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"n_cells\"] = number\n",
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:283: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"n_cells\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape after filtering: (3187, 100)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (3187, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (3187, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (3187, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (3187, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (3187, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (3187, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (456, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (456, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (456, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (456, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (456, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (911, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (911, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (911, 100)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (911, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (911, 20)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': multi_sc: 3187 samples × 18018 features, 'indices': {'paired': {'train': array([2792,  189,  208, ..., 1193, 3542, 1077])}}}, 'valid': {'data': multi_sc: 456 samples × 18018 features, 'indices': {'paired': {'valid': array([1444, 3945, 1139, 2875, 1288,   53, 1198, 2789,  669,  519, 1036,\n",
      "       3174, 4291, 3538, 4036, 1846, 3103, 2865, 3989,  845,  209,  727,\n",
      "       3200, 3591, 1269, 3657, 3871, 2669, 2928, 2756,  195, 3524, 3557,\n",
      "       2187,  599, 3425,  738, 3892,  896, 1200, 2131,  963, 2597, 2619,\n",
      "       3632, 3886, 1365,  473, 1723, 2403, 3300, 2468, 1904,   20, 3597,\n",
      "       4518, 4327, 3669,  110, 1593, 2477,  327,  477,  526, 1943, 3555,\n",
      "        240,   51, 2297,  814, 2022, 2459, 2696, 1743, 4516, 2326,   30,\n",
      "       3918, 3127, 2638,  726,   22, 4394, 1843,  633, 4330, 1677, 3977,\n",
      "       3835, 2415,  105, 1085, 3837, 2676, 1486, 3196, 1751, 1405,  487,\n",
      "       3144, 3904,  822, 2200, 2763, 1945,  411,  244, 3063,  406, 2123,\n",
      "       1527, 4001, 1313, 2830, 4182, 4035,  511, 3622,  886, 3073,  202,\n",
      "       2134, 1651, 1801, 3281,  629, 2496, 4146,  124, 1496, 1590, 4398,\n",
      "       2986, 1332,   63,  131,  554, 1207, 3553, 4077, 1392, 3231, 3723,\n",
      "       3378, 1106, 4234, 3448, 4097,  853, 3111,  515, 2031, 4262, 2551,\n",
      "       3297, 4386, 2736,  623, 3400, 4037, 3700,   83, 3391,  919, 1634,\n",
      "       3787,  579, 1890, 2212, 1466, 3683, 3939, 1915, 2705,  488, 3327,\n",
      "        612, 4552, 2339, 1481, 2220, 2882, 1913, 4391,  163,  229, 2362,\n",
      "       1898, 1270, 3621, 3727, 1852,  647,  713, 3733, 3496, 1172, 3932,\n",
      "        723, 3681, 4306, 2363, 3081, 3386, 3943, 4060, 4318,  722,  536,\n",
      "       3265, 3109, 2766,  234, 2135,  388, 1856, 1239,  412, 2128, 2601,\n",
      "       2208, 1675, 2931, 3208,  995, 4002, 1475,  353, 3635, 2434, 3974,\n",
      "       1933, 2167, 2142, 2898,  683, 1210,  539,  451,   72, 3406, 1901,\n",
      "       3043, 2999,  387, 3114, 4381, 1471, 1758, 1871,   73, 1137, 1799,\n",
      "       1120, 2609, 1604, 2452,  265, 3217,  805, 2997, 1389, 3728, 1894,\n",
      "       1815, 4495, 1625, 4112,  875, 2249, 4443, 2922,  549, 1504, 1133,\n",
      "        548, 1104, 3537,  781, 1694, 3193,  767,  690, 1280, 2716, 4104,\n",
      "       2258, 2650, 4363,   92, 3011,  672,  576,  228, 2940,  241,  903,\n",
      "       4549, 4385, 1121, 3299,  715, 2977, 2357, 3808,  547, 3623, 3098,\n",
      "       3905,  432, 4320, 3218, 2721, 3489, 3026,  638, 1345, 1467,  807,\n",
      "       3834,  815, 1941,  922, 3211,  741,  399, 3014, 2912, 3933, 1541,\n",
      "       1536, 1089,  869,  476, 3056,  421, 3040, 1022, 4422,  616, 2737,\n",
      "       2588, 2915, 3796,   88, 2724, 3776, 2472,  499, 3596,   74, 1673,\n",
      "       2950, 2340,  615, 3870, 1792, 3872, 2061, 3080, 3142, 3359, 1096,\n",
      "       3600, 3691, 2552, 3987, 2817,  328, 4225, 2591,  159, 1706, 4379,\n",
      "       3928, 3722,  249, 1570, 1261, 1214, 4199, 2776,  759, 2197, 1045,\n",
      "        721, 2995, 2464, 1664, 1956, 1219,  847, 4281, 1905,  590, 2166,\n",
      "        459, 1805, 3822, 2924, 1629, 2844, 1921,  867, 2550, 1327, 2462,\n",
      "       1711, 4236, 3375,  496,  750, 4517, 4420, 2944,  857, 4550, 3909,\n",
      "       3767, 2303, 1763,  569, 3101, 4164,  691, 3880,  402,   29, 2845,\n",
      "       1340, 4048,  373, 1551, 4419, 1319, 1421,  879, 3674,  885, 3499,\n",
      "       3472,  273, 4530, 1498, 3258,  439, 3514, 1930, 2747,  334, 2075,\n",
      "       2761, 1005, 2876, 2420, 2503])}}}, 'test': {'data': multi_sc: 911 samples × 18018 features, 'indices': {'paired': {'test': array([1615,  133, 3459, 1768,   21, 3376, 3513, 2949, 2811, 4106, 1375,\n",
      "       2535, 2298, 2334,   62, 2471,  899, 2498, 2301, 1217, 2679, 4242,\n",
      "       2785, 3150, 3343, 2018, 2577,  795, 1535, 2000,  779, 1329, 4445,\n",
      "       1772, 1413, 4384,  607, 4179, 1098, 1523, 3720, 1721, 3778, 3269,\n",
      "       1610, 3953, 1050, 3662, 3030, 1630, 1043,  700,  574, 1497, 3958,\n",
      "       3128,  343,  756, 2927, 3312,  563, 1169,  555, 4423, 1559, 3699,\n",
      "       4367, 2738, 4015, 3074,  960,  494, 2611, 1771, 1735, 1548, 1827,\n",
      "       3037, 3774, 2506,  324, 3506, 2102, 2651, 2972,  136, 2323, 3052,\n",
      "       3647, 1875,  285, 2902,  745, 2820, 1406, 1061, 2313, 3025, 1233,\n",
      "        771,   44, 3436, 2268, 3362, 3949, 3019,   98, 3875,   90, 1128,\n",
      "       2480, 3091, 4350, 2517,  157,  299, 2682, 1501, 1560, 1808, 4335,\n",
      "        636, 4339,  870, 1865, 2011,  921, 2878, 1078, 3589, 3483, 4528,\n",
      "       3285, 1686, 1176, 4153,  573, 4144, 4451, 1781, 4321,  359, 4092,\n",
      "        988, 1814, 4117, 4100, 1113,  219, 2027, 1141,  957, 3176, 2158,\n",
      "       3331,  102, 2098, 1641, 4551, 4522,  941, 3970,  836, 1822, 3041,\n",
      "        222, 3411, 2240, 1787, 3765,   82, 3108, 4178, 4315, 3625, 3023,\n",
      "       1528, 4509,  553, 4282, 4336, 2374, 2527, 2583, 1973, 3444, 1851,\n",
      "       3711,  349, 2911, 4483, 2969, 3245,  552,  959, 1351, 2753, 4254,\n",
      "       4012, 2569, 2814, 2448,  366,  846, 3403, 4168, 1291, 3219, 4221,\n",
      "       3276, 3704, 1403, 2558, 2308,  592,  330, 2966,  993,   40, 1237,\n",
      "        854, 4484, 4139, 4513, 1666, 1832, 4054, 3018, 3490,  808, 3571,\n",
      "        447, 1683, 3116,  932,  200, 2708, 2174,  372, 2786,  190, 4410,\n",
      "       2860, 1060, 1117,  534, 3295, 2717, 3207, 2259, 2831, 3664,   17,\n",
      "        161, 1648,  331, 3552, 3227, 4271, 1381,  758,  566,  685, 2727,\n",
      "       1410, 4538, 1206, 1550, 2404, 2132, 3494, 3862, 1742, 3921, 2146,\n",
      "       1235,   94, 4489,  998, 2740,   32, 4400, 3417, 2968, 1268, 3785,\n",
      "       2668, 1736, 4088, 4329,  407, 1946, 1162,  394, 2379, 2991, 3840,\n",
      "       1960, 1355, 2725, 3736, 1745, 2473,  748, 3969,   99, 1499, 2423,\n",
      "       4019, 4523, 1919, 2139, 1650, 4337, 3924, 1094, 2424, 2225,  230,\n",
      "       2408, 2644, 3003, 2973, 2854, 2204, 1155, 1796, 3715, 2328, 2276,\n",
      "        134, 4292, 3731, 1916, 1123, 1409, 2617, 3451, 4061, 3350,  678,\n",
      "       2595, 2294, 1586, 3326, 2188, 2458,   28, 4389,  608, 4365, 2703,\n",
      "       4156, 1049, 1962, 2680, 4046, 1938, 3577, 1624, 2894, 2330, 3982,\n",
      "        943, 1272, 1653,  123, 3389, 3155, 4328, 1836, 3409, 3895,  329,\n",
      "       4322, 4033, 2910,  544, 2079,  107, 4469,  100, 3560,  120, 2494,\n",
      "       3740,  364, 4295,  987,  108, 1810, 3398, 3124, 3344, 2501, 3256,\n",
      "       3279, 3388, 4243, 3730, 4124, 1453, 4172, 3253, 1238, 1587, 2015,\n",
      "       4338, 4191, 3534,  188, 2605, 1044, 2114, 1246, 2867,  893, 2321,\n",
      "       2105, 2739, 3725, 3960, 3650,  115, 2101, 4414, 3232, 2463, 3588,\n",
      "       4073, 3781, 1395,  301, 3275, 1508, 1922,  910, 4128, 3458, 1333,\n",
      "       3165, 1296,  931, 2896, 1524, 2851, 4403, 3825, 2185, 3887, 3387,\n",
      "       2816, 4541,   13, 1520, 2731, 4462, 1227,  761,  128, 1447, 3859,\n",
      "        560, 3404, 2586, 4369, 3649, 1008,  236, 1687, 1564, 3328,  763,\n",
      "       1690, 3694, 4219, 4397, 3366, 1195, 4294, 2118,  205, 2684, 3721,\n",
      "       1674,  420,  785,  965, 1432, 2333,  718, 1328, 1680, 4049, 3134,\n",
      "       3573, 2513,  662,  486,  280,  778, 3679,  196,  418, 3505, 1417,\n",
      "       3421, 2883, 1030,  589, 1399, 1833, 3405, 1863, 3440,  457, 2107,\n",
      "       4533, 4218, 1859,  644, 2781, 2012, 4031, 4352,  684, 2672, 3385,\n",
      "       4288,  453, 4246, 4323, 4424, 3540, 2157, 2965, 1419, 2534, 1939,\n",
      "       4125,  518, 1995,  749, 3549, 3283,  703,  368,  804, 3603, 2005,\n",
      "       2662,   45, 4405,  792, 3507, 3244, 1156,  216, 4382, 2793,  840,\n",
      "       1727,  729,  953, 3856,  610,  772, 3504, 1603, 2971,  111, 1380,\n",
      "       3565, 1783, 1928,   58, 1063, 3420,  784,  645, 1334,  275,    1,\n",
      "       2256, 3919, 3154,  210, 2245, 3392,  438, 1159, 2926, 3123, 1614,\n",
      "       3192, 3510,  191, 3337, 4269,  823, 3035, 1177, 2179, 3620, 4175,\n",
      "       4465, 3076,  385, 1042, 4209, 2921, 3330, 1147,  587, 3307, 2104,\n",
      "       1080, 2443, 3476,  306, 4226, 2338, 2511, 1534, 1081, 2358, 4206,\n",
      "       1773, 1903,  126, 4150, 2456, 4140, 3473, 1441, 2706, 1448, 2008,\n",
      "       3626, 3178, 4274, 2936, 1579, 3456, 3578, 1297,  290, 3527, 1845,\n",
      "        787, 1232, 2013, 1185, 1882, 1016, 2932, 3677, 3745,  650, 3087,\n",
      "        769, 1562, 2115, 1785, 3735, 1729, 2213, 2930,  345, 2217,  881,\n",
      "       1635,  557, 1216, 2359, 3332, 3686, 2227, 4216, 3702, 2318, 4480,\n",
      "       2872, 3566, 2320,  268, 3471, 2295, 1507, 3495, 1352, 2016,  724,\n",
      "       1456, 4099, 2017, 3293, 1299,  695, 2937,  181, 1143, 3884, 3839,\n",
      "        313,  501,  443, 1064, 1540,   12,  895, 2068, 3160, 3879, 1230,\n",
      "       3248, 1848, 2378, 2838,  495, 3709,  906, 2361, 1672, 2299, 4376,\n",
      "       2778, 4303, 2048, 2750, 1715, 2479, 1953, 3313, 1584, 4241, 3162,\n",
      "       3262, 2352,  632,  577, 3306, 4095, 4543, 2349, 2038, 1542, 4325,\n",
      "       2537, 2576, 4198, 2800,  909, 3301, 1881,  524, 3749, 4399, 4383,\n",
      "       4113, 3906, 3429, 1248, 2150, 1710, 3948, 2165, 1918,  292, 4395,\n",
      "        561,  556, 3532, 3758,   93,  671, 1900,  661, 1884,   37, 1563,\n",
      "       3092, 1914,  393, 4237, 2242, 1414, 3215,  657, 1213, 3831,  874,\n",
      "       4200,  187, 4333, 3611,  891,  389, 4194, 2984, 3257, 3466,  256,\n",
      "       4020, 1342,    6, 4545, 1749, 3485, 1253, 2556,   79,  224, 4158,\n",
      "        613, 2942,  203, 1929, 2653, 4161, 2610,   19, 2182, 1684, 1273,\n",
      "       1850, 2311, 4361, 2124, 3054, 2136, 3881,  314, 1225,  834, 1020,\n",
      "       1281, 2040, 3684, 3084, 3357, 4203, 3900, 2155, 4258, 2133, 4157,\n",
      "       1011, 3653, 1247, 1891, 3271,  464,  913, 2284, 1637,  794, 1379,\n",
      "       1344,  231, 2159,  940, 2698, 4006, 2712, 4072,  119, 4080, 3189,\n",
      "       2606, 3741,  799, 3220, 2327, 3249, 2289, 1021,  791, 3911, 1140,\n",
      "       1004, 2861, 4378,  773,  325, 4170, 4252, 2687, 4021, 3645,  201,\n",
      "       3093, 1959, 1926,  342, 3502, 2663,  416, 2514, 4425,  796, 2226,\n",
      "       4034, 4310, 3254, 3829, 3323, 3336,  338, 2621, 2544])}}}}\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 59.344881147146225\n",
      "Epoch: 1, Loss: 44.438254445791245\n",
      "Epoch: 2, Loss: 41.202704668045044\n",
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "import autoencodix as acx\n",
    "sc_van = acx.Vanillix(config=scconfig)\n",
    "result = sc_van.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can pass the `scconfig` to our Pipeline as shown with the bulk example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.3 Translating between omics data\n",
    "We only allow bulk to bulk and single-cell to single cell. The config is almost identical to the case before, we only add the direction of the translation like:\n",
    "```YAML\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "     translate_direction: \"FROM\"\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     translate_direction: \"TO\"\n",
    "\n",
    "```\n",
    "\n",
    "For the bulk case we can keep annotation data without including it in the translation like:\n",
    "```YAML\n",
    "# config.yaml\n",
    "data_config:\n",
    "  data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"FROM\"\n",
    "   METHYLATION:\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"TO\"\n",
    "   CLINICAL:\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\"\n",
    "     # default translate_direction is  NONE, so we don't need to specify it here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.4 Working with images\n",
    "When working with images, we need have two cases:\n",
    "- pure image, without translating\n",
    "- translating between omics and images\n",
    "\n",
    "In the first case we need to provide the folder path of the images. In the second case we need to provide the folder path of the images and an annotation file that maps the metadata for the images to the image filenames. In this file we also need to map the sample_ids of the other data modality to the image filename and metadata. Later we will add support for an unpaired case, where we only provide image metadata without mapping to the other data modality.\n",
    "The file should look like this:\n",
    "**important**: this file needs to contain the columns `sample_ids` and `img_paths`\n",
    "```text\n",
    "sample_ids\timg_paths\tMETADATA1\tMETADATA2\n",
    "TCGA-05-4244-01\t0_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4249-01\t1_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4250-01\t2_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4382-01\t3_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4384-01\t4_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4389-01\t5_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4390-01\t6_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4395-01\t7_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4396-01\t8_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image only case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/default_config.py:389: UserWarning: Could not determine data_case: No numeric datasets found in data_info\n",
      "  warnings.warn(f\"Could not determine data_case: {str(e)}\")\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(file_path=\"data/raw/images/tcga_fake\", data_type=\"IMG\"),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\", data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Images and omics data\n",
    "If you want to translate between image and another data modality you need to provide the same files as above. For the Annotation files you have two possibilities: (a) you provide one annotation file (as shown above), in this file you match the metadata of the two data modalites, by an shared sample_id / mapping of sample_id and image_path and other metadata. (b) you can have supply an extra annotation file for the images with the attribute `img_anno_file`. If None is given, we will use the shared file. This is only allowed for unpaired translation.\n",
    "So for the unpaired translation the `DataConfig` should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_imgreader.py:192: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  annotation = pd.read_csv(anno_file, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading annotation file: data/raw/tcga_mappings.txt\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "\n",
    "imgreader = ImageDataReader()\n",
    "imgdata = imgreader.read_data(config=img_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['IMG'])\n",
      "Number of images: 3204\n"
     ]
    }
   ],
   "source": [
    "print(imgdata.keys())\n",
    "print(f\"Number of images: {len(imgdata['IMG'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unpaired case\n",
    "This case is not implemented in the old version of `autoencodix` and will be added after the other translating features, we still show how the config can look like:\n",
    "```python\n",
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake.txt\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\"\n",
    "                extra_anno_file=\"path/to/file\"\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\"\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data_clinical_formatted.parquet\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1 How to use raw data \n",
    "If you don't want to provide files via config, you can create a DataPackage directly in Python. First you need to decide what kind of data you use. We currently support the following cases:\n",
    "- Multi-Bulk (or any other numeric data)\n",
    "- Multi-SingleCell (or standard Single Cell)\n",
    "- Bulk-to-Bulk translation\n",
    "- SingleCell-to-SingleCell translation\n",
    "- Image-Bulk translation or vice versa\n",
    "- SingleCell-Image translation or vice versa\n",
    "\n",
    "With Multi-Bulk (Multi-Numeric) we mean combining different types of  sequencing data e.g. mRNA and ATAC. We define Multi-Single-Cell analogous. \n",
    "Now we show how to prepare the data in Python. While we will perform basic preprocessing like NaN removal, and scaling and filtering (if specified), we expect a certain amount of preprocessing for omics data:\n",
    "**For Bulk**:\n",
    "- TODO\n",
    "- TODO\n",
    "\n",
    "**For Single Cell**\n",
    "- TODO \n",
    "- TODO\n",
    "\n",
    "##### Multi-Bulk / Multi-Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.utils.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "\n",
    "# Create fake methylation data\n",
    "# you would normally load your data here\n",
    "meth_data = pd.DataFrame(\n",
    "    np.random.rand(100, 50),  # 100 samples, 50 features\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"Meth_Feature_{j}\" for j in range(50)],\n",
    ")\n",
    "\n",
    "# Create fake RNA data\n",
    "# you would normally load your data here\n",
    "rna_data = pd.DataFrame(\n",
    "    np.random.rand(100, 100),  # TODO align\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"RNA_Feature_{j}\" for j in range(100)],\n",
    ")\n",
    "\n",
    "# Create fake clinical annotations\n",
    "# you would normally load your data here\n",
    "clinical_annotations = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample_ID\": [f\"Sample_{i}\" for i in range(100)],\n",
    "        \"Age\": np.random.randint(20, 80, size=100),\n",
    "        \"Gender\": np.random.choice([\"Male\", \"Female\"], size=100),\n",
    "        \"Disease_Status\": np.random.choice([\"Healthy\", \"Diseased\"], size=100),\n",
    "    }\n",
    ").set_index(\"Sample_ID\")\n",
    "\n",
    "# multi_bulk is a dict with \"name/identifier\" of the dataset as key\n",
    "# the key for annotation needs to be \"paired\" if only one annotation is given, otherwise it has to have the same keys as multi_bulk\n",
    "my_data = DataPackage(\n",
    "    multi_bulk={\"RNA\": rna_data, \"METH\": meth_data},\n",
    "    annotation={\"paired\": clinical_annotations},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pass this data to our Autoencodix. \n",
    "\n",
    "**IMPORTANT**: In you config you need specify the usecase (see code) \n",
    "The preprocessing will be done according to the values in the DefaultConfig. We show how to adjust this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTI_SINGLE_CELL Multi Single Cell\n",
      "MULTI_BULK Multi Bulk\n",
      "BULK_TO_BULK Bulk<->Bulk\n",
      "IMG_TO_BULK IMG<->Bulk\n",
      "SINGLE_CELL_TO_SINGLE_CELL Single Cell<->Single Cell\n",
      "SINGLE_CELL_TO_IMG Single Cell<->IMG\n",
      "IMG_TO_IMG IMG<->IMG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = Vanillix(config=config, user_data=my_data)\n",
    "# USE ONE OF THESE FOR data_case\n",
    "for case in DataCase:\n",
    "    print(case.name, case.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape after filtering: (70, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (70, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying VAR filtering\n",
      "Shape after filtering: (70, 20)\n",
      "Fitted STANDARD scaler.\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (70, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (10, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (10, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (20, 20)\n",
      "scaler: StandardScaler()\n",
      "Applying STANDARD scaling.\n",
      "shape before scaling: (20, 20)\n",
      "scaler: StandardScaler()\n",
      "{'train': {'data': multi_bulk:\n",
      "  RNA: 70 samples × 20 features\n",
      "  METH: 70 samples × 20 features\n",
      "annotation:\n",
      "  paired: 70 samples × 3 features, 'indices': {'paired': {'train': array([58, 11, 21, 30, 85, 67,  3, 97, 49,  4, 89, 40, 25, 13, 34, 28, 72,\n",
      "        6, 45, 12, 50, 47, 70, 29, 37, 53,  1, 62,  0,  7, 42, 22, 83, 46,\n",
      "       59,  2, 16, 61, 27,  9, 68, 95, 77, 24, 43, 96, 90, 66, 14, 15, 19,\n",
      "       71, 88, 98, 26, 99, 23, 86, 57, 41, 94, 73, 48, 20, 35, 75, 38, 64,\n",
      "       54, 87])}}}, 'valid': {'data': multi_bulk:\n",
      "  RNA: 10 samples × 20 features\n",
      "  METH: 10 samples × 20 features\n",
      "annotation:\n",
      "  paired: 10 samples × 3 features, 'indices': {'paired': {'valid': array([18, 91, 55, 76,  8, 60, 63,  5, 74, 79])}}}, 'test': {'data': multi_bulk:\n",
      "  RNA: 20 samples × 20 features\n",
      "  METH: 20 samples × 20 features\n",
      "annotation:\n",
      "  paired: 20 samples × 3 features, 'indices': {'paired': {'test': array([80, 84, 33, 81, 93, 17, 36, 82, 69, 65, 92, 39, 56, 52, 51, 32, 31,\n",
      "       44, 78, 10])}}}}\n"
     ]
    }
   ],
   "source": [
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetContainer(train=<autoencodix.data._numeric_dataset.NumericDataset object at 0x3489a6650>, valid=<autoencodix.data._numeric_dataset.NumericDataset object at 0x357522b30>, test=<autoencodix.data._numeric_dataset.NumericDataset object at 0x34892f610>)\n"
     ]
    }
   ],
   "source": [
    "processed_data = van.result.datasets\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Single-Cell case\n",
    "Here you can provide one MuData object an don't need an extra annotation file, because the annotation info is stored in `obs` of the modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_sc:\n",
      "  multi_sc: 100 samples × 250 features\n"
     ]
    }
   ],
   "source": [
    "import mudata\n",
    "\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "# IMPORTANT specify datacase\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "# Number of samples and features\n",
    "n_samples = 100\n",
    "n_rna_features = 200\n",
    "n_atac_features = 50\n",
    "\n",
    "# Create sparse matrices instead of dense arrays\n",
    "rna_X = sparse.csr_matrix(np.random.rand(n_samples, n_rna_features))\n",
    "atac_X = sparse.csr_matrix(np.random.rand(n_samples, n_atac_features))\n",
    "\n",
    "# Create observation and variable DataFrames\n",
    "obs_df = pd.DataFrame(index=[f\"Sample_{i}\" for i in range(n_samples)])\n",
    "rna_var_df = pd.DataFrame(index=[f\"Gene_{i}\" for i in range(n_rna_features)])\n",
    "atac_var_df = pd.DataFrame(index=[f\"ATAC_Feature_{i}\" for i in range(n_atac_features)])\n",
    "\n",
    "# Try creating AnnData objects with sparse matrices\n",
    "rna_adata = ad.AnnData(X=rna_X, obs=obs_df, var=rna_var_df, dtype=np.float32)\n",
    "\n",
    "atac_adata = ad.AnnData(\n",
    "    X=atac_X,\n",
    "    obs=obs_df,\n",
    "    var=atac_var_df,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "# Create MuData object\n",
    "mdata = mudata.MuData({\"RNA\": rna_adata, \"ATAC\": atac_adata})\n",
    "\n",
    "dp = DataPackage(multi_sc={\"multi_sc\": mdata})\n",
    "# Print the object\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data in nanremover: multi_sc:\n",
      "  multi_sc: 100 samples × 250 features\n",
      "multi_sc in nanremover: {'multi_sc': MuData object with n_obs × n_vars = 100 × 250\n",
      "  2 modalities\n",
      "    RNA:\t100 x 200\n",
      "    ATAC:\t100 x 50}\n",
      "indices: {'paired': {'train': array([58, 11, 21, 30, 85, 67,  3, 97, 49,  4, 89, 40, 25, 13, 34, 28, 72,\n",
      "        6, 45, 12, 50, 47, 70, 29, 37, 53,  1, 62,  0,  7, 42, 22, 83, 46,\n",
      "       59,  2, 16, 61, 27,  9, 68, 95, 77, 24, 43, 96, 90, 66, 14, 15, 19,\n",
      "       71, 88, 98, 26, 99, 23, 86, 57, 41, 94, 73, 48, 20, 35, 75, 38, 64,\n",
      "       54, 87]), 'valid': array([18, 91, 55, 76,  8, 60, 63,  5, 74, 79]), 'test': array([80, 84, 33, 81, 93, 17, 36, 82, 69, 65, 92, 39, 56, 52, 51, 32, 31,\n",
      "       44, 78, 10])}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:167: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'mod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Varix\n\u001b[1;32m      3\u001b[0m var \u001b[38;5;241m=\u001b[39m Varix(user_data\u001b[38;5;241m=\u001b[39mdp, config\u001b[38;5;241m=\u001b[39mconfig) \u001b[38;5;66;03m# TODO allow adata object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mdatasets\n\u001b[1;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/utils/_utils.py:128\u001b[0m, in \u001b[0;36mconfig_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter must be of type DefaultConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m     config \u001b[38;5;241m=\u001b[39m user_config\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:306\u001b[0m, in \u001b[0;36mBasePipeline.preprocess\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_user_data()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mdatasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/data/general_preprocessor.py:219\u001b[0m, in \u001b[0;36mGeneralPreprocessor.preprocess\u001b[0;34m(self, raw_user_data, predict_new_data)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mExecutes the general preprocessing steps and returns the processed data package.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Dict[str, Any]: The processed data package.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_new_data \u001b[38;5;241m=\u001b[39m predict_new_data\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_general_preprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_new_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_new_data\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapackage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:111\u001b[0m, in \u001b[0;36mBasePreprocessor._general_preprocess\u001b[0;34m(self, raw_user_data, predict_new_data)\u001b[0m\n\u001b[1;32m    109\u001b[0m process_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_process_function(datacase\u001b[38;5;241m=\u001b[39mdatacase)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_function:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_user_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_user_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported data case: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatacase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:251\u001b[0m, in \u001b[0;36mBasePreprocessor._process_multi_single_cell\u001b[0;34m(self, raw_user_data)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpostsplit_processor\u001b[39m(\n\u001b[1;32m    245\u001b[0m     split_data: Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[1;32m    246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postsplit_multi_single_cell(\n\u001b[1;32m    248\u001b[0m         split_data\u001b[38;5;241m=\u001b[39msplit_data, datapackage_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_sc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     )\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data_case\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality_processors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_sc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresplit_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostsplit_processor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:198\u001b[0m, in \u001b[0;36mBasePreprocessor._process_data_case\u001b[0;34m(self, data_package, modality_processors)\u001b[0m\n\u001b[1;32m    195\u001b[0m processed_splits \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modality_key, (_, postsplit_processor) \u001b[38;5;129;01min\u001b[39;00m modality_processors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 198\u001b[0m     split_packages \u001b[38;5;241m=\u001b[39m \u001b[43mpostsplit_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_packages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_name, split_package \u001b[38;5;129;01min\u001b[39;00m split_packages\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    200\u001b[0m     split_indices \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    201\u001b[0m         name: {\n\u001b[1;32m    202\u001b[0m             split: idx\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    207\u001b[0m     }\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:247\u001b[0m, in \u001b[0;36mBasePreprocessor._process_multi_single_cell.<locals>.postsplit_processor\u001b[0;34m(split_data)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpostsplit_processor\u001b[39m(\n\u001b[1;32m    245\u001b[0m     split_data: Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[1;32m    246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_postsplit_multi_single_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatapackage_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_sc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_preprocessor.py:262\u001b[0m, in \u001b[0;36mBasePreprocessor._postsplit_multi_single_cell\u001b[0;34m(self, split_data, datapackage_key)\u001b[0m\n\u001b[1;32m    260\u001b[0m train_split \u001b[38;5;241m=\u001b[39m split_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    261\u001b[0m sc_filter \u001b[38;5;241m=\u001b[39m SingleCellFilter(data_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_config\u001b[38;5;241m.\u001b[39mdata_info)\n\u001b[0;32m--> 262\u001b[0m filtered_train, sc_genes_to_keep \u001b[38;5;241m=\u001b[39m \u001b[43msc_filter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc_postsplit_processing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmudata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_split\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatapackage_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m processed_train, general_genes_to_keep, scalers \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    266\u001b[0m     sc_filter\u001b[38;5;241m.\u001b[39mgeneral_postsplit_processing(\n\u001b[1;32m    267\u001b[0m         mudata\u001b[38;5;241m=\u001b[39mfiltered_train, scaler_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gene_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    269\u001b[0m )\n\u001b[1;32m    270\u001b[0m train_split[datapackage_key] \u001b[38;5;241m=\u001b[39m processed_train\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/data/_sc_filter.py:200\u001b[0m, in \u001b[0;36mSingleCellFilter.sc_postsplit_processing\u001b[0;34m(self, mudata, gene_map)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03mPreprocess the data using modality-specific configurations.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Preprocessed MuData and a dictionary mapping modality keys to the names of kept genes.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m kept_genes: Dict[\u001b[38;5;28mstr\u001b[39m, List] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod_key, mod_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmudata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    201\u001b[0m     data_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_info_for_modality(mod_key)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'mod'"
     ]
    }
   ],
   "source": [
    "from autoencodix import Varix\n",
    "\n",
    "var = Varix(user_data=dp, config=config) # TODO allow adata object\n",
    "var.preprocess()\n",
    "dataset = var.result.datasets\n",
    "res = var.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translation between modalities.\n",
    "If you want to translate between modalties i.e. mRNA to ATAC, you can populate the `from_modality` and `to_modality` attributes of the DataPackage. For the `annotation` attribute you need to add at leas one annotation file for the bulk/numeric case. Details see code:\n",
    "\n",
    "As of March 2025, we've not implemented models that support Translation in the new package, so we only show how to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.utils.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "dp = DataPackage()\n",
    "data_info = {\n",
    "    \"RNA\": DataInfo(translate_direction=\"from\"),\n",
    "    \"METH\": DataInfo(translate_direction=\"to\"),\n",
    "}\n",
    "config = DefaultConfig(\n",
    "    paired_translation=True, # we want to have matched samples in this case\n",
    "    data_case=DataCase.BULK_TO_BULK,\n",
    "    data_config=DataConfig(data_info=data_info),\n",
    ")\n",
    "\n",
    "dp.from_modality = {\"from_modality\": rna_data}\n",
    "dp.to_modality = {\"to_modality\": meth_data}\n",
    "dp.annotation = {\"paired\": clinical_annotations} # here we can also provide {RNA: rna_anno, MEth: meth_anno} if we have two anno files\n",
    "\n",
    "van = Vanillix(user_data=dp, config=config)\n",
    "van.preprocess()\n",
    "datasets = van.result.datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with Images\n",
    "When you want to use images for our pipelines, it is the easiest to pass the folder and annotations files via config params as shown above. For some usecases, however users want to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add example (see already existing configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 How to add a new architecture\n",
    "### High level workflow\n",
    "To add a new autoencoder architecture, you need to at least code two things:\n",
    "- the model architecture itself in  `src/autoencodix/modeling/` - anlogous to `_varix_architecture.py`\n",
    "- the pipeline itself in `src/autoencodix/` - analgous to `varix.py`\n",
    "Depending on the complexity and data requirements you might also want to provide the following:\n",
    "- a new custom dataset class in `src/autoencodix/data` - analogous to `numeric_dataset.py`\n",
    "- a new custom preprocessor in `src/autoencodix/data` - as in `preprocessor.py`\n",
    "- a new custom trainer in `src/autoencodix/trainers` - as in `_general_trainer.py`\n",
    "  - including a custom predict method of your trainer\n",
    "- a custom loss for your model\n",
    "- a custom visualizer (no example implemented yet)\n",
    "- a custom evaluator for downstream tasks (no example implemented yet)\n",
    "- a custom tuner (not sure if this will be part of the package)\n",
    "### High level structure\n",
    "- Each autoencodix model in our family is based on our base classes in `src/autoencodix/base`. Here we have (often abstract) classes that define the general structure of each step (preprocess, fit, predict, evaluate, visualize) in our pipeline, as well as additional classes e.g. losses.\n",
    "- In these base classes we've implemented shared functionalities, like calling the corresponding trainer, or preprocessor.\n",
    "- The base classes also guide you to the structure of your new class. The methods of the base classes should not be changed. Rather overwrite the method in the implementation of your child class in case you need to make changes.\n",
    "\n",
    "### Must-do files details\n",
    "We'll illustrate this by an example. We want to add the new architecture with the name MySpecial to our package. First we add the actual architecture:\n",
    "- create the file `src/autoencodix/modeling/_myspecialix_architecture.py` (note files that should not be imported at end-user lever have a leading underscore).\n",
    "- for each newly created file, add the classes to the `__init__.py` in the corresponding folder. Example for the pipeline file in  `src/autoencodix`:\n",
    "```python\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "try:\n",
    "    __version__ = version(\"autoencodix\")\n",
    "except PackageNotFoundError:\n",
    "    __version__ = \"unknown\"\n",
    "\n",
    "# Import key classes to make them directly accessible\n",
    "from .vanillix import Vanillix\n",
    "from .varix import Varix\n",
    "from .stackix import Stackix\n",
    "# NEW: -------------------------------------\n",
    "from .MyNewSpecialix imiport MyNewSpecialix\n",
    "# -----------------------------------------\n",
    "\n",
    "__all__ = [\"Vanillix\", \"Varix\", \"Stackix\"] # TODO add \"MyNewSpecialx\"\n",
    "```\n",
    "\n",
    "- create the file `tests/test_modelling/test_myspecialix_architecture`\n",
    "- we write the class itself that might look like:\n",
    "```python\n",
    "from autoencodix.base._base_autoencoder import BaseAutoencoder\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "\n",
    "# needs to inherit from BaseAutoencoder\n",
    "class MySpecialArchitecture(BaseAutoencoder):\n",
    "    \"\"\"\n",
    "    MySpecial implementation accroding to (cite paper, yourself, etc)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.input_dim : int\n",
    "        number of input features\n",
    "    self.config: DefaultConfig\n",
    "        Configuration object containing model architecture parameters\n",
    "    self._encoder: nn.Module\n",
    "        Encoder network of the autoencoder\n",
    "    self._decoder: nn.Module\n",
    "        Decoder network of the autoencoder\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    my_super_special_method():\n",
    "        does cool stuff\n",
    "    _build_network()\n",
    "        Construct the encoder and decoder networks via the LayerFactory\n",
    "    encode(x: torch.Tensor) -> torch.Tensor\n",
    "        Encode the input tensor x\n",
    "    decode(x: torch.Tensor) -> torch.Tensor\n",
    "        Decode the latent tensor x\n",
    "    forward(x: torch.Tensor) -> ModelOutput\n",
    "        Forward pass of the model, fills in the reconstruction and latentspace attributes of ModelOutput class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, config: Optional[Union[None, DefaultConfig]], input_dim: int\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = DefaultConfig()\n",
    "        self._config = config\n",
    "        super().__init__(config, input_dim)\n",
    "        self.input_dim = input_dim # we always base the input dimension (usually number of features in your dataset)\n",
    "\n",
    "        # populate self.encoder and self.decoder\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Construct the encoder and decoder networks.\n",
    "        See your _layer_factory.py file that could help you here.\n",
    "        Also check other implementation to see how to use _layer_factory.py\n",
    "        \"\"\"\n",
    "        self._encoder = TODO\n",
    "        self._decoder = TODO\n",
    "\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encode the input tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Encoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        encoded = self._encoder(x)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode the latent tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Latent tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Decoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        return self._decoder(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> ModelOutput:\n",
    "        \"\"\"\n",
    "        Forward pass of the model, fill\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelOutput\n",
    "            ModelOutput object containing the reconstructed tensor and latent tensor\n",
    "\n",
    "        \"\"\"\n",
    "        latent = self.encode(x)\n",
    "        x_hat = self.decode(z)\n",
    "        # fill model output arcodding to your needs (we need reconstruction and a latentspace, see ModelOuput class for required output)\n",
    "        return ModelOutput(\n",
    "            reconstruction=x_hat,\n",
    "            latentspace=latent\n",
    "            latent_mean=None,\n",
    "            latent_logvar=None,\n",
    "            additional_info=None,\n",
    "        )\n",
    "\n",
    "```\n",
    "- adjust the `__init__.py` in `src/autoencodix/modelling` to import `MySpecialArchitecture\n",
    "- next we write tests for the newly created file in the test file\n",
    "- lastly, we need to create the pipeline file:\n",
    "  - create `src/autoencodix/myspecialix.py`\n",
    "  - create `tests/test_myspecialix.py`\n",
    "- the `myspecialix.py` might look like this\n",
    "```python\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "class MySpecialix(BasePipeline): # must inherit from BasePipeline\n",
    "    \"\"\"\n",
    "    MySpecialix specific version of the BasePipeline class.\n",
    "    Inherits preprocess, fit, predict, evaluate, and visualize methods from BasePipeline.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "        Input data from the user\n",
    "    config : Optional[Union[None, DefaultConfig]]\n",
    "        Configuration object containing customizations for the pipeline\n",
    "    _preprocessor : Preprocessor\n",
    "        Preprocessor object to preprocess the input data (custom for Vanillix)\n",
    "    _visualizer : Visualizer\n",
    "        Visualizer object to visualize the model output (custom for Vanillix)\n",
    "    _trainer : GeneralTrainer\n",
    "        Trainer object that trains the model (custom for Vanillix)\n",
    "    _evaluator : Evaluator\n",
    "        Evaluator object that evaluates the model performance or downstream tasks (custom for Vanillix)\n",
    "    result : Result\n",
    "        Result object to store the pipeline results\n",
    "    _datasets : Optional[DatasetContainer]\n",
    "        Container for train, validation, and test datasets (preprocessed)\n",
    "    data_splitter : DataSplitter\n",
    "        DataSplitter object to split the data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[np.ndarray, AnnData, pd.DataFrame],\n",
    "        # this can be also a custom Type like MySpecialixDataset\n",
    "        dataset_type: Type[BaseDataset] = NumericDataset,\n",
    "        # This will be the Type MySpecialixArchitecture that we created before\n",
    "        model_type: Type[BaseAutoencoder] = MySpecialixArchitecture,\n",
    "        # This can be a custom Loss class, or an exisiting one see _losses.py\n",
    "        loss_type: Type[BaseLoss] = VanillixLoss,\n",
    "        preprocessor: Optional[Preprocessor] = None,\n",
    "        visualizer: Optional[BaseVisualizer] = None,\n",
    "        evaluator: Optional[Evaluator] = None,\n",
    "        result: Optional[Result] = None,\n",
    "        datasplitter_type: Type[DataSplitter] = DataSplitter,\n",
    "        custom_splits: Optional[Dict[str, np.ndarray]] = None,\n",
    "        config: Optional[DefaultConfig] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize MySpecialix pipeline with customizable components.\n",
    "\n",
    "        Some components are passed as types rather than instances because they require\n",
    "        data that is only available after preprocessing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "            Input data to be processed\n",
    "        trainer_type : Type[BaseTrainer]\n",
    "            Type of trainer to be instantiated during fit step, default is GeneralTrainer\n",
    "        dataset_type : Type[BaseDataset]\n",
    "            Type of dataset to be instantiated post-preprocessing, default is NumericDataset\n",
    "        loss_type : Type[BaseLoss], which loss to use for Vanillix, default is VanillaAutoencoderLoss\n",
    "        preprocessor : Optional[Preprocessor]\n",
    "            For data preprocessing, default creates new Preprocessor\n",
    "        visualizer : Optional[Visualizer]\n",
    "            For result visualization, default creates new Visualizer\n",
    "        evaluator : Optional[Evaluator]\n",
    "            For model evaluation, default creates new Evaluator\n",
    "        result : Optional[Result]\n",
    "            Container for pipeline results, default creates new Result\n",
    "        datasplitter_type : Type[DataSplitter], optional\n",
    "            Type of splitter to be instantiated during preprocessing, default is DataSplitter\n",
    "        custom_splits : Optional[Dict[str, np.ndarray]]\n",
    "            Custom train/valid/test split indices\n",
    "        config : Optional[DefaultConfig]\n",
    "            Configuration for all pipeline components\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            dataset_type=dataset_type,\n",
    "            trainer_type=trainer_type,\n",
    "            model_type=model_type,\n",
    "            loss_type=loss_type,\n",
    "            preprocessor=preprocessor or Preprocessor(),\n",
    "            visualizer=visualizer or Visualizer(),\n",
    "            evaluator=evaluator or Evaluator(),\n",
    "            result=result or Result(),\n",
    "            datasplitter_type=datasplitter_type,\n",
    "            config=config or DefaultConfig(),\n",
    "            custom_split=custom_splits,\n",
    "        )\n",
    "\n",
    "```\n",
    "##### More explaination to the passing of Types instead of classes:\n",
    "Most functionality of the pipeline comes from the BasePipeline. To make the methods custom to our specific architecture that we use in our `MySpecial` pipeline, we need to pass our specializes subclasses. Since we don't have all required parameters for this subclasses when calling the init method of the parent class, we pass only the type of the subclasses. These types need to be childs of the corresponding base class. Inside the BasePipeline we instantiate the specific classes with the required paramters as soon as we have them\n",
    "### Optional files details\n",
    "The optional files work from the same principle as the mandatory files, so we can always create a special class based on the baseclass and then we pass the type of our special class to our MySpecialix Pipeline e.g MySpecialTrainer n the init mehtod of MySpecialix (same as we did with MySpecialArchitecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- show how to update and work with the config object (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANDBOX \n",
    "testing Varix and losses, especially sub_losses in result_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### P1 Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.utils._screader import SingleCellDataReader\n",
    "from autoencodix.utils._bulkreader import BulkDataReader\n",
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "\n",
    "\n",
    "from autoencodix.base._base_preprocessor import BasePreprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### config paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_path = \"configs/largebulk.yaml\"\n",
    "scpath = \"configs/largesc.yaml\"\n",
    "tranpath = \"configs/sc_img_tran_config.yaml\"\n",
    "unpaired_path = \"configs/bulk_img_up.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_config = DefaultConfig.model_validate(yaml.safe_load(Path(bulk_path).read_text()))\n",
    "scconfig = DefaultConfig.model_validate(yaml.safe_load(Path(scpath).read_text()))\n",
    "tranconfig = DefaultConfig.model_validate(yaml.safe_load(Path(tranpath).read_text()))\n",
    "unpaired_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(unpaired_path).read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scconfig.data_config.data_info[\"RNA\"].selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "import mudata as md\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from autoencodix.data._datasetcontainer import DatasetContainer\n",
    "from autoencodix.base._base_preprocessor import BasePreprocessor\n",
    "\n",
    "\n",
    "class GeneralPreprocessor(BasePreprocessor):\n",
    "    \"\"\"\n",
    "    General Preprocessor class that uses the general_preprocessing steps from BasePreprocessor.\n",
    "    It takes the split, cleaned, scaled, and filtered data packages and transforms them into a PyTorch\n",
    "    Dataset that can be used in training. This class is primarily used for the Vanillix and Varix\n",
    "    pipelines for numeric data.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _datapackage : Dict[str, Any]\n",
    "        The processed data package containing split, cleaned, scaled, and filtered data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess()\n",
    "        Executes the general preprocessing steps and returns the processed data package.\n",
    "    _extract_primary_data(modality_data: Any) -> np.ndarray\n",
    "        Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "    _combine_modality_data(mudata: MuData) -> np.ndarray\n",
    "        Combines the primary data matrices (.X) from all modalities in a MuData object.\n",
    "    _create_numeric_dataset(data: np.ndarray, config: Any, split_ids: np.ndarray, metadata: Any, ids: List[str]) -> NumericDataset\n",
    "        Creates a NumericDataset from the given data and metadata.\n",
    "    _process_multi_bulk(data_dict: Dict[str, pd.DataFrame], config: Any, split_ids: np.ndarray, metadata: Any) -> NumericDataset\n",
    "        Processes multi-bulk data by concatenating all dataframes and creating a NumericDataset.\n",
    "    _process_multi_sc(mudata: MuData, config: Any, split_ids: np.ndarray, metadata: Any) -> NumericDataset\n",
    "        Processes multi-single-cell data by combining modalities and creating a NumericDataset.\n",
    "    _process_data_package(data_package: Dict[str, Any], config: Any, split_type: str = \"train\") -> Union[NumericDataset, None]\n",
    "        Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: DefaultConfig):\n",
    "        \"\"\"\n",
    "        Initializes the GeneralPreprocessor with the given configuration.\n",
    "\n",
    "        Parameters:\n",
    "            config (Any): Configuration for the preprocessor.\n",
    "        \"\"\"\n",
    "        super().__init__(config=config)\n",
    "        self._datapackage = None\n",
    "\n",
    "    def _extract_primary_data(self, modality_data: md.MuData) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "\n",
    "        Parameters:\n",
    "            modality_data (Any): The modality data (e.g., AnnData object).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The primary data matrix as a dense array.\n",
    "        \"\"\"\n",
    "        primary_data = modality_data.X\n",
    "        if issparse(primary_data):\n",
    "            primary_data = primary_data.toarray()\n",
    "        return primary_data\n",
    "\n",
    "    def _combine_layers(self, modality_name: str, modality_data: Any) -> np.ndarray:\n",
    "        layer_list = []\n",
    "        selected_layers = self.config.data_config.data_info[\n",
    "            modality_name\n",
    "        ].selected_layers\n",
    "\n",
    "        for layer_name in selected_layers:\n",
    "            if layer_name == \"X\":\n",
    "                primary_data = self._extract_primary_data(modality_data)\n",
    "                layer_list.append(primary_data)\n",
    "            elif layer_name in modality_data.layers:\n",
    "                # Handle additional layers\n",
    "                layer_data = modality_data.layers[layer_name]\n",
    "                # Convert sparse matrix to dense if necessary\n",
    "                if issparse(layer_data):\n",
    "                    layer_data = layer_data.toarray()\n",
    "                layer_list.append(layer_data)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Layer '{layer_name}' not found in modality '{modality_name}'. Skipping.\"\n",
    "                )\n",
    "        return layer_list\n",
    "\n",
    "    def _combine_modality_data(self, mudata: md.MuData) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Combines the primary data matrices (.X) and specified layers from all modalities in a MuData object.\n",
    "\n",
    "        Parameters:\n",
    "            mudata (MuData): The MuData object containing multiple modalities.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The combined data matrix.\n",
    "        \"\"\"\n",
    "        modality_data_list = []\n",
    "\n",
    "        for modality_name, modality_data in mudata.mod.items():\n",
    "            combined_layers = self._combine_layers(\n",
    "                modality_name=modality_name, modality_data=modality_data\n",
    "            )\n",
    "            modality_data_list.extend(combined_layers)\n",
    "\n",
    "        return np.concatenate(modality_data_list, axis=1)\n",
    "\n",
    "    def _create_numeric_dataset(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        config: DefaultConfig,\n",
    "        split_ids: np.ndarray,\n",
    "        metadata: pd.DataFrame,\n",
    "        ids: List[str],\n",
    "    ) -> NumericDataset:\n",
    "        \"\"\"\n",
    "        Creates a NumericDataset from the given data and metadata.\n",
    "\n",
    "        Parameters:\n",
    "            data (np.ndarray): The data matrix.\n",
    "            config (Any): Configuration for the dataset.\n",
    "            split_ids (np.ndarray): Indices for splitting the data.\n",
    "            metadata (Any): Metadata associated with the data.\n",
    "            ids (List[str]): Identifiers for the observations.\n",
    "\n",
    "        Returns:\n",
    "            NumericDataset: The created NumericDataset.\n",
    "        \"\"\"\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        return NumericDataset(\n",
    "            data=tensor_data,\n",
    "            config=config,\n",
    "            split_ids=split_ids,\n",
    "            metadata=metadata,\n",
    "            ids=ids,\n",
    "        )\n",
    "\n",
    "    def _process_data_package(\n",
    "        self, data_dict: Dict[str, Any]\n",
    "    ) -> Union[NumericDataset, None]:\n",
    "        \"\"\"\n",
    "        Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "\n",
    "        Parameters:\n",
    "            data_package (Dict[str, Any]): The data package containing data and metadata.\n",
    "            config (Any): Configuration for the dataset.\n",
    "            split_type (str): The type of split to process (e.g., \"train\").\n",
    "\n",
    "        Returns:\n",
    "            Union[NumericDataset, None]: The created NumericDataset or None if the data type is unsupported.\n",
    "        \"\"\"\n",
    "        data, split_ids = data_dict[\"data\"], data_dict[\"indices\"]\n",
    "\n",
    "        for key in data.__annotations__.keys():\n",
    "            attr_val = getattr(data, key)\n",
    "            if key == \"multi_bulk\" and attr_val is not None:\n",
    "                metadata = data.annotation\n",
    "                dfs_to_concat = list(attr_val.values())\n",
    "                combined_df = pd.concat(dfs_to_concat, axis=1)\n",
    "                return self._create_numeric_dataset(\n",
    "                    data=combined_df.values,\n",
    "                    config=self.config,\n",
    "                    split_ids=split_ids,\n",
    "                    metadata=metadata,\n",
    "                    ids=combined_df.index.tolist(),\n",
    "                )\n",
    "\n",
    "            elif key == \"multi_sc\" and attr_val is not None:\n",
    "                combined_data = self._combine_modality_data(attr_val)\n",
    "                combined_obs = pd.concat(\n",
    "                    [modality_data.obs for modality_data in attr_val.mod.values()],\n",
    "                    axis=1,\n",
    "                )\n",
    "                return self._create_numeric_dataset(\n",
    "                    data=combined_data,\n",
    "                    config=self.config,\n",
    "                    split_ids=split_ids,\n",
    "                    metadata=combined_obs,\n",
    "                    ids=attr_val.obs_names.tolist(),\n",
    "                )\n",
    "\n",
    "        return None\n",
    "\n",
    "    def preprocess(self) -> DatasetContainer:\n",
    "        \"\"\"\n",
    "        Executes the general preprocessing steps and returns the processed data package.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The processed data package.\n",
    "        \"\"\"\n",
    "\n",
    "        self._datapackage = self._general_preprocess()\n",
    "        self._dataset_container = DatasetContainer()\n",
    "        for split in [\"train\", \"test\", \"valid\"]:\n",
    "            dataset = self._process_data_package(data_dict=self._datapackage[split])\n",
    "            self._dataset_container[split] = dataset\n",
    "\n",
    "        return self._dataset_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprocessor = GeneralPreprocessor(config=scconfig)\n",
    "bulkprocessor = GeneralPreprocessor(config=bulk_config)\n",
    "tranupprocessor = GeneralPreprocessor(config=unpaired_config)\n",
    "trprocessor = GeneralPreprocessor(config=tranconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GeneralPreprocessor(config=bulk_config)\n",
    "dp = processor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprocessor = GeneralPreprocessor(config=scconfig)\n",
    "scdp = scprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mudata = sc.read_h5ad(\"data/raw/Sc-2-mini.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mudata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from mudata import MuData\n",
    "\n",
    "\n",
    "def subsample_matched_data(\n",
    "    mdata1: MuData,\n",
    "    mdata2: MuData,\n",
    "    cell_frac: float = 0.1,\n",
    "    gene_frac: float = 0.3,\n",
    "    random_seed: int = 42,\n",
    ") -> tuple[MuData, MuData]:\n",
    "    \"\"\"\n",
    "    Subsample matched cells and genes from two MuData objects.\n",
    "\n",
    "    Parameters:\n",
    "        mdata1 (MuData): The first MuData object.\n",
    "        mdata2 (MuData): The second MuData object.\n",
    "        cell_frac (float): Fraction of cells to keep (default: 0.1).\n",
    "        gene_frac (float): Fraction of genes to keep (default: 0.3).\n",
    "        random_seed (int): Random seed for reproducibility (default: 42).\n",
    "\n",
    "    Returns:\n",
    "        tuple[MuData, MuData]: Subsampled MuData objects.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Ensure both datasets have the same cells and genes\n",
    "    if not np.array_equal(mdata1.obs_names, mdata2.obs_names):\n",
    "        raise ValueError(\"Datasets do not have the same cells.\")\n",
    "    if not np.array_equal(mdata1.var_names, mdata2.var_names):\n",
    "        raise ValueError(\"Datasets do not have the same genes.\")\n",
    "\n",
    "    # Subsample cells\n",
    "    n_cells = int(mdata1.n_obs * cell_frac)\n",
    "    cell_indices = np.random.choice(mdata1.n_obs, size=n_cells, replace=False)\n",
    "\n",
    "    # Subsample genes\n",
    "    n_genes = int(mdata1.n_vars * gene_frac)\n",
    "    gene_indices = np.random.choice(mdata1.n_vars, size=n_genes, replace=False)\n",
    "\n",
    "    # Subset both datasets using the same indices\n",
    "    mdata1_subset = mdata1[cell_indices, gene_indices].copy()\n",
    "    mdata2_subset = mdata2[cell_indices, gene_indices].copy()\n",
    "\n",
    "    # Validate the subsets\n",
    "    print(\n",
    "        f\"Subsampled MuData 1: {mdata1_subset.n_obs} cells, {mdata1_subset.n_vars} genes\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Subsampled MuData 2: {mdata2_subset.n_obs} cells, {mdata2_subset.n_vars} genes\"\n",
    "    )\n",
    "\n",
    "    return mdata1_subset, mdata2_subset\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Load the datasets\n",
    "mdata1 = sc.read_h5ad(\"data/raw/Sc-1.h5ad\")\n",
    "mdata2 = sc.read_h5ad(\"data/raw/Sc-2.h5ad\")\n",
    "\n",
    "# Subsample matched data (10% of cells and 30% of genes)\n",
    "mdata1_subset, mdata2_subset = subsample_matched_data(\n",
    "    mdata1, mdata2, cell_frac=0.1, gene_frac=0.3\n",
    ")\n",
    "\n",
    "# Save the subsets to new files\n",
    "mdata1_subset.write_h5ad(\"data/raw/Sc-1-mini.h5ad\")\n",
    "mdata2_subset.write_h5ad(\"data/raw/Sc-2-mini.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdp.train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for i in range(9):\n",
    "    x = 9009 + x\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from mudata import MuData\n",
    "\n",
    "data = dp[\"train\"][\"data\"]\n",
    "for k in data.__annotations__.keys():\n",
    "    print(k)\n",
    "\n",
    "    attr_val = getattr(data, k)\n",
    "    if k == \"multi_bulk\":\n",
    "        dfs_to_concat = list(attr_val.values())\n",
    "        df = pd.concat(dfs_to_concat, axis=1)\n",
    "        t = torch.from_numpy(df.values)\n",
    "        dataset = NumericDataset(\n",
    "            data=t,\n",
    "            config=bulk_config,\n",
    "            split_ids=dp[\"train\"][\"indices\"],\n",
    "            metadata=data.annotation,\n",
    "            ids=df.index,\n",
    "        )\n",
    "\n",
    "    elif k == \"multi_sc\":\n",
    "        # Collect all modality data matrices\n",
    "        layer_list = []\n",
    "\n",
    "        # Iterate over modalities in the MuData object\n",
    "        for modality_name, modality_data in attr_val.mod.items():\n",
    "            print(f\"Processing modality: {modality_name}\")\n",
    "            primary_data = modality_data.X\n",
    "            if issparse(primary_data):\n",
    "                primary_data = primary_data.toarray()\n",
    "            layer_list.append(primary_data)\n",
    "\n",
    "        combined_data = np.concatenate(layer_list, axis=1)\n",
    "        t = torch.from_numpy(combined_data)\n",
    "        dataset = NumericDataset(\n",
    "            data=t,\n",
    "            config=sc_config,  # Replace with appropriate config for single-cell data\n",
    "            split_ids=dp[\"train\"][\"indices\"],\n",
    "            metadata=data.annotation,\n",
    "            ids=attr_val.obs_names,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "from mudata import MuData\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "\n",
    "\n",
    "def extract_primary_data(modality_data: Any) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "\n",
    "    Parameters:\n",
    "        modality_data: The modality data (e.g., AnnData object).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The primary data matrix as a dense array.\n",
    "    \"\"\"\n",
    "    primary_data = modality_data.X\n",
    "    if issparse(primary_data):\n",
    "        primary_data = primary_data.toarray()\n",
    "    return primary_data\n",
    "\n",
    "\n",
    "def combine_modality_data(mudata: MuData) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Combines the primary data matrices (.X) from all modalities in a MuData object.\n",
    "\n",
    "    Parameters:\n",
    "        mudata (MuData): The MuData object containing multiple modalities.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The combined data matrix.\n",
    "    \"\"\"\n",
    "    modality_data_list = []\n",
    "    for modality_name, modality_data in mudata.mod.items():\n",
    "        print(f\"Processing modality: {modality_name}\")\n",
    "        primary_data = extract_primary_data(modality_data)\n",
    "        modality_data_list.append(primary_data)\n",
    "    return np.concatenate(modality_data_list, axis=1)\n",
    "\n",
    "\n",
    "def create_numeric_dataset(\n",
    "    data: np.ndarray,\n",
    "    config: Any,\n",
    "    split_ids: np.ndarray,\n",
    "    metadata: Any,\n",
    "    ids: List[str],\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Creates a NumericDataset from the given data and metadata.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): The data matrix.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "        ids (List[str]): Identifiers for the observations.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    tensor_data = torch.from_numpy(data)\n",
    "    return NumericDataset(\n",
    "        data=tensor_data,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=ids,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_multi_bulk(\n",
    "    data_dict: Dict[str, pd.DataFrame],\n",
    "    config: Any,\n",
    "    split_ids: np.ndarray,\n",
    "    metadata: Any,\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Processes multi-bulk data by concatenating all dataframes and creating a NumericDataset.\n",
    "\n",
    "    Parameters:\n",
    "        data_dict (Dict[str, pd.DataFrame]): Dictionary of dataframes.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    dfs_to_concat = list(data_dict.values())\n",
    "    combined_df = pd.concat(dfs_to_concat, axis=1)\n",
    "    return create_numeric_dataset(\n",
    "        data=combined_df.values,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=combined_df.index.tolist(),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_multi_sc(\n",
    "    mudata: MuData, config: Any, split_ids: np.ndarray, metadata: Any\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Processes multi-single-cell data by combining modalities and creating a NumericDataset.\n",
    "\n",
    "    Parameters:\n",
    "        mudata (MuData): The MuData object containing multiple modalities.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    combined_data = combine_modality_data(mudata)\n",
    "    return create_numeric_dataset(\n",
    "        data=combined_data,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=mudata.obs_names.tolist(),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_data_package(\n",
    "    data_package: Dict[str, Any], config: Any, split_type: str = \"train\"\n",
    ") -> Union[NumericDataset, None]:\n",
    "    \"\"\"\n",
    "    Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "\n",
    "    Parameters:\n",
    "        data_package (Dict[str, Any]): The data package containing data and metadata.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_type (str): The type of split to process (e.g., \"train\").\n",
    "\n",
    "    Returns:\n",
    "        Union[NumericDataset, None]: The created NumericDataset or None if the data type is unsupported.\n",
    "    \"\"\"\n",
    "    split = data_package[split_type][\"data\"]\n",
    "    split_ids = data_package[split_type][\"indices\"]\n",
    "    metadata = split.annotation\n",
    "\n",
    "    for key in split.__annotations__.keys():\n",
    "        attr_val = getattr(split, key)\n",
    "        if key == \"multi_bulk\":\n",
    "            return process_multi_bulk(attr_val, config, split_ids, metadata)\n",
    "        elif key == \"multi_sc\":\n",
    "            if isinstance(attr_val, MuData):\n",
    "                return process_multi_sc(attr_val, config, split_ids, metadata)\n",
    "            else:\n",
    "                print(f\"Unexpected type for 'multi_sc': {type(attr_val)}\")\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jggdataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(data.multi_bulk[\"RNA\"].shape)\n",
    "print(data.multi_bulk[\"METHYLATION\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid confgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = os.path.join(\"configs/invalid\")\n",
    "invalid_configs = [\n",
    "    \"invalid_modalities_config.yaml\",\n",
    "    \"invalid_one_config.yaml\",\n",
    "    \"invalid_sc_bulk_config.yaml\",\n",
    "    \"invalid_three_config.yaml\",\n",
    "]\n",
    "invalid_config_objects = []\n",
    "for i, c in enumerate(invalid_configs):\n",
    "    print(c)\n",
    "    try:\n",
    "        data_info = DefaultConfig.model_validate(\n",
    "            yaml.safe_load(Path(os.path.join(base_path, c)).read_text())\n",
    "        )\n",
    "        invalid_config_objects.append(data_info)\n",
    "    except Exception as e:\n",
    "        print(invalid_configs[i])\n",
    "        print(e)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "valid_configs = glob.glob(\"configs/*.yaml\")\n",
    "print(valid_configs)\n",
    "valid_config_objects = []\n",
    "\n",
    "print(len(valid_configs))\n",
    "for c in valid_configs:\n",
    "    print(c)\n",
    "    data_info = DefaultConfig.model_validate(yaml.safe_load(Path(c).read_text()))\n",
    "    valid_config_objects.append(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated config structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate from object\n",
    "Alternatively, we can just create our DefaultConfig Object and initialize it with the data info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next TODOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- write docu of new data handling:\n",
    "  - how to fill config\n",
    "  - how different scenarios work\n",
    "  - how to proceed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
