{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e778cd3b",
   "metadata": {},
   "source": [
    "## Adapting Stackix to work with unpaired Miracle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8d3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/maximilianjoas/development/autoencodix_package'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autoencodix as acx\n",
    "import os\n",
    "from autoencodix.configs.stackix_config import StackixConfig\n",
    "from autoencodix.configs.default_config import DataConfig, DataInfo, DataCase\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a276e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = os.path.join(\"data/miracle/Daten/Relevanten\")\n",
    "rna_file = \"2025-05-16_RESTING_RNA_log2TPM_gene_name.parquet\"\n",
    "clin_file = \"2025-05-16_RESTING_clinical_noNAs.parquet\" # TODO test with non filtered version including nans\n",
    "mut_file = \"2025-05-16_RESTING_WES_MutMatrix.parquet\"\n",
    "radio_con = \"2025-05-16_RESTING_RADIO_contrast.parquet\"\n",
    "cell_deco = \"2025-05-26_RESTING_celldeco.parquet\"\n",
    "clin_file_nas = \"2025-05-16_RESTING_clinical.parquet\"\n",
    "\n",
    "rna_file = \"2025-05-16_RESTING_RNA_log2TPM_gene_name.parquet\"\n",
    "clin_file = \"2025-05-16_RESTING_clinical_noNAs.parquet\"\n",
    "mut_file = \"2025-05-16_RESTING_WES_MutMatrix.parquet\"\n",
    "radio_con = \"2025-05-16_RESTING_RADIO_contrast.parquet\"\n",
    "cell_deco = \"2025-05-26_RESTING_celldeco.parquet\"\n",
    "\n",
    "# Create a dictionary of DataInfo objects\n",
    "data_info = {\n",
    "    \"RNA\": DataInfo(file_path=os.path.join(root_dir, rna_file)),\n",
    "    \"clinical\": DataInfo(file_path=os.path.join(root_dir, clin_file_nas), data_type=\"ANNOTATION\"),\n",
    "    \"mutation\": DataInfo(file_path=os.path.join(root_dir, mut_file)),\n",
    "    \"radiology\": DataInfo(file_path=os.path.join(root_dir, radio_con)),\n",
    "    \"cell_deconvolution\": DataInfo(file_path=os.path.join(root_dir, cell_deco))\n",
    "}\n",
    "\n",
    "config = StackixConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info=data_info\n",
    "    ),\n",
    "    data_case=DataCase.MULTI_BULK,\n",
    "    requires_paired=False,\n",
    "    epochs = 100\n",
    ")\n",
    "\n",
    "stackix = acx.Stackix(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e6f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'RNA', 9 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_062', 'RESTING_129', 'RESTING_140', 'RESTING_141', 'RESTING_146', 'RESTING_179', 'RESTING_185', 'RESTING_253', 'RESTING_318']\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'mutation', 5 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_062', 'RESTING_140', 'RESTING_141', 'RESTING_146', 'RESTING_253']\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'cell_deconvolution', 9 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_062', 'RESTING_129', 'RESTING_140', 'RESTING_141', 'RESTING_146', 'RESTING_179', 'RESTING_185', 'RESTING_253', 'RESTING_318']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_dfs keys in process_multi_bulk: dict_keys(['RNA', 'mutation', 'radiology', 'cell_deconvolution'])\n",
      "--- Running Pairing-Aware Split ---\n",
      "Identified 56 fully paired samples across all modalities.\n",
      "Identified 115 samples present in at least one, but not all, modalities.\n",
      "Successfully generated synchronized indices for all modalities.\n",
      "Training each modality model...\n",
      "Training modality: RNA\n",
      "Training modality: RNA\n",
      "Epoch 1 - Train Loss: 1169.8654\n",
      "Sub-losses: recon_loss: 1169.8643, var_loss: 245.2240, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 130.7664\n",
      "Sub-losses: recon_loss: 130.7664, var_loss: 3.1480, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 1191.8819\n",
      "Sub-losses: recon_loss: 1191.8806, var_loss: 232.5216, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 126.2228\n",
      "Sub-losses: recon_loss: 126.2228, var_loss: 4.1985, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 1121.4524\n",
      "Sub-losses: recon_loss: 1121.4509, var_loss: 229.5559, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Valid Loss: 128.2569\n",
      "Sub-losses: recon_loss: 128.2568, var_loss: 6.1995, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Train Loss: 1062.7347\n",
      "Sub-losses: recon_loss: 1062.7328, var_loss: 234.8352, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Valid Loss: 105.9347\n",
      "Sub-losses: recon_loss: 105.9346, var_loss: 8.6674, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Train Loss: 1019.6584\n",
      "Sub-losses: recon_loss: 1019.6561, var_loss: 234.4106, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Valid Loss: 123.8285\n",
      "Sub-losses: recon_loss: 123.8284, var_loss: 10.2374, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Train Loss: 1045.0600\n",
      "Sub-losses: recon_loss: 1045.0566, var_loss: 270.3899, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Valid Loss: 102.2937\n",
      "Sub-losses: recon_loss: 102.2936, var_loss: 12.4111, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Train Loss: 951.9769\n",
      "Sub-losses: recon_loss: 951.9735, var_loss: 228.1333, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Valid Loss: 117.1060\n",
      "Sub-losses: recon_loss: 117.1058, var_loss: 13.9338, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Train Loss: 992.2700\n",
      "Sub-losses: recon_loss: 992.2657, var_loss: 235.2700, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Valid Loss: 134.6640\n",
      "Sub-losses: recon_loss: 134.6637, var_loss: 15.4433, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Train Loss: 895.4163\n",
      "Sub-losses: recon_loss: 895.4110, var_loss: 232.5401, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Valid Loss: 108.2733\n",
      "Sub-losses: recon_loss: 108.2729, var_loss: 17.8873, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Train Loss: 933.7590\n",
      "Sub-losses: recon_loss: 933.7521, var_loss: 251.7951, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Valid Loss: 140.6200\n",
      "Sub-losses: recon_loss: 140.6195, var_loss: 18.6536, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Train Loss: 898.1645\n",
      "Sub-losses: recon_loss: 898.1559, var_loss: 257.1751, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Valid Loss: 106.1032\n",
      "Sub-losses: recon_loss: 106.1025, var_loss: 19.0164, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Train Loss: 792.9908\n",
      "Sub-losses: recon_loss: 792.9813, var_loss: 232.9825, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Valid Loss: 113.6731\n",
      "Sub-losses: recon_loss: 113.6723, var_loss: 18.7981, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 13 - Train Loss: 840.1112\n",
      "Sub-losses: recon_loss: 840.0993, var_loss: 238.5268, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 13 - Valid Loss: 122.3867\n",
      "Sub-losses: recon_loss: 122.3857, var_loss: 19.4065, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Train Loss: 832.1917\n",
      "Sub-losses: recon_loss: 832.1756, var_loss: 264.6040, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Valid Loss: 109.9394\n",
      "Sub-losses: recon_loss: 109.9381, var_loss: 20.0933, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Train Loss: 808.4023\n",
      "Sub-losses: recon_loss: 808.3832, var_loss: 255.0539, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Valid Loss: 113.0919\n",
      "Sub-losses: recon_loss: 113.0903, var_loss: 21.3359, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Train Loss: 838.8450\n",
      "Sub-losses: recon_loss: 838.8230, var_loss: 241.6863, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Valid Loss: 101.9466\n",
      "Sub-losses: recon_loss: 101.9446, var_loss: 21.8552, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Train Loss: 757.2745\n",
      "Sub-losses: recon_loss: 757.2451, var_loss: 264.6788, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Valid Loss: 97.5693\n",
      "Sub-losses: recon_loss: 97.5668, var_loss: 22.2374, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Train Loss: 726.2820\n",
      "Sub-losses: recon_loss: 726.2459, var_loss: 265.5263, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Valid Loss: 115.5656\n",
      "Sub-losses: recon_loss: 115.5626, var_loss: 21.9805, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 19 - Train Loss: 787.4257\n",
      "Sub-losses: recon_loss: 787.3813, var_loss: 267.9860, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 19 - Valid Loss: 113.5778\n",
      "Sub-losses: recon_loss: 113.5742, var_loss: 22.0187, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Train Loss: 719.7116\n",
      "Sub-losses: recon_loss: 719.6549, var_loss: 279.9753, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Valid Loss: 103.5346\n",
      "Sub-losses: recon_loss: 103.5299, var_loss: 23.2029, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Train Loss: 725.1304\n",
      "Sub-losses: recon_loss: 725.0698, var_loss: 245.1394, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Valid Loss: 103.3218\n",
      "Sub-losses: recon_loss: 103.3157, var_loss: 24.6843, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 22 - Train Loss: 741.8108\n",
      "Sub-losses: recon_loss: 741.7320, var_loss: 261.1993, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 22 - Valid Loss: 105.1289\n",
      "Sub-losses: recon_loss: 105.1208, var_loss: 26.7133, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 23 - Train Loss: 765.1537\n",
      "Sub-losses: recon_loss: 765.0583, var_loss: 258.8396, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 23 - Valid Loss: 101.9954\n",
      "Sub-losses: recon_loss: 101.9857, var_loss: 26.2391, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Train Loss: 674.8961\n",
      "Sub-losses: recon_loss: 674.7740, var_loss: 271.5595, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Valid Loss: 101.7591\n",
      "Sub-losses: recon_loss: 101.7469, var_loss: 27.0338, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 25 - Train Loss: 676.0004\n",
      "Sub-losses: recon_loss: 675.8261, var_loss: 317.6269, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 25 - Valid Loss: 103.5563\n",
      "Sub-losses: recon_loss: 103.5415, var_loss: 26.8929, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 26 - Train Loss: 719.3135\n",
      "Sub-losses: recon_loss: 719.1320, var_loss: 271.1525, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 26 - Valid Loss: 108.3531\n",
      "Sub-losses: recon_loss: 108.3345, var_loss: 27.8738, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 27 - Train Loss: 685.9025\n",
      "Sub-losses: recon_loss: 685.6623, var_loss: 294.3358, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 27 - Valid Loss: 94.5948\n",
      "Sub-losses: recon_loss: 94.5698, var_loss: 30.6616, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 28 - Train Loss: 702.6074\n",
      "Sub-losses: recon_loss: 702.2909, var_loss: 318.0406, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 28 - Valid Loss: 103.2924\n",
      "Sub-losses: recon_loss: 103.2613, var_loss: 31.1978, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 29 - Train Loss: 686.6465\n",
      "Sub-losses: recon_loss: 686.2495, var_loss: 327.3263, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 29 - Valid Loss: 107.7074\n",
      "Sub-losses: recon_loss: 107.6680, var_loss: 32.4567, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 30 - Train Loss: 687.2455\n",
      "Sub-losses: recon_loss: 686.7409, var_loss: 341.5643, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 30 - Valid Loss: 108.2656\n",
      "Sub-losses: recon_loss: 108.2192, var_loss: 31.3513, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 31 - Train Loss: 708.9957\n",
      "Sub-losses: recon_loss: 708.3513, var_loss: 358.2571, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 31 - Valid Loss: 103.0764\n",
      "Sub-losses: recon_loss: 103.0168, var_loss: 33.1000, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 32 - Train Loss: 667.4384\n",
      "Sub-losses: recon_loss: 666.6832, var_loss: 345.1448, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 32 - Valid Loss: 104.7365\n",
      "Sub-losses: recon_loss: 104.6661, var_loss: 32.1673, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 33 - Train Loss: 665.6034\n",
      "Sub-losses: recon_loss: 664.7744, var_loss: 311.7106, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 33 - Valid Loss: 107.5870\n",
      "Sub-losses: recon_loss: 107.5018, var_loss: 32.0368, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 34 - Train Loss: 687.9542\n",
      "Sub-losses: recon_loss: 686.7759, var_loss: 364.8579, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 34 - Valid Loss: 96.3382\n",
      "Sub-losses: recon_loss: 96.2328, var_loss: 32.6512, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 35 - Train Loss: 644.1114\n",
      "Sub-losses: recon_loss: 642.8424, var_loss: 324.0001, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 35 - Valid Loss: 94.9303\n",
      "Sub-losses: recon_loss: 94.7980, var_loss: 33.7802, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 36 - Train Loss: 667.6283\n",
      "Sub-losses: recon_loss: 665.7797, var_loss: 389.7857, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 36 - Valid Loss: 99.5652\n",
      "Sub-losses: recon_loss: 99.3859, var_loss: 37.8120, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 37 - Train Loss: 606.1250\n",
      "Sub-losses: recon_loss: 603.8654, var_loss: 394.1765, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 37 - Valid Loss: 87.5220\n",
      "Sub-losses: recon_loss: 87.3022, var_loss: 38.3435, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 38 - Train Loss: 658.2055\n",
      "Sub-losses: recon_loss: 655.6067, var_loss: 375.8809, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 38 - Valid Loss: 95.7660\n",
      "Sub-losses: recon_loss: 95.5130, var_loss: 36.5974, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 39 - Train Loss: 634.9689\n",
      "Sub-losses: recon_loss: 631.5807, var_loss: 407.3678, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 39 - Valid Loss: 102.3866\n",
      "Sub-losses: recon_loss: 102.0631, var_loss: 38.8926, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 40 - Train Loss: 631.7083\n",
      "Sub-losses: recon_loss: 627.7407, var_loss: 397.7537, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 40 - Valid Loss: 100.9601\n",
      "Sub-losses: recon_loss: 100.5699, var_loss: 39.1141, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 41 - Train Loss: 639.5355\n",
      "Sub-losses: recon_loss: 634.3149, var_loss: 437.9610, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 41 - Valid Loss: 93.2621\n",
      "Sub-losses: recon_loss: 92.7958, var_loss: 39.1159, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 42 - Train Loss: 673.5721\n",
      "Sub-losses: recon_loss: 667.8417, var_loss: 403.9745, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 42 - Valid Loss: 98.2653\n",
      "Sub-losses: recon_loss: 97.6996, var_loss: 39.8769, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 43 - Train Loss: 598.5693\n",
      "Sub-losses: recon_loss: 592.0759, var_loss: 386.5557, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 43 - Valid Loss: 97.7032\n",
      "Sub-losses: recon_loss: 97.0732, var_loss: 37.5057, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 44 - Train Loss: 591.2004\n",
      "Sub-losses: recon_loss: 583.8750, var_loss: 370.3139, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 44 - Valid Loss: 99.7403\n",
      "Sub-losses: recon_loss: 98.9729, var_loss: 38.7968, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 45 - Train Loss: 673.6485\n",
      "Sub-losses: recon_loss: 664.2919, var_loss: 404.2168, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 45 - Valid Loss: 96.1834\n",
      "Sub-losses: recon_loss: 95.3266, var_loss: 37.0165, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 46 - Train Loss: 635.0665\n",
      "Sub-losses: recon_loss: 625.7264, var_loss: 347.2922, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 46 - Valid Loss: 91.7653\n",
      "Sub-losses: recon_loss: 90.7706, var_loss: 36.9860, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 47 - Train Loss: 642.2674\n",
      "Sub-losses: recon_loss: 631.4611, var_loss: 348.5623, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 47 - Valid Loss: 101.5300\n",
      "Sub-losses: recon_loss: 100.3185, var_loss: 39.0768, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 48 - Train Loss: 614.5003\n",
      "Sub-losses: recon_loss: 602.9187, var_loss: 326.8446, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 48 - Valid Loss: 105.7372\n",
      "Sub-losses: recon_loss: 104.4035, var_loss: 37.6389, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 49 - Train Loss: 629.2207\n",
      "Sub-losses: recon_loss: 613.6763, var_loss: 387.3380, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 49 - Valid Loss: 103.8693\n",
      "Sub-losses: recon_loss: 102.3863, var_loss: 36.9537, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 50 - Train Loss: 634.1597\n",
      "Sub-losses: recon_loss: 616.8520, var_loss: 384.4758, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 50 - Valid Loss: 102.4905\n",
      "Sub-losses: recon_loss: 100.8380, var_loss: 36.7083, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 51 - Train Loss: 637.7700\n",
      "Sub-losses: recon_loss: 616.7075, var_loss: 421.2505, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 51 - Valid Loss: 93.5942\n",
      "Sub-losses: recon_loss: 91.7320, var_loss: 37.2454, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 52 - Train Loss: 614.9209\n",
      "Sub-losses: recon_loss: 591.8661, var_loss: 419.3040, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 52 - Valid Loss: 99.5634\n",
      "Sub-losses: recon_loss: 97.5596, var_loss: 36.4425, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 53 - Train Loss: 646.3370\n",
      "Sub-losses: recon_loss: 624.4415, var_loss: 365.7247, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 53 - Valid Loss: 92.6363\n",
      "Sub-losses: recon_loss: 90.3837, var_loss: 37.6249, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 54 - Train Loss: 626.1172\n",
      "Sub-losses: recon_loss: 600.2300, var_loss: 400.9431, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 54 - Valid Loss: 99.5420\n",
      "Sub-losses: recon_loss: 97.1500, var_loss: 37.0474, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 55 - Train Loss: 622.1472\n",
      "Sub-losses: recon_loss: 597.1637, var_loss: 362.0937, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 55 - Valid Loss: 92.3610\n",
      "Sub-losses: recon_loss: 89.7442, var_loss: 37.9264, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 56 - Train Loss: 653.1086\n",
      "Sub-losses: recon_loss: 626.9176, var_loss: 358.2620, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 56 - Valid Loss: 96.9240\n",
      "Sub-losses: recon_loss: 94.1113, var_loss: 38.4747, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 57 - Train Loss: 600.3595\n",
      "Sub-losses: recon_loss: 571.7780, var_loss: 371.9003, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 57 - Valid Loss: 96.5236\n",
      "Sub-losses: recon_loss: 93.5767, var_loss: 38.3441, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 58 - Train Loss: 604.8552\n",
      "Sub-losses: recon_loss: 580.2249, var_loss: 307.0404, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 58 - Valid Loss: 97.5358\n",
      "Sub-losses: recon_loss: 94.5105, var_loss: 37.7128, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 59 - Train Loss: 603.1185\n",
      "Sub-losses: recon_loss: 572.3662, var_loss: 369.6107, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 59 - Valid Loss: 97.2690\n",
      "Sub-losses: recon_loss: 94.1842, var_loss: 37.0764, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 60 - Train Loss: 643.5052\n",
      "Sub-losses: recon_loss: 611.5066, var_loss: 372.8790, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 60 - Valid Loss: 101.2473\n",
      "Sub-losses: recon_loss: 98.0406, var_loss: 37.3677, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 61 - Train Loss: 648.2162\n",
      "Sub-losses: recon_loss: 613.5987, var_loss: 393.0249, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 61 - Valid Loss: 100.8689\n",
      "Sub-losses: recon_loss: 97.6127, var_loss: 36.9692, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 62 - Train Loss: 632.9892\n",
      "Sub-losses: recon_loss: 601.6208, var_loss: 348.4420, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 62 - Valid Loss: 89.3589\n",
      "Sub-losses: recon_loss: 86.1405, var_loss: 35.7497, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 63 - Train Loss: 633.6631\n",
      "Sub-losses: recon_loss: 601.1637, var_loss: 354.4763, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 63 - Valid Loss: 94.1143\n",
      "Sub-losses: recon_loss: 90.8570, var_loss: 35.5278, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 64 - Train Loss: 617.6237\n",
      "Sub-losses: recon_loss: 588.1107, var_loss: 317.0510, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 64 - Valid Loss: 93.1622\n",
      "Sub-losses: recon_loss: 90.1463, var_loss: 32.3996, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 65 - Train Loss: 625.8640\n",
      "Sub-losses: recon_loss: 594.1556, var_loss: 336.3660, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 65 - Valid Loss: 91.6855\n",
      "Sub-losses: recon_loss: 88.4866, var_loss: 33.9343, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 66 - Train Loss: 629.1377\n",
      "Sub-losses: recon_loss: 602.7708, var_loss: 276.7964, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 66 - Valid Loss: 92.8297\n",
      "Sub-losses: recon_loss: 89.6993, var_loss: 32.8625, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 67 - Train Loss: 618.1466\n",
      "Sub-losses: recon_loss: 589.9320, var_loss: 293.6474, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 67 - Valid Loss: 93.1746\n",
      "Sub-losses: recon_loss: 90.0583, var_loss: 32.4334, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 68 - Train Loss: 623.8837\n",
      "Sub-losses: recon_loss: 592.4246, var_loss: 325.0905, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 68 - Valid Loss: 105.8209\n",
      "Sub-losses: recon_loss: 102.7255, var_loss: 31.9870, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 69 - Train Loss: 638.2755\n",
      "Sub-losses: recon_loss: 609.1722, var_loss: 298.9851, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 69 - Valid Loss: 94.6145\n",
      "Sub-losses: recon_loss: 91.2697, var_loss: 34.3617, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 70 - Train Loss: 608.9262\n",
      "Sub-losses: recon_loss: 579.5839, var_loss: 299.9864, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 70 - Valid Loss: 90.4342\n",
      "Sub-losses: recon_loss: 87.2951, var_loss: 32.0934, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 71 - Train Loss: 611.6639\n",
      "Sub-losses: recon_loss: 583.0539, var_loss: 291.3402, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 71 - Valid Loss: 98.0851\n",
      "Sub-losses: recon_loss: 94.9056, var_loss: 32.3777, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 72 - Train Loss: 627.4837\n",
      "Sub-losses: recon_loss: 597.3598, var_loss: 305.7565, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 72 - Valid Loss: 89.8698\n",
      "Sub-losses: recon_loss: 86.5714, var_loss: 33.4793, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 73 - Train Loss: 579.5504\n",
      "Sub-losses: recon_loss: 550.6565, var_loss: 292.4863, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 73 - Valid Loss: 101.5926\n",
      "Sub-losses: recon_loss: 98.2754, var_loss: 33.5797, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 74 - Train Loss: 576.2245\n",
      "Sub-losses: recon_loss: 550.3887, var_loss: 260.9557, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 74 - Valid Loss: 96.8091\n",
      "Sub-losses: recon_loss: 93.5243, var_loss: 33.1781, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 75 - Train Loss: 601.7173\n",
      "Sub-losses: recon_loss: 572.8845, var_loss: 290.7012, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 75 - Valid Loss: 91.0777\n",
      "Sub-losses: recon_loss: 87.8472, var_loss: 32.5710, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 76 - Train Loss: 610.6360\n",
      "Sub-losses: recon_loss: 582.2800, var_loss: 285.4704, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 76 - Valid Loss: 102.1802\n",
      "Sub-losses: recon_loss: 98.9528, var_loss: 32.4918, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 77 - Train Loss: 595.1090\n",
      "Sub-losses: recon_loss: 567.7936, var_loss: 274.6606, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 77 - Valid Loss: 96.6793\n",
      "Sub-losses: recon_loss: 93.5373, var_loss: 31.5930, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 78 - Train Loss: 665.7167\n",
      "Sub-losses: recon_loss: 638.1401, var_loss: 277.0112, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 78 - Valid Loss: 86.5038\n",
      "Sub-losses: recon_loss: 83.4271, var_loss: 30.9060, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Train Loss: 626.6851\n",
      "Sub-losses: recon_loss: 599.9480, var_loss: 268.3595, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Valid Loss: 95.9916\n",
      "Sub-losses: recon_loss: 92.8074, var_loss: 31.9606, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 80 - Train Loss: 615.4204\n",
      "Sub-losses: recon_loss: 588.8718, var_loss: 266.2899, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 80 - Valid Loss: 93.9574\n",
      "Sub-losses: recon_loss: 90.7493, var_loss: 32.1777, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 81 - Train Loss: 595.2120\n",
      "Sub-losses: recon_loss: 568.1368, var_loss: 271.4236, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 81 - Valid Loss: 92.5946\n",
      "Sub-losses: recon_loss: 89.3419, var_loss: 32.6077, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Train Loss: 603.9303\n",
      "Sub-losses: recon_loss: 578.7321, var_loss: 252.4940, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Valid Loss: 100.7259\n",
      "Sub-losses: recon_loss: 97.6236, var_loss: 31.0860, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Train Loss: 582.4707\n",
      "Sub-losses: recon_loss: 555.6081, var_loss: 269.0729, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Valid Loss: 92.2255\n",
      "Sub-losses: recon_loss: 89.1794, var_loss: 30.5112, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 84 - Train Loss: 583.2609\n",
      "Sub-losses: recon_loss: 555.0521, var_loss: 282.4717, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 84 - Valid Loss: 93.2933\n",
      "Sub-losses: recon_loss: 90.2361, var_loss: 30.6135, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Train Loss: 597.4163\n",
      "Sub-losses: recon_loss: 570.1513, var_loss: 272.9533, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Valid Loss: 83.2618\n",
      "Sub-losses: recon_loss: 80.2995, var_loss: 29.6559, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Train Loss: 584.2358\n",
      "Sub-losses: recon_loss: 557.3430, var_loss: 269.1727, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Valid Loss: 77.0633\n",
      "Sub-losses: recon_loss: 74.1549, var_loss: 29.1105, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Train Loss: 593.5086\n",
      "Sub-losses: recon_loss: 569.2480, var_loss: 242.7877, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Valid Loss: 89.3613\n",
      "Sub-losses: recon_loss: 86.4466, var_loss: 29.1688, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Train Loss: 606.2001\n",
      "Sub-losses: recon_loss: 577.3772, var_loss: 288.4052, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Valid Loss: 98.9435\n",
      "Sub-losses: recon_loss: 96.0327, var_loss: 29.1252, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Train Loss: 614.1106\n",
      "Sub-losses: recon_loss: 587.9388, var_loss: 261.8485, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Valid Loss: 95.0539\n",
      "Sub-losses: recon_loss: 92.3006, var_loss: 27.5469, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 90 - Train Loss: 585.6919\n",
      "Sub-losses: recon_loss: 561.4929, var_loss: 242.0891, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 90 - Valid Loss: 94.4283\n",
      "Sub-losses: recon_loss: 91.6041, var_loss: 28.2544, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Train Loss: 636.5212\n",
      "Sub-losses: recon_loss: 610.3618, var_loss: 261.6824, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Valid Loss: 89.7394\n",
      "Sub-losses: recon_loss: 87.0382, var_loss: 27.0208, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Train Loss: 589.0297\n",
      "Sub-losses: recon_loss: 562.1025, var_loss: 269.3458, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Valid Loss: 100.5657\n",
      "Sub-losses: recon_loss: 97.6901, var_loss: 28.7635, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Train Loss: 601.4806\n",
      "Sub-losses: recon_loss: 574.4075, var_loss: 270.7927, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Valid Loss: 93.7338\n",
      "Sub-losses: recon_loss: 90.8247, var_loss: 29.0974, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Train Loss: 593.7919\n",
      "Sub-losses: recon_loss: 566.0884, var_loss: 277.0865, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Valid Loss: 99.1506\n",
      "Sub-losses: recon_loss: 96.0968, var_loss: 30.5438, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Train Loss: 561.2802\n",
      "Sub-losses: recon_loss: 535.7143, var_loss: 255.6973, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Valid Loss: 90.8322\n",
      "Sub-losses: recon_loss: 87.7768, var_loss: 30.5583, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Train Loss: 584.3254\n",
      "Sub-losses: recon_loss: 557.1803, var_loss: 271.4850, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Valid Loss: 89.8559\n",
      "Sub-losses: recon_loss: 86.7802, var_loss: 30.7602, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Train Loss: 591.1725\n",
      "Sub-losses: recon_loss: 564.0766, var_loss: 270.9863, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Valid Loss: 84.9482\n",
      "Sub-losses: recon_loss: 82.0040, var_loss: 29.4449, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Train Loss: 594.6835\n",
      "Sub-losses: recon_loss: 568.6420, var_loss: 260.4372, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Valid Loss: 93.7894\n",
      "Sub-losses: recon_loss: 91.0076, var_loss: 27.8202, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Train Loss: 625.9417\n",
      "Sub-losses: recon_loss: 600.2532, var_loss: 256.9030, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Valid Loss: 97.0204\n",
      "Sub-losses: recon_loss: 94.2514, var_loss: 27.6919, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Train Loss: 563.5023\n",
      "Sub-losses: recon_loss: 537.4642, var_loss: 260.3947, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Valid Loss: 93.5897\n",
      "Sub-losses: recon_loss: 90.8709, var_loss: 27.1898, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Training modality: mutation\n",
      "Training modality: mutation\n",
      "Epoch 1 - Train Loss: 980.4124\n",
      "Sub-losses: recon_loss: 980.4098, var_loss: 577.0710, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 103.3574\n",
      "Sub-losses: recon_loss: 103.3574, var_loss: 9.1296, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 988.5418\n",
      "Sub-losses: recon_loss: 988.5388, var_loss: 544.5954, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 112.0010\n",
      "Sub-losses: recon_loss: 112.0009, var_loss: 12.7018, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 905.9343\n",
      "Sub-losses: recon_loss: 905.9302, var_loss: 602.7276, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Valid Loss: 106.6525\n",
      "Sub-losses: recon_loss: 106.6524, var_loss: 16.5286, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Train Loss: 842.6919\n",
      "Sub-losses: recon_loss: 842.6870, var_loss: 589.8886, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Valid Loss: 94.3098\n",
      "Sub-losses: recon_loss: 94.3096, var_loss: 20.7278, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Train Loss: 896.6772\n",
      "Sub-losses: recon_loss: 896.6715, var_loss: 561.3263, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Valid Loss: 99.0457\n",
      "Sub-losses: recon_loss: 99.0454, var_loss: 26.5365, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Train Loss: 904.1196\n",
      "Sub-losses: recon_loss: 904.1128, var_loss: 557.8516, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Valid Loss: 119.0590\n",
      "Sub-losses: recon_loss: 119.0586, var_loss: 31.0595, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Train Loss: 882.3130\n",
      "Sub-losses: recon_loss: 882.3032, var_loss: 652.1368, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Valid Loss: 111.3730\n",
      "Sub-losses: recon_loss: 111.3725, var_loss: 35.2541, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Train Loss: 806.3055\n",
      "Sub-losses: recon_loss: 806.2946, var_loss: 591.5022, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Valid Loss: 89.0026\n",
      "Sub-losses: recon_loss: 89.0018, var_loss: 38.5584, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Train Loss: 814.1340\n",
      "Sub-losses: recon_loss: 814.1195, var_loss: 643.3869, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Valid Loss: 108.1712\n",
      "Sub-losses: recon_loss: 108.1703, var_loss: 41.0959, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Train Loss: 779.8703\n",
      "Sub-losses: recon_loss: 779.8535, var_loss: 609.4368, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Valid Loss: 113.7368\n",
      "Sub-losses: recon_loss: 113.7356, var_loss: 43.1885, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Train Loss: 772.4134\n",
      "Sub-losses: recon_loss: 772.3926, var_loss: 618.6372, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Valid Loss: 105.4730\n",
      "Sub-losses: recon_loss: 105.4715, var_loss: 45.5840, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Train Loss: 791.2645\n",
      "Sub-losses: recon_loss: 791.2379, var_loss: 648.4899, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Valid Loss: 100.8277\n",
      "Sub-losses: recon_loss: 100.8257, var_loss: 48.7371, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 13 - Train Loss: 733.2604\n",
      "Sub-losses: recon_loss: 733.2256, var_loss: 694.3316, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 13 - Valid Loss: 93.2451\n",
      "Sub-losses: recon_loss: 93.2425, var_loss: 51.3509, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Train Loss: 774.4876\n",
      "Sub-losses: recon_loss: 774.4394, var_loss: 789.6985, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Valid Loss: 102.7933\n",
      "Sub-losses: recon_loss: 102.7898, var_loss: 56.5870, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Train Loss: 741.4928\n",
      "Sub-losses: recon_loss: 741.4398, var_loss: 710.7799, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Valid Loss: 101.5954\n",
      "Sub-losses: recon_loss: 101.5912, var_loss: 56.6666, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Train Loss: 657.9472\n",
      "Sub-losses: recon_loss: 657.8571, var_loss: 988.2923, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Valid Loss: 98.2790\n",
      "Sub-losses: recon_loss: 98.2740, var_loss: 54.6660, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Train Loss: 694.9406\n",
      "Sub-losses: recon_loss: 694.8490, var_loss: 823.1791, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Valid Loss: 99.5275\n",
      "Sub-losses: recon_loss: 99.5215, var_loss: 54.3182, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Train Loss: 707.0853\n",
      "Sub-losses: recon_loss: 706.9364, var_loss: 1095.5664, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Valid Loss: 109.5393\n",
      "Sub-losses: recon_loss: 109.5314, var_loss: 58.1535, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 19 - Train Loss: 694.3859\n",
      "Sub-losses: recon_loss: 694.2388, var_loss: 887.1418, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 19 - Valid Loss: 94.8516\n",
      "Sub-losses: recon_loss: 94.8426, var_loss: 54.1153, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Train Loss: 670.1939\n",
      "Sub-losses: recon_loss: 670.0239, var_loss: 839.2451, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Valid Loss: 95.9424\n",
      "Sub-losses: recon_loss: 95.9317, var_loss: 52.8574, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Train Loss: 674.7673\n",
      "Sub-losses: recon_loss: 674.4278, var_loss: 1372.9521, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Valid Loss: 101.1494\n",
      "Sub-losses: recon_loss: 101.1362, var_loss: 53.2085, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 22 - Train Loss: 693.4740\n",
      "Sub-losses: recon_loss: 693.1773, var_loss: 982.9391, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 22 - Valid Loss: 89.3392\n",
      "Sub-losses: recon_loss: 89.3227, var_loss: 54.6931, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 23 - Train Loss: 648.3202\n",
      "Sub-losses: recon_loss: 647.9964, var_loss: 879.0594, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 23 - Valid Loss: 98.9329\n",
      "Sub-losses: recon_loss: 98.9105, var_loss: 60.8384, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Train Loss: 653.8229\n",
      "Sub-losses: recon_loss: 653.5281, var_loss: 655.6548, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Valid Loss: 102.6763\n",
      "Sub-losses: recon_loss: 102.6493, var_loss: 59.9662, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 25 - Train Loss: 660.7980\n",
      "Sub-losses: recon_loss: 659.9595, var_loss: 1528.3890, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 25 - Valid Loss: 97.0590\n",
      "Sub-losses: recon_loss: 97.0256, var_loss: 60.9130, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 26 - Train Loss: 663.9120\n",
      "Sub-losses: recon_loss: 662.9285, var_loss: 1469.4272, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 26 - Valid Loss: 100.1132\n",
      "Sub-losses: recon_loss: 100.0720, var_loss: 61.5696, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 27 - Train Loss: 625.8042\n",
      "Sub-losses: recon_loss: 625.0844, var_loss: 881.8321, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 27 - Valid Loss: 88.3544\n",
      "Sub-losses: recon_loss: 88.3034, var_loss: 62.5293, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 28 - Train Loss: 645.4604\n",
      "Sub-losses: recon_loss: 643.4190, var_loss: 2051.2184, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 28 - Valid Loss: 88.7112\n",
      "Sub-losses: recon_loss: 88.6471, var_loss: 64.4057, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 29 - Train Loss: 593.2658\n",
      "Sub-losses: recon_loss: 592.0867, var_loss: 972.1642, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 29 - Valid Loss: 96.8175\n",
      "Sub-losses: recon_loss: 96.7395, var_loss: 64.2582, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 30 - Train Loss: 614.9246\n",
      "Sub-losses: recon_loss: 613.6884, var_loss: 836.7313, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 30 - Valid Loss: 91.0275\n",
      "Sub-losses: recon_loss: 90.9305, var_loss: 65.6835, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 31 - Train Loss: 628.0854\n",
      "Sub-losses: recon_loss: 625.1459, var_loss: 1634.3096, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 31 - Valid Loss: 91.9676\n",
      "Sub-losses: recon_loss: 91.8460, var_loss: 67.5804, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 32 - Train Loss: 651.4923\n",
      "Sub-losses: recon_loss: 648.6596, var_loss: 1294.5773, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 32 - Valid Loss: 98.3782\n",
      "Sub-losses: recon_loss: 98.2292, var_loss: 68.1068, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 33 - Train Loss: 627.5197\n",
      "Sub-losses: recon_loss: 623.5707, var_loss: 1484.7527, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 33 - Valid Loss: 84.9041\n",
      "Sub-losses: recon_loss: 84.7303, var_loss: 65.3205, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 34 - Train Loss: 596.3184\n",
      "Sub-losses: recon_loss: 591.6108, var_loss: 1457.6718, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 34 - Valid Loss: 91.6935\n",
      "Sub-losses: recon_loss: 91.4688, var_loss: 69.5767, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 35 - Train Loss: 636.4723\n",
      "Sub-losses: recon_loss: 631.9956, var_loss: 1143.0172, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 35 - Valid Loss: 97.7936\n",
      "Sub-losses: recon_loss: 97.5096, var_loss: 72.5193, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 36 - Train Loss: 586.7618\n",
      "Sub-losses: recon_loss: 579.2673, var_loss: 1580.2598, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 36 - Valid Loss: 84.7586\n",
      "Sub-losses: recon_loss: 84.4265, var_loss: 70.0377, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 37 - Train Loss: 601.2944\n",
      "Sub-losses: recon_loss: 594.0778, var_loss: 1258.9247, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 37 - Valid Loss: 85.7453\n",
      "Sub-losses: recon_loss: 85.3447, var_loss: 69.8811, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 38 - Train Loss: 626.4326\n",
      "Sub-losses: recon_loss: 617.9500, var_loss: 1226.9136, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 38 - Valid Loss: 89.2618\n",
      "Sub-losses: recon_loss: 88.7832, var_loss: 69.2152, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 39 - Train Loss: 611.0365\n",
      "Sub-losses: recon_loss: 602.4742, var_loss: 1029.4648, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 39 - Valid Loss: 100.2827\n",
      "Sub-losses: recon_loss: 99.7001, var_loss: 70.0546, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 40 - Train Loss: 637.3183\n",
      "Sub-losses: recon_loss: 627.5681, var_loss: 977.4550, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 40 - Valid Loss: 97.5812\n",
      "Sub-losses: recon_loss: 96.8529, var_loss: 73.0124, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 41 - Train Loss: 600.9429\n",
      "Sub-losses: recon_loss: 581.2819, var_loss: 1649.3761, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 41 - Valid Loss: 83.9542\n",
      "Sub-losses: recon_loss: 83.0556, var_loss: 75.3791, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 42 - Train Loss: 601.8115\n",
      "Sub-losses: recon_loss: 586.7887, var_loss: 1059.0594, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 42 - Valid Loss: 88.4433\n",
      "Sub-losses: recon_loss: 87.3689, var_loss: 75.7379, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 43 - Train Loss: 602.2940\n",
      "Sub-losses: recon_loss: 586.1763, var_loss: 959.4945, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 43 - Valid Loss: 90.1743\n",
      "Sub-losses: recon_loss: 88.9616, var_loss: 72.1903, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 44 - Train Loss: 633.1244\n",
      "Sub-losses: recon_loss: 612.8417, var_loss: 1025.3282, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 44 - Valid Loss: 92.5705\n",
      "Sub-losses: recon_loss: 91.1222, var_loss: 73.2161, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 45 - Train Loss: 617.8830\n",
      "Sub-losses: recon_loss: 592.9272, var_loss: 1078.1189, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 45 - Valid Loss: 91.6587\n",
      "Sub-losses: recon_loss: 90.0414, var_loss: 69.8678, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 46 - Train Loss: 617.5731\n",
      "Sub-losses: recon_loss: 582.3734, var_loss: 1308.8252, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 46 - Valid Loss: 88.7747\n",
      "Sub-losses: recon_loss: 86.9146, var_loss: 69.1638, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 47 - Train Loss: 614.5727\n",
      "Sub-losses: recon_loss: 577.6608, var_loss: 1190.6090, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 47 - Valid Loss: 89.5372\n",
      "Sub-losses: recon_loss: 87.4027, var_loss: 68.8493, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 48 - Train Loss: 608.6843\n",
      "Sub-losses: recon_loss: 571.6673, var_loss: 1044.6633, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 48 - Valid Loss: 92.4796\n",
      "Sub-losses: recon_loss: 89.9351, var_loss: 71.8083, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 49 - Train Loss: 632.1581\n",
      "Sub-losses: recon_loss: 591.3135, var_loss: 1017.7744, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 49 - Valid Loss: 90.4542\n",
      "Sub-losses: recon_loss: 87.6701, var_loss: 69.3756, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 50 - Train Loss: 612.8969\n",
      "Sub-losses: recon_loss: 575.4391, var_loss: 832.0862, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 50 - Valid Loss: 91.8201\n",
      "Sub-losses: recon_loss: 88.8520, var_loss: 65.9335, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 51 - Train Loss: 612.9653\n",
      "Sub-losses: recon_loss: 575.6134, var_loss: 747.0376, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 51 - Valid Loss: 89.2628\n",
      "Sub-losses: recon_loss: 85.9459, var_loss: 66.3372, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 52 - Train Loss: 614.1360\n",
      "Sub-losses: recon_loss: 574.8777, var_loss: 714.0027, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 52 - Valid Loss: 89.0363\n",
      "Sub-losses: recon_loss: 85.5406, var_loss: 63.5765, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 53 - Train Loss: 623.1261\n",
      "Sub-losses: recon_loss: 579.9051, var_loss: 721.9298, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 53 - Valid Loss: 93.2906\n",
      "Sub-losses: recon_loss: 89.3667, var_loss: 65.5405, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 54 - Train Loss: 656.4188\n",
      "Sub-losses: recon_loss: 605.1900, var_loss: 793.4372, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 54 - Valid Loss: 89.9332\n",
      "Sub-losses: recon_loss: 85.6957, var_loss: 65.6307, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 55 - Train Loss: 628.0849\n",
      "Sub-losses: recon_loss: 573.7159, var_loss: 787.9857, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 55 - Valid Loss: 89.4848\n",
      "Sub-losses: recon_loss: 84.5717, var_loss: 71.2073, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 56 - Train Loss: 640.0217\n",
      "Sub-losses: recon_loss: 597.2577, var_loss: 584.9601, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 56 - Valid Loss: 89.1562\n",
      "Sub-losses: recon_loss: 84.1668, var_loss: 68.2498, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 57 - Train Loss: 624.1500\n",
      "Sub-losses: recon_loss: 575.0473, var_loss: 638.9217, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 57 - Valid Loss: 92.9209\n",
      "Sub-losses: recon_loss: 87.6523, var_loss: 68.5556, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 58 - Train Loss: 635.6547\n",
      "Sub-losses: recon_loss: 584.7611, var_loss: 634.4377, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 58 - Valid Loss: 97.0841\n",
      "Sub-losses: recon_loss: 91.9053, var_loss: 64.5588, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 59 - Train Loss: 619.5713\n",
      "Sub-losses: recon_loss: 568.8543, var_loss: 609.5652, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 59 - Valid Loss: 94.1208\n",
      "Sub-losses: recon_loss: 88.8932, var_loss: 62.8308, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 60 - Train Loss: 644.2638\n",
      "Sub-losses: recon_loss: 592.3900, var_loss: 604.4846, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 60 - Valid Loss: 96.8195\n",
      "Sub-losses: recon_loss: 91.6934, var_loss: 59.7351, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 61 - Train Loss: 642.4401\n",
      "Sub-losses: recon_loss: 591.6451, var_loss: 576.6933, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 61 - Valid Loss: 97.6655\n",
      "Sub-losses: recon_loss: 92.3447, var_loss: 60.4089, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 62 - Train Loss: 624.5857\n",
      "Sub-losses: recon_loss: 567.9827, var_loss: 628.7487, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 62 - Valid Loss: 89.6796\n",
      "Sub-losses: recon_loss: 84.2043, var_loss: 60.8204, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 63 - Train Loss: 613.8241\n",
      "Sub-losses: recon_loss: 561.9429, var_loss: 565.8781, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 63 - Valid Loss: 96.6529\n",
      "Sub-losses: recon_loss: 91.1982, var_loss: 59.4955, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 64 - Train Loss: 637.3003\n",
      "Sub-losses: recon_loss: 587.2965, var_loss: 537.1777, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 64 - Valid Loss: 94.0717\n",
      "Sub-losses: recon_loss: 88.6265, var_loss: 58.4956, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 65 - Train Loss: 617.6108\n",
      "Sub-losses: recon_loss: 562.0538, var_loss: 589.3545, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 65 - Valid Loss: 101.9834\n",
      "Sub-losses: recon_loss: 96.7202, var_loss: 55.8323, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 66 - Train Loss: 637.0357\n",
      "Sub-losses: recon_loss: 583.2539, var_loss: 564.5943, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 66 - Valid Loss: 101.8186\n",
      "Sub-losses: recon_loss: 96.5497, var_loss: 55.3123, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 67 - Train Loss: 650.9809\n",
      "Sub-losses: recon_loss: 597.9960, var_loss: 551.4465, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 67 - Valid Loss: 90.3851\n",
      "Sub-losses: recon_loss: 85.0393, var_loss: 55.6378, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 68 - Train Loss: 629.7293\n",
      "Sub-losses: recon_loss: 576.6843, var_loss: 548.1530, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 68 - Valid Loss: 93.8406\n",
      "Sub-losses: recon_loss: 88.4324, var_loss: 55.8865, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 69 - Train Loss: 625.7136\n",
      "Sub-losses: recon_loss: 578.2125, var_loss: 487.9900, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 69 - Valid Loss: 91.3255\n",
      "Sub-losses: recon_loss: 86.1003, var_loss: 53.6795, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 70 - Train Loss: 594.8445\n",
      "Sub-losses: recon_loss: 550.2508, var_loss: 455.9131, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 70 - Valid Loss: 86.5838\n",
      "Sub-losses: recon_loss: 81.4931, var_loss: 52.0456, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 71 - Train Loss: 646.4626\n",
      "Sub-losses: recon_loss: 603.7339, var_loss: 435.1130, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 71 - Valid Loss: 91.2980\n",
      "Sub-losses: recon_loss: 86.4216, var_loss: 49.6578, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 72 - Train Loss: 625.4023\n",
      "Sub-losses: recon_loss: 580.3467, var_loss: 457.3122, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 72 - Valid Loss: 94.0460\n",
      "Sub-losses: recon_loss: 89.3132, var_loss: 48.0376, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 73 - Train Loss: 636.8806\n",
      "Sub-losses: recon_loss: 590.6379, var_loss: 468.1047, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 73 - Valid Loss: 86.7570\n",
      "Sub-losses: recon_loss: 82.2224, var_loss: 45.9028, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 74 - Train Loss: 612.2431\n",
      "Sub-losses: recon_loss: 564.3023, var_loss: 484.2270, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 74 - Valid Loss: 91.6699\n",
      "Sub-losses: recon_loss: 87.2315, var_loss: 44.8294, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 75 - Train Loss: 636.2363\n",
      "Sub-losses: recon_loss: 593.5414, var_loss: 430.4622, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 75 - Valid Loss: 90.4393\n",
      "Sub-losses: recon_loss: 85.8783, var_loss: 45.9849, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 76 - Train Loss: 604.0923\n",
      "Sub-losses: recon_loss: 558.3381, var_loss: 460.6253, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 76 - Valid Loss: 87.5558\n",
      "Sub-losses: recon_loss: 82.9949, var_loss: 45.9162, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 77 - Train Loss: 612.4829\n",
      "Sub-losses: recon_loss: 569.9537, var_loss: 427.6376, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 77 - Valid Loss: 94.5020\n",
      "Sub-losses: recon_loss: 89.7176, var_loss: 48.1079, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 78 - Train Loss: 625.0551\n",
      "Sub-losses: recon_loss: 581.1168, var_loss: 441.3676, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 78 - Valid Loss: 92.1434\n",
      "Sub-losses: recon_loss: 87.7769, var_loss: 43.8629, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Train Loss: 607.8710\n",
      "Sub-losses: recon_loss: 566.3853, var_loss: 416.3904, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Valid Loss: 90.4835\n",
      "Sub-losses: recon_loss: 86.1731, var_loss: 43.2636, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 80 - Train Loss: 623.6487\n",
      "Sub-losses: recon_loss: 582.3105, var_loss: 414.6334, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 80 - Valid Loss: 90.4133\n",
      "Sub-losses: recon_loss: 86.0182, var_loss: 44.0841, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 81 - Train Loss: 602.9690\n",
      "Sub-losses: recon_loss: 563.2184, var_loss: 398.4913, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 81 - Valid Loss: 93.5872\n",
      "Sub-losses: recon_loss: 89.1977, var_loss: 44.0037, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Train Loss: 603.0348\n",
      "Sub-losses: recon_loss: 563.0525, var_loss: 400.6346, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Valid Loss: 92.4076\n",
      "Sub-losses: recon_loss: 87.9954, var_loss: 44.2117, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Train Loss: 637.5102\n",
      "Sub-losses: recon_loss: 598.6837, var_loss: 388.9100, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Valid Loss: 87.3857\n",
      "Sub-losses: recon_loss: 83.3711, var_loss: 40.2129, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 84 - Train Loss: 626.7032\n",
      "Sub-losses: recon_loss: 589.0766, var_loss: 376.7779, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 84 - Valid Loss: 89.6894\n",
      "Sub-losses: recon_loss: 85.7251, var_loss: 39.6974, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Train Loss: 595.0122\n",
      "Sub-losses: recon_loss: 557.3361, var_loss: 377.1804, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Valid Loss: 90.4942\n",
      "Sub-losses: recon_loss: 86.6134, var_loss: 38.8517, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Train Loss: 617.0716\n",
      "Sub-losses: recon_loss: 582.1450, var_loss: 349.5848, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Valid Loss: 90.5464\n",
      "Sub-losses: recon_loss: 86.5196, var_loss: 40.3043, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Train Loss: 626.7693\n",
      "Sub-losses: recon_loss: 592.3608, var_loss: 344.3418, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Valid Loss: 91.2646\n",
      "Sub-losses: recon_loss: 87.4942, var_loss: 37.7319, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Train Loss: 582.7198\n",
      "Sub-losses: recon_loss: 546.9242, var_loss: 358.1750, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Valid Loss: 89.7900\n",
      "Sub-losses: recon_loss: 85.9860, var_loss: 38.0626, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Train Loss: 567.4594\n",
      "Sub-losses: recon_loss: 533.1954, var_loss: 342.8123, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Valid Loss: 89.3911\n",
      "Sub-losses: recon_loss: 85.6344, var_loss: 37.5854, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 90 - Train Loss: 573.1207\n",
      "Sub-losses: recon_loss: 537.7946, var_loss: 353.4052, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 90 - Valid Loss: 88.8223\n",
      "Sub-losses: recon_loss: 84.9891, var_loss: 38.3479, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Train Loss: 629.6490\n",
      "Sub-losses: recon_loss: 595.7971, var_loss: 338.6316, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Valid Loss: 90.2223\n",
      "Sub-losses: recon_loss: 86.5616, var_loss: 36.6189, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Train Loss: 609.0892\n",
      "Sub-losses: recon_loss: 579.2894, var_loss: 298.0791, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Valid Loss: 90.0426\n",
      "Sub-losses: recon_loss: 86.6077, var_loss: 34.3585, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Train Loss: 616.3240\n",
      "Sub-losses: recon_loss: 581.4237, var_loss: 349.0816, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Valid Loss: 86.6284\n",
      "Sub-losses: recon_loss: 83.0539, var_loss: 35.7525, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Train Loss: 590.5917\n",
      "Sub-losses: recon_loss: 554.5314, var_loss: 360.6689, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Valid Loss: 88.3322\n",
      "Sub-losses: recon_loss: 84.7057, var_loss: 36.2715, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Train Loss: 588.4272\n",
      "Sub-losses: recon_loss: 556.2642, var_loss: 321.6787, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Valid Loss: 86.5043\n",
      "Sub-losses: recon_loss: 82.7409, var_loss: 37.6399, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Train Loss: 582.4196\n",
      "Sub-losses: recon_loss: 547.5700, var_loss: 348.5389, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Valid Loss: 84.3659\n",
      "Sub-losses: recon_loss: 80.5015, var_loss: 38.6487, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Train Loss: 608.5359\n",
      "Sub-losses: recon_loss: 573.9633, var_loss: 345.7601, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Valid Loss: 88.4414\n",
      "Sub-losses: recon_loss: 84.6539, var_loss: 37.8792, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Train Loss: 579.8159\n",
      "Sub-losses: recon_loss: 548.8028, var_loss: 310.1571, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Valid Loss: 96.5658\n",
      "Sub-losses: recon_loss: 92.8951, var_loss: 36.7096, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Train Loss: 552.8686\n",
      "Sub-losses: recon_loss: 518.4462, var_loss: 344.2475, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Valid Loss: 82.5702\n",
      "Sub-losses: recon_loss: 78.9109, var_loss: 36.5953, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Train Loss: 591.0913\n",
      "Sub-losses: recon_loss: 556.5197, var_loss: 345.7356, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Valid Loss: 93.1773\n",
      "Sub-losses: recon_loss: 89.7273, var_loss: 34.5015, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Training modality: radiology\n",
      "Training modality: radiology\n",
      "Epoch 1 - Train Loss: 341.9249\n",
      "Sub-losses: recon_loss: 341.9184, var_loss: 1421.1364, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 3.9896\n",
      "Sub-losses: recon_loss: 3.9896, var_loss: 0.3682, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 438.8887\n",
      "Sub-losses: recon_loss: 438.8853, var_loss: 603.8534, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 4.4266\n",
      "Sub-losses: recon_loss: 4.4266, var_loss: 0.4284, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 366.0500\n",
      "Sub-losses: recon_loss: 366.0401, var_loss: 1455.7467, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Valid Loss: 9.5863\n",
      "Sub-losses: recon_loss: 9.5863, var_loss: 0.4262, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Train Loss: 455.8545\n",
      "Sub-losses: recon_loss: 455.8491, var_loss: 651.6950, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Valid Loss: 4.5379\n",
      "Sub-losses: recon_loss: 4.5379, var_loss: 0.5017, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Train Loss: 377.3946\n",
      "Sub-losses: recon_loss: 377.3888, var_loss: 573.2937, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Valid Loss: 5.8126\n",
      "Sub-losses: recon_loss: 5.8126, var_loss: 0.7278, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Train Loss: 383.3654\n",
      "Sub-losses: recon_loss: 383.3557, var_loss: 786.7247, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Valid Loss: 6.6506\n",
      "Sub-losses: recon_loss: 6.6505, var_loss: 0.8801, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Train Loss: 369.3394\n",
      "Sub-losses: recon_loss: 369.3001, var_loss: 2612.4668, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Valid Loss: 5.9464\n",
      "Sub-losses: recon_loss: 5.9464, var_loss: 1.0850, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Train Loss: 418.2016\n",
      "Sub-losses: recon_loss: 418.1918, var_loss: 531.3781, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Valid Loss: 9.1802\n",
      "Sub-losses: recon_loss: 9.1801, var_loss: 1.3281, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Train Loss: 401.5770\n",
      "Sub-losses: recon_loss: 401.5692, var_loss: 345.7343, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Valid Loss: 8.6363\n",
      "Sub-losses: recon_loss: 8.6363, var_loss: 1.5180, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Train Loss: 277.6484\n",
      "Sub-losses: recon_loss: 277.5867, var_loss: 2248.0324, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Valid Loss: 11.4469\n",
      "Sub-losses: recon_loss: 11.4468, var_loss: 1.6925, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Train Loss: 275.6097\n",
      "Sub-losses: recon_loss: 275.5569, var_loss: 1576.5852, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Valid Loss: 9.6497\n",
      "Sub-losses: recon_loss: 9.6496, var_loss: 1.6521, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Train Loss: 406.4551\n",
      "Sub-losses: recon_loss: 406.3943, var_loss: 1484.0583, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Valid Loss: 5.1893\n",
      "Sub-losses: recon_loss: 5.1892, var_loss: 1.8851, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 13 - Train Loss: 407.4274\n",
      "Sub-losses: recon_loss: 407.3839, var_loss: 870.2691, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 13 - Valid Loss: 7.7680\n",
      "Sub-losses: recon_loss: 7.7679, var_loss: 2.0592, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Train Loss: 294.4415\n",
      "Sub-losses: recon_loss: 294.3701, var_loss: 1168.4912, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Valid Loss: 7.7804\n",
      "Sub-losses: recon_loss: 7.7803, var_loss: 1.8140, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Train Loss: 298.7299\n",
      "Sub-losses: recon_loss: 298.6670, var_loss: 843.8982, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Valid Loss: 7.2734\n",
      "Sub-losses: recon_loss: 7.2733, var_loss: 2.0793, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Train Loss: 341.3263\n",
      "Sub-losses: recon_loss: 341.2291, var_loss: 1066.9789, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Valid Loss: 11.0356\n",
      "Sub-losses: recon_loss: 11.0353, var_loss: 2.7650, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Train Loss: 339.4193\n",
      "Sub-losses: recon_loss: 339.2906, var_loss: 1156.7809, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Valid Loss: 8.9612\n",
      "Sub-losses: recon_loss: 8.9609, var_loss: 2.6788, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Train Loss: 346.2049\n",
      "Sub-losses: recon_loss: 345.5852, var_loss: 4561.1832, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Valid Loss: 11.2864\n",
      "Sub-losses: recon_loss: 11.2861, var_loss: 2.7095, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 19 - Train Loss: 319.3860\n",
      "Sub-losses: recon_loss: 319.3372, var_loss: 294.5831, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 19 - Valid Loss: 7.1288\n",
      "Sub-losses: recon_loss: 7.1283, var_loss: 2.6731, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Train Loss: 365.6361\n",
      "Sub-losses: recon_loss: 365.4781, var_loss: 780.3946, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Valid Loss: 8.2867\n",
      "Sub-losses: recon_loss: 8.2861, var_loss: 2.8637, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Train Loss: 329.4336\n",
      "Sub-losses: recon_loss: 329.0783, var_loss: 1437.0011, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Valid Loss: 6.4972\n",
      "Sub-losses: recon_loss: 6.4965, var_loss: 2.8781, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 22 - Train Loss: 401.8826\n",
      "Sub-losses: recon_loss: 401.2605, var_loss: 2060.7863, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 22 - Valid Loss: 6.5849\n",
      "Sub-losses: recon_loss: 6.5839, var_loss: 3.2216, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 23 - Train Loss: 265.7311\n",
      "Sub-losses: recon_loss: 265.2778, var_loss: 1230.3624, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 23 - Valid Loss: 5.7756\n",
      "Sub-losses: recon_loss: 5.7745, var_loss: 3.1311, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Train Loss: 293.2547\n",
      "Sub-losses: recon_loss: 293.0617, var_loss: 429.1125, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Valid Loss: 5.6032\n",
      "Sub-losses: recon_loss: 5.6019, var_loss: 2.8475, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 25 - Train Loss: 321.7070\n",
      "Sub-losses: recon_loss: 321.4682, var_loss: 435.1986, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 25 - Valid Loss: 9.2194\n",
      "Sub-losses: recon_loss: 9.2177, var_loss: 3.0547, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 26 - Train Loss: 247.7509\n",
      "Sub-losses: recon_loss: 247.3694, var_loss: 569.9451, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 26 - Valid Loss: 7.5573\n",
      "Sub-losses: recon_loss: 7.5555, var_loss: 2.7697, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 27 - Train Loss: 248.9149\n",
      "Sub-losses: recon_loss: 248.6312, var_loss: 347.5665, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 27 - Valid Loss: 8.6422\n",
      "Sub-losses: recon_loss: 8.6400, var_loss: 2.7149, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 28 - Train Loss: 266.8049\n",
      "Sub-losses: recon_loss: 266.0836, var_loss: 724.8919, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 28 - Valid Loss: 7.3657\n",
      "Sub-losses: recon_loss: 7.3628, var_loss: 2.8804, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 29 - Train Loss: 251.7140\n",
      "Sub-losses: recon_loss: 250.5095, var_loss: 993.1036, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 29 - Valid Loss: 11.2560\n",
      "Sub-losses: recon_loss: 11.2525, var_loss: 2.8924, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 30 - Train Loss: 335.0176\n",
      "Sub-losses: recon_loss: 334.2683, var_loss: 507.1977, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 30 - Valid Loss: 12.2437\n",
      "Sub-losses: recon_loss: 12.2399, var_loss: 2.6168, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 31 - Train Loss: 312.1425\n",
      "Sub-losses: recon_loss: 310.5446, var_loss: 888.3965, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 31 - Valid Loss: 6.6733\n",
      "Sub-losses: recon_loss: 6.6685, var_loss: 2.6363, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 32 - Train Loss: 228.4806\n",
      "Sub-losses: recon_loss: 225.7624, var_loss: 1242.2366, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 32 - Valid Loss: 9.3079\n",
      "Sub-losses: recon_loss: 9.3026, var_loss: 2.4433, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 33 - Train Loss: 235.9809\n",
      "Sub-losses: recon_loss: 234.5887, var_loss: 523.4318, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 33 - Valid Loss: 5.8446\n",
      "Sub-losses: recon_loss: 5.8378, var_loss: 2.5364, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 34 - Train Loss: 263.2197\n",
      "Sub-losses: recon_loss: 261.3854, var_loss: 567.9770, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 34 - Valid Loss: 9.1290\n",
      "Sub-losses: recon_loss: 9.1210, var_loss: 2.4665, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 35 - Train Loss: 236.4119\n",
      "Sub-losses: recon_loss: 230.6685, var_loss: 1466.4414, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 35 - Valid Loss: 9.0275\n",
      "Sub-losses: recon_loss: 9.0187, var_loss: 2.2617, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 36 - Train Loss: 303.8812\n",
      "Sub-losses: recon_loss: 298.1138, var_loss: 1216.0804, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 36 - Valid Loss: 7.3872\n",
      "Sub-losses: recon_loss: 7.3752, var_loss: 2.5403, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 37 - Train Loss: 320.6224\n",
      "Sub-losses: recon_loss: 317.1325, var_loss: 608.7915, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 37 - Valid Loss: 6.5778\n",
      "Sub-losses: recon_loss: 6.5635, var_loss: 2.4944, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 38 - Train Loss: 244.8669\n",
      "Sub-losses: recon_loss: 241.9130, var_loss: 427.2421, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 38 - Valid Loss: 5.1342\n",
      "Sub-losses: recon_loss: 5.1147, var_loss: 2.8180, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 39 - Train Loss: 312.9488\n",
      "Sub-losses: recon_loss: 307.2985, var_loss: 679.3396, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 39 - Valid Loss: 10.1080\n",
      "Sub-losses: recon_loss: 10.0858, var_loss: 2.6704, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 40 - Train Loss: 291.4299\n",
      "Sub-losses: recon_loss: 273.2231, var_loss: 1825.2419, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 40 - Valid Loss: 5.4322\n",
      "Sub-losses: recon_loss: 5.4047, var_loss: 2.7522, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 41 - Train Loss: 251.6023\n",
      "Sub-losses: recon_loss: 235.1210, var_loss: 1382.6233, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 41 - Valid Loss: 5.3550\n",
      "Sub-losses: recon_loss: 5.3193, var_loss: 2.9938, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 42 - Train Loss: 255.4725\n",
      "Sub-losses: recon_loss: 245.7920, var_loss: 682.4401, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 42 - Valid Loss: 5.3385\n",
      "Sub-losses: recon_loss: 5.2929, var_loss: 3.2152, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 43 - Train Loss: 225.2004\n",
      "Sub-losses: recon_loss: 210.0620, var_loss: 901.1947, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 43 - Valid Loss: 10.1598\n",
      "Sub-losses: recon_loss: 10.1059, var_loss: 3.2102, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 44 - Train Loss: 291.4746\n",
      "Sub-losses: recon_loss: 274.9592, var_loss: 834.8850, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 44 - Valid Loss: 13.2131\n",
      "Sub-losses: recon_loss: 13.1504, var_loss: 3.1711, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 45 - Train Loss: 266.9929\n",
      "Sub-losses: recon_loss: 244.7121, var_loss: 962.5574, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 45 - Valid Loss: 7.2958\n",
      "Sub-losses: recon_loss: 7.2185, var_loss: 3.3385, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 46 - Train Loss: 229.3727\n",
      "Sub-losses: recon_loss: 216.6469, var_loss: 473.1809, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 46 - Valid Loss: 8.2398\n",
      "Sub-losses: recon_loss: 8.1516, var_loss: 3.2806, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 47 - Train Loss: 260.2585\n",
      "Sub-losses: recon_loss: 246.2810, var_loss: 450.8503, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 47 - Valid Loss: 4.9553\n",
      "Sub-losses: recon_loss: 4.8548, var_loss: 3.2414, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 48 - Train Loss: 224.9344\n",
      "Sub-losses: recon_loss: 202.5283, var_loss: 632.3289, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 48 - Valid Loss: 4.3314\n",
      "Sub-losses: recon_loss: 4.2209, var_loss: 3.1176, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 49 - Train Loss: 243.5990\n",
      "Sub-losses: recon_loss: 223.5982, var_loss: 498.3849, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 49 - Valid Loss: 7.8702\n",
      "Sub-losses: recon_loss: 7.7355, var_loss: 3.3561, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 50 - Train Loss: 235.4857\n",
      "Sub-losses: recon_loss: 220.6401, var_loss: 329.7793, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 50 - Valid Loss: 7.5608\n",
      "Sub-losses: recon_loss: 7.4149, var_loss: 3.2422, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 51 - Train Loss: 386.4868\n",
      "Sub-losses: recon_loss: 160.8966, var_loss: 4511.8037, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 51 - Valid Loss: 4.3585\n",
      "Sub-losses: recon_loss: 4.1945, var_loss: 3.2804, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 52 - Train Loss: 197.2803\n",
      "Sub-losses: recon_loss: 170.5433, var_loss: 486.2752, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 52 - Valid Loss: 6.7946\n",
      "Sub-losses: recon_loss: 6.6213, var_loss: 3.1534, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 53 - Train Loss: 232.7053\n",
      "Sub-losses: recon_loss: 213.5668, var_loss: 319.6748, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 53 - Valid Loss: 4.9423\n",
      "Sub-losses: recon_loss: 4.7364, var_loss: 3.4388, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 54 - Train Loss: 232.9225\n",
      "Sub-losses: recon_loss: 192.2394, var_loss: 630.1039, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 54 - Valid Loss: 7.7572\n",
      "Sub-losses: recon_loss: 7.5303, var_loss: 3.5138, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 55 - Train Loss: 215.8521\n",
      "Sub-losses: recon_loss: 186.0306, var_loss: 432.2117, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 55 - Valid Loss: 6.7761\n",
      "Sub-losses: recon_loss: 6.5283, var_loss: 3.5909, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 56 - Train Loss: 322.7310\n",
      "Sub-losses: recon_loss: 294.2244, var_loss: 389.9357, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 56 - Valid Loss: 7.4747\n",
      "Sub-losses: recon_loss: 7.2204, var_loss: 3.4774, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 57 - Train Loss: 315.6481\n",
      "Sub-losses: recon_loss: 213.2646, var_loss: 1332.2075, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 57 - Valid Loss: 5.2255\n",
      "Sub-losses: recon_loss: 4.9535, var_loss: 3.5399, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 58 - Train Loss: 253.6733\n",
      "Sub-losses: recon_loss: 228.1339, var_loss: 318.3724, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 58 - Valid Loss: 6.6015\n",
      "Sub-losses: recon_loss: 6.2835, var_loss: 3.9640, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 59 - Train Loss: 228.2724\n",
      "Sub-losses: recon_loss: 173.2399, var_loss: 661.4339, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 59 - Valid Loss: 5.2597\n",
      "Sub-losses: recon_loss: 4.9548, var_loss: 3.6650, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 60 - Train Loss: 241.1680\n",
      "Sub-losses: recon_loss: 198.0464, var_loss: 502.4960, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 60 - Valid Loss: 7.6191\n",
      "Sub-losses: recon_loss: 7.2322, var_loss: 4.5086, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 61 - Train Loss: 235.6138\n",
      "Sub-losses: recon_loss: 157.0147, var_loss: 892.3635, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 61 - Valid Loss: 4.7634\n",
      "Sub-losses: recon_loss: 4.3656, var_loss: 4.5158, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 62 - Train Loss: 202.4288\n",
      "Sub-losses: recon_loss: 167.4462, var_loss: 388.5885, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 62 - Valid Loss: 6.3184\n",
      "Sub-losses: recon_loss: 5.9031, var_loss: 4.6128, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 63 - Train Loss: 189.6111\n",
      "Sub-losses: recon_loss: 164.3517, var_loss: 275.5088, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 63 - Valid Loss: 7.6313\n",
      "Sub-losses: recon_loss: 7.2170, var_loss: 4.5186, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 64 - Train Loss: 361.3641\n",
      "Sub-losses: recon_loss: 259.7700, var_loss: 1091.3986, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 64 - Valid Loss: 6.9599\n",
      "Sub-losses: recon_loss: 6.6171, var_loss: 3.6825, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 65 - Train Loss: 239.0503\n",
      "Sub-losses: recon_loss: 188.8879, var_loss: 532.1282, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 65 - Valid Loss: 6.6724\n",
      "Sub-losses: recon_loss: 6.2828, var_loss: 4.1332, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 66 - Train Loss: 278.1597\n",
      "Sub-losses: recon_loss: 222.0966, var_loss: 588.5428, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 66 - Valid Loss: 4.9626\n",
      "Sub-losses: recon_loss: 4.6170, var_loss: 3.6284, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 67 - Train Loss: 183.6832\n",
      "Sub-losses: recon_loss: 119.3769, var_loss: 669.2757, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 67 - Valid Loss: 5.3650\n",
      "Sub-losses: recon_loss: 5.0401, var_loss: 3.3818, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 68 - Train Loss: 175.6013\n",
      "Sub-losses: recon_loss: 132.9305, var_loss: 440.9485, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 68 - Valid Loss: 4.7012\n",
      "Sub-losses: recon_loss: 4.3711, var_loss: 3.4114, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 69 - Train Loss: 197.1038\n",
      "Sub-losses: recon_loss: 150.7033, var_loss: 476.6834, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 69 - Valid Loss: 7.9087\n",
      "Sub-losses: recon_loss: 7.5940, var_loss: 3.2327, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 70 - Train Loss: 235.6493\n",
      "Sub-losses: recon_loss: 162.4608, var_loss: 748.2572, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 70 - Valid Loss: 6.7434\n",
      "Sub-losses: recon_loss: 6.4175, var_loss: 3.3324, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 71 - Train Loss: 253.3828\n",
      "Sub-losses: recon_loss: 226.1735, var_loss: 277.0763, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 71 - Valid Loss: 8.4272\n",
      "Sub-losses: recon_loss: 8.1364, var_loss: 2.9613, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 72 - Train Loss: 255.5256\n",
      "Sub-losses: recon_loss: 155.8364, var_loss: 1011.8417, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 72 - Valid Loss: 4.5970\n",
      "Sub-losses: recon_loss: 4.3090, var_loss: 2.9237, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 73 - Train Loss: 297.9585\n",
      "Sub-losses: recon_loss: 230.8815, var_loss: 679.0052, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 73 - Valid Loss: 3.1872\n",
      "Sub-losses: recon_loss: 2.9365, var_loss: 2.5376, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 74 - Train Loss: 262.0046\n",
      "Sub-losses: recon_loss: 191.4697, var_loss: 712.4394, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 74 - Valid Loss: 4.7426\n",
      "Sub-losses: recon_loss: 4.5241, var_loss: 2.2077, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 75 - Train Loss: 199.0957\n",
      "Sub-losses: recon_loss: 153.5102, var_loss: 459.6063, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 75 - Valid Loss: 6.4556\n",
      "Sub-losses: recon_loss: 6.2501, var_loss: 2.0720, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 76 - Train Loss: 195.7264\n",
      "Sub-losses: recon_loss: 145.3302, var_loss: 507.3578, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 76 - Valid Loss: 8.9109\n",
      "Sub-losses: recon_loss: 8.6905, var_loss: 2.2195, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 77 - Train Loss: 179.2428\n",
      "Sub-losses: recon_loss: 142.3385, var_loss: 371.0795, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 77 - Valid Loss: 3.0795\n",
      "Sub-losses: recon_loss: 2.8333, var_loss: 2.4751, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 78 - Train Loss: 235.6635\n",
      "Sub-losses: recon_loss: 206.2907, var_loss: 295.0541, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 78 - Valid Loss: 4.8228\n",
      "Sub-losses: recon_loss: 4.5882, var_loss: 2.3562, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Train Loss: 210.7711\n",
      "Sub-losses: recon_loss: 158.2678, var_loss: 526.9752, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Valid Loss: 5.5082\n",
      "Sub-losses: recon_loss: 5.2765, var_loss: 2.3249, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 80 - Train Loss: 198.2780\n",
      "Sub-losses: recon_loss: 125.4283, var_loss: 730.7021, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 80 - Valid Loss: 4.9949\n",
      "Sub-losses: recon_loss: 4.7668, var_loss: 2.2880, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 81 - Train Loss: 162.4817\n",
      "Sub-losses: recon_loss: 120.1028, var_loss: 424.8393, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 81 - Valid Loss: 4.7005\n",
      "Sub-losses: recon_loss: 4.5018, var_loss: 1.9921, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Train Loss: 165.9468\n",
      "Sub-losses: recon_loss: 133.3340, var_loss: 326.7901, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Valid Loss: 4.7858\n",
      "Sub-losses: recon_loss: 4.5640, var_loss: 2.2231, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Train Loss: 172.8901\n",
      "Sub-losses: recon_loss: 136.2279, var_loss: 367.2311, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Valid Loss: 3.9680\n",
      "Sub-losses: recon_loss: 3.7234, var_loss: 2.4496, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 84 - Train Loss: 168.5922\n",
      "Sub-losses: recon_loss: 134.3437, var_loss: 342.9508, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 84 - Valid Loss: 5.3727\n",
      "Sub-losses: recon_loss: 5.1030, var_loss: 2.7004, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Train Loss: 240.6593\n",
      "Sub-losses: recon_loss: 201.5758, var_loss: 391.2711, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Valid Loss: 3.3029\n",
      "Sub-losses: recon_loss: 3.1054, var_loss: 1.9774, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Train Loss: 175.0181\n",
      "Sub-losses: recon_loss: 138.4714, var_loss: 365.7994, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Valid Loss: 5.6573\n",
      "Sub-losses: recon_loss: 5.4429, var_loss: 2.1461, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Train Loss: 211.7906\n",
      "Sub-losses: recon_loss: 177.4761, var_loss: 343.4009, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Valid Loss: 5.6964\n",
      "Sub-losses: recon_loss: 5.4762, var_loss: 2.2035, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Train Loss: 194.4080\n",
      "Sub-losses: recon_loss: 157.1271, var_loss: 373.0364, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Valid Loss: 5.8160\n",
      "Sub-losses: recon_loss: 5.5986, var_loss: 2.1750, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Train Loss: 134.5202\n",
      "Sub-losses: recon_loss: 105.4896, var_loss: 290.4511, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Valid Loss: 4.9988\n",
      "Sub-losses: recon_loss: 4.7831, var_loss: 2.1572, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 90 - Train Loss: 165.2502\n",
      "Sub-losses: recon_loss: 119.7684, var_loss: 455.0044, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 90 - Valid Loss: 5.1005\n",
      "Sub-losses: recon_loss: 4.8800, var_loss: 2.2055, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Train Loss: 184.5194\n",
      "Sub-losses: recon_loss: 153.9210, var_loss: 306.0874, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Valid Loss: 4.2336\n",
      "Sub-losses: recon_loss: 3.9856, var_loss: 2.4816, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Train Loss: 220.6953\n",
      "Sub-losses: recon_loss: 182.7321, var_loss: 379.7369, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Valid Loss: 4.1557\n",
      "Sub-losses: recon_loss: 3.9501, var_loss: 2.0567, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Train Loss: 207.6426\n",
      "Sub-losses: recon_loss: 180.3834, var_loss: 272.6529, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Valid Loss: 7.7803\n",
      "Sub-losses: recon_loss: 7.5685, var_loss: 2.1182, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Train Loss: 184.8330\n",
      "Sub-losses: recon_loss: 152.3752, var_loss: 324.6376, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Valid Loss: 3.3629\n",
      "Sub-losses: recon_loss: 3.1474, var_loss: 2.1561, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Train Loss: 142.2039\n",
      "Sub-losses: recon_loss: 111.3359, var_loss: 308.7265, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Valid Loss: 7.7647\n",
      "Sub-losses: recon_loss: 7.5763, var_loss: 1.8849, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Train Loss: 176.3002\n",
      "Sub-losses: recon_loss: 119.4986, var_loss: 568.0860, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Valid Loss: 4.3955\n",
      "Sub-losses: recon_loss: 4.2167, var_loss: 1.7887, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Train Loss: 278.8926\n",
      "Sub-losses: recon_loss: 240.1724, var_loss: 387.2409, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Valid Loss: 7.4721\n",
      "Sub-losses: recon_loss: 7.3121, var_loss: 1.6006, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Train Loss: 206.9842\n",
      "Sub-losses: recon_loss: 184.9367, var_loss: 220.4940, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Valid Loss: 3.0026\n",
      "Sub-losses: recon_loss: 2.8412, var_loss: 1.6140, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Train Loss: 118.3911\n",
      "Sub-losses: recon_loss: 88.1312, var_loss: 302.6197, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Valid Loss: 6.3180\n",
      "Sub-losses: recon_loss: 6.1580, var_loss: 1.6005, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Train Loss: 149.5021\n",
      "Sub-losses: recon_loss: 117.0662, var_loss: 324.3774, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Valid Loss: 4.6698\n",
      "Sub-losses: recon_loss: 4.5078, var_loss: 1.6208, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Training modality: cell_deconvolution\n",
      "Training modality: cell_deconvolution\n",
      "Epoch 1 - Train Loss: 967.4648\n",
      "Sub-losses: recon_loss: 967.4630, var_loss: 392.9442, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 80.9757\n",
      "Sub-losses: recon_loss: 80.9757, var_loss: 5.7719, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 1046.9396\n",
      "Sub-losses: recon_loss: 1046.9378, var_loss: 341.0232, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 88.0801\n",
      "Sub-losses: recon_loss: 88.0801, var_loss: 7.4113, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 915.2291\n",
      "Sub-losses: recon_loss: 915.2267, var_loss: 357.1304, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Valid Loss: 85.6470\n",
      "Sub-losses: recon_loss: 85.6469, var_loss: 10.1996, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Train Loss: 866.8011\n",
      "Sub-losses: recon_loss: 866.7982, var_loss: 361.5641, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Valid Loss: 85.3078\n",
      "Sub-losses: recon_loss: 85.3077, var_loss: 12.4733, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Train Loss: 946.1426\n",
      "Sub-losses: recon_loss: 946.1386, var_loss: 393.3659, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Valid Loss: 82.6102\n",
      "Sub-losses: recon_loss: 82.6100, var_loss: 14.5789, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Train Loss: 786.9725\n",
      "Sub-losses: recon_loss: 786.9678, var_loss: 383.3531, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Valid Loss: 78.7362\n",
      "Sub-losses: recon_loss: 78.7360, var_loss: 17.4633, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Train Loss: 798.3009\n",
      "Sub-losses: recon_loss: 798.2956, var_loss: 347.6153, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Valid Loss: 83.8870\n",
      "Sub-losses: recon_loss: 83.8867, var_loss: 19.8786, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Train Loss: 853.2295\n",
      "Sub-losses: recon_loss: 853.2229, var_loss: 357.3930, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Valid Loss: 88.0347\n",
      "Sub-losses: recon_loss: 88.0343, var_loss: 21.4530, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Train Loss: 850.0743\n",
      "Sub-losses: recon_loss: 850.0664, var_loss: 352.3469, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Valid Loss: 90.9159\n",
      "Sub-losses: recon_loss: 90.9153, var_loss: 23.6308, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Train Loss: 866.9908\n",
      "Sub-losses: recon_loss: 866.9810, var_loss: 359.1202, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Valid Loss: 86.9080\n",
      "Sub-losses: recon_loss: 86.9072, var_loss: 26.5469, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Train Loss: 810.9169\n",
      "Sub-losses: recon_loss: 810.9050, var_loss: 354.0237, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Valid Loss: 88.6943\n",
      "Sub-losses: recon_loss: 88.6934, var_loss: 27.2662, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Train Loss: 803.5053\n",
      "Sub-losses: recon_loss: 803.4901, var_loss: 371.6223, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Valid Loss: 78.5172\n",
      "Sub-losses: recon_loss: 78.5160, var_loss: 29.5843, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 13 - Train Loss: 793.1943\n",
      "Sub-losses: recon_loss: 793.1756, var_loss: 373.0903, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 13 - Valid Loss: 75.9594\n",
      "Sub-losses: recon_loss: 75.9579, var_loss: 30.2540, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Train Loss: 710.0637\n",
      "Sub-losses: recon_loss: 710.0406, var_loss: 378.1523, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Valid Loss: 86.9208\n",
      "Sub-losses: recon_loss: 86.9189, var_loss: 31.1184, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Train Loss: 636.5918\n",
      "Sub-losses: recon_loss: 636.5621, var_loss: 397.5994, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Valid Loss: 97.6590\n",
      "Sub-losses: recon_loss: 97.6567, var_loss: 31.3612, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Train Loss: 775.5290\n",
      "Sub-losses: recon_loss: 775.4917, var_loss: 410.3328, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Valid Loss: 82.6370\n",
      "Sub-losses: recon_loss: 82.6342, var_loss: 29.9702, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Train Loss: 753.8292\n",
      "Sub-losses: recon_loss: 753.7851, var_loss: 395.8677, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Valid Loss: 82.4683\n",
      "Sub-losses: recon_loss: 82.4648, var_loss: 31.3199, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Train Loss: 716.1738\n",
      "Sub-losses: recon_loss: 716.1209, var_loss: 389.6620, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Valid Loss: 79.2811\n",
      "Sub-losses: recon_loss: 79.2765, var_loss: 33.6720, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 19 - Train Loss: 683.2419\n",
      "Sub-losses: recon_loss: 683.1789, var_loss: 379.6160, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 19 - Valid Loss: 74.0305\n",
      "Sub-losses: recon_loss: 74.0248, var_loss: 34.2433, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Train Loss: 677.3238\n",
      "Sub-losses: recon_loss: 677.2512, var_loss: 358.6855, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Valid Loss: 77.4109\n",
      "Sub-losses: recon_loss: 77.4039, var_loss: 34.2744, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Train Loss: 690.7193\n",
      "Sub-losses: recon_loss: 690.6277, var_loss: 370.2355, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Valid Loss: 76.9238\n",
      "Sub-losses: recon_loss: 76.9141, var_loss: 39.1625, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 22 - Train Loss: 638.1646\n",
      "Sub-losses: recon_loss: 638.0450, var_loss: 396.3473, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 22 - Valid Loss: 76.4378\n",
      "Sub-losses: recon_loss: 76.4262, var_loss: 38.4905, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 23 - Train Loss: 658.6441\n",
      "Sub-losses: recon_loss: 658.4930, var_loss: 410.0479, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 23 - Valid Loss: 74.7110\n",
      "Sub-losses: recon_loss: 74.6972, var_loss: 37.5629, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Train Loss: 688.1010\n",
      "Sub-losses: recon_loss: 687.9259, var_loss: 389.4821, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Valid Loss: 73.8581\n",
      "Sub-losses: recon_loss: 73.8413, var_loss: 37.4239, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 25 - Train Loss: 663.5467\n",
      "Sub-losses: recon_loss: 663.3254, var_loss: 403.4472, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 25 - Valid Loss: 84.4989\n",
      "Sub-losses: recon_loss: 84.4779, var_loss: 38.4173, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 26 - Train Loss: 624.7295\n",
      "Sub-losses: recon_loss: 624.4436, var_loss: 427.2068, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 26 - Valid Loss: 84.7618\n",
      "Sub-losses: recon_loss: 84.7359, var_loss: 38.6705, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 27 - Train Loss: 644.1991\n",
      "Sub-losses: recon_loss: 643.8499, var_loss: 427.8473, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 27 - Valid Loss: 74.7914\n",
      "Sub-losses: recon_loss: 74.7609, var_loss: 37.2701, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 28 - Train Loss: 697.4884\n",
      "Sub-losses: recon_loss: 697.0260, var_loss: 464.6517, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 28 - Valid Loss: 80.2731\n",
      "Sub-losses: recon_loss: 80.2355, var_loss: 37.7392, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 29 - Train Loss: 648.7391\n",
      "Sub-losses: recon_loss: 648.2546, var_loss: 399.4976, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 29 - Valid Loss: 79.0870\n",
      "Sub-losses: recon_loss: 79.0408, var_loss: 38.1561, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 30 - Train Loss: 653.0922\n",
      "Sub-losses: recon_loss: 652.4287, var_loss: 449.0881, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 30 - Valid Loss: 74.9607\n",
      "Sub-losses: recon_loss: 74.8996, var_loss: 41.3474, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 31 - Train Loss: 647.2350\n",
      "Sub-losses: recon_loss: 646.4648, var_loss: 428.2387, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 31 - Valid Loss: 67.0817\n",
      "Sub-losses: recon_loss: 67.0084, var_loss: 40.7576, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 32 - Train Loss: 597.4038\n",
      "Sub-losses: recon_loss: 596.4079, var_loss: 455.1226, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 32 - Valid Loss: 69.4452\n",
      "Sub-losses: recon_loss: 69.3553, var_loss: 41.1104, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 33 - Train Loss: 676.8373\n",
      "Sub-losses: recon_loss: 675.6718, var_loss: 438.1872, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 33 - Valid Loss: 69.2655\n",
      "Sub-losses: recon_loss: 69.1568, var_loss: 40.8448, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 34 - Train Loss: 611.9327\n",
      "Sub-losses: recon_loss: 610.4641, var_loss: 454.7525, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 34 - Valid Loss: 71.4509\n",
      "Sub-losses: recon_loss: 71.3105, var_loss: 43.4472, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 35 - Train Loss: 655.6912\n",
      "Sub-losses: recon_loss: 653.8183, var_loss: 478.1784, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 35 - Valid Loss: 67.1667\n",
      "Sub-losses: recon_loss: 66.9989, var_loss: 42.8599, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 36 - Train Loss: 627.0414\n",
      "Sub-losses: recon_loss: 624.7785, var_loss: 477.1275, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 36 - Valid Loss: 66.5106\n",
      "Sub-losses: recon_loss: 66.3060, var_loss: 43.1232, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 37 - Train Loss: 621.4694\n",
      "Sub-losses: recon_loss: 618.9068, var_loss: 447.0375, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 37 - Valid Loss: 66.2604\n",
      "Sub-losses: recon_loss: 66.0031, var_loss: 44.8868, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 38 - Train Loss: 657.2332\n",
      "Sub-losses: recon_loss: 654.0800, var_loss: 456.0754, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 38 - Valid Loss: 65.7059\n",
      "Sub-losses: recon_loss: 65.3867, var_loss: 46.1784, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 39 - Train Loss: 605.2839\n",
      "Sub-losses: recon_loss: 601.4599, var_loss: 459.7597, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 39 - Valid Loss: 78.6184\n",
      "Sub-losses: recon_loss: 78.2552, var_loss: 43.6723, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 40 - Train Loss: 627.0212\n",
      "Sub-losses: recon_loss: 622.1032, var_loss: 493.0241, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 40 - Valid Loss: 64.7185\n",
      "Sub-losses: recon_loss: 64.2539, var_loss: 46.5850, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 41 - Train Loss: 613.1178\n",
      "Sub-losses: recon_loss: 607.3631, var_loss: 482.7683, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 41 - Valid Loss: 67.0895\n",
      "Sub-losses: recon_loss: 66.5087, var_loss: 48.7220, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 42 - Train Loss: 633.5603\n",
      "Sub-losses: recon_loss: 626.9845, var_loss: 463.5744, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 42 - Valid Loss: 71.5222\n",
      "Sub-losses: recon_loss: 70.8247, var_loss: 49.1724, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 43 - Train Loss: 581.2971\n",
      "Sub-losses: recon_loss: 573.3126, var_loss: 475.3236, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 43 - Valid Loss: 68.6775\n",
      "Sub-losses: recon_loss: 67.7793, var_loss: 53.4696, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 44 - Train Loss: 613.1291\n",
      "Sub-losses: recon_loss: 604.0386, var_loss: 459.5465, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 44 - Valid Loss: 65.5219\n",
      "Sub-losses: recon_loss: 64.4254, var_loss: 55.4316, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 45 - Train Loss: 584.7644\n",
      "Sub-losses: recon_loss: 572.2509, var_loss: 540.5977, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 45 - Valid Loss: 71.1003\n",
      "Sub-losses: recon_loss: 69.9113, var_loss: 51.3687, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 46 - Train Loss: 612.5666\n",
      "Sub-losses: recon_loss: 600.1150, var_loss: 462.9880, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 46 - Valid Loss: 70.4330\n",
      "Sub-losses: recon_loss: 69.1029, var_loss: 49.4590, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 47 - Train Loss: 619.3353\n",
      "Sub-losses: recon_loss: 603.3773, var_loss: 514.7336, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 47 - Valid Loss: 73.5128\n",
      "Sub-losses: recon_loss: 72.0635, var_loss: 46.7461, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 48 - Train Loss: 617.5486\n",
      "Sub-losses: recon_loss: 598.3505, var_loss: 541.7950, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 48 - Valid Loss: 66.4205\n",
      "Sub-losses: recon_loss: 64.7796, var_loss: 46.3096, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 49 - Train Loss: 596.9600\n",
      "Sub-losses: recon_loss: 575.7136, var_loss: 529.4209, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 49 - Valid Loss: 68.7427\n",
      "Sub-losses: recon_loss: 66.7961, var_loss: 48.5066, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 50 - Train Loss: 620.5582\n",
      "Sub-losses: recon_loss: 596.6633, var_loss: 530.8015, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 50 - Valid Loss: 66.2550\n",
      "Sub-losses: recon_loss: 64.0497, var_loss: 48.9896, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 51 - Train Loss: 601.6582\n",
      "Sub-losses: recon_loss: 576.1000, var_loss: 511.1631, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 51 - Valid Loss: 74.4227\n",
      "Sub-losses: recon_loss: 71.8947, var_loss: 50.5593, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 52 - Train Loss: 619.0954\n",
      "Sub-losses: recon_loss: 591.8560, var_loss: 495.4118, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 52 - Valid Loss: 66.0132\n",
      "Sub-losses: recon_loss: 63.0177, var_loss: 54.4802, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 53 - Train Loss: 611.5536\n",
      "Sub-losses: recon_loss: 580.1594, var_loss: 524.3843, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 53 - Valid Loss: 62.4425\n",
      "Sub-losses: recon_loss: 59.2668, var_loss: 53.0432, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 54 - Train Loss: 579.7586\n",
      "Sub-losses: recon_loss: 546.4469, var_loss: 515.9347, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 54 - Valid Loss: 69.1761\n",
      "Sub-losses: recon_loss: 65.8027, var_loss: 52.2474, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 55 - Train Loss: 601.6105\n",
      "Sub-losses: recon_loss: 563.4808, var_loss: 552.6256, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 55 - Valid Loss: 74.6707\n",
      "Sub-losses: recon_loss: 71.1057, var_loss: 51.6673, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 56 - Train Loss: 583.3589\n",
      "Sub-losses: recon_loss: 547.0380, var_loss: 496.8260, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 56 - Valid Loss: 68.2063\n",
      "Sub-losses: recon_loss: 64.4867, var_loss: 50.8791, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 57 - Train Loss: 622.0435\n",
      "Sub-losses: recon_loss: 583.4169, var_loss: 502.6059, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 57 - Valid Loss: 72.7031\n",
      "Sub-losses: recon_loss: 68.6403, var_loss: 52.8650, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 58 - Train Loss: 576.3804\n",
      "Sub-losses: recon_loss: 535.7044, var_loss: 507.0645, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 58 - Valid Loss: 71.5593\n",
      "Sub-losses: recon_loss: 67.2464, var_loss: 53.7639, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 59 - Train Loss: 587.5147\n",
      "Sub-losses: recon_loss: 548.1834, var_loss: 472.7215, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 59 - Valid Loss: 67.3274\n",
      "Sub-losses: recon_loss: 62.8733, var_loss: 53.5340, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 60 - Train Loss: 580.7663\n",
      "Sub-losses: recon_loss: 540.9520, var_loss: 463.9556, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 60 - Valid Loss: 67.0076\n",
      "Sub-losses: recon_loss: 62.4849, var_loss: 52.7027, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 61 - Train Loss: 581.3273\n",
      "Sub-losses: recon_loss: 540.7593, var_loss: 460.5829, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 61 - Valid Loss: 71.2374\n",
      "Sub-losses: recon_loss: 66.6785, var_loss: 51.7592, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 62 - Train Loss: 609.6659\n",
      "Sub-losses: recon_loss: 564.9678, var_loss: 496.5086, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 62 - Valid Loss: 64.9945\n",
      "Sub-losses: recon_loss: 60.4221, var_loss: 50.7903, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 63 - Train Loss: 595.0117\n",
      "Sub-losses: recon_loss: 552.7031, var_loss: 461.4682, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 63 - Valid Loss: 76.0112\n",
      "Sub-losses: recon_loss: 71.4693, var_loss: 49.5395, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 64 - Train Loss: 593.6140\n",
      "Sub-losses: recon_loss: 552.9145, var_loss: 437.2233, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 64 - Valid Loss: 71.0828\n",
      "Sub-losses: recon_loss: 66.6335, var_loss: 47.7982, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 65 - Train Loss: 563.9492\n",
      "Sub-losses: recon_loss: 522.4992, var_loss: 439.7060, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 65 - Valid Loss: 63.7467\n",
      "Sub-losses: recon_loss: 59.1230, var_loss: 49.0487, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 66 - Train Loss: 564.7129\n",
      "Sub-losses: recon_loss: 522.8126, var_loss: 439.8643, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 66 - Valid Loss: 67.1310\n",
      "Sub-losses: recon_loss: 62.6166, var_loss: 47.3907, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 67 - Train Loss: 594.1159\n",
      "Sub-losses: recon_loss: 551.3777, var_loss: 444.8028, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 67 - Valid Loss: 70.9134\n",
      "Sub-losses: recon_loss: 66.3881, var_loss: 47.0974, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 68 - Train Loss: 563.2912\n",
      "Sub-losses: recon_loss: 523.5345, var_loss: 410.8353, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 68 - Valid Loss: 63.9298\n",
      "Sub-losses: recon_loss: 59.2438, var_loss: 48.4233, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 69 - Train Loss: 563.0163\n",
      "Sub-losses: recon_loss: 522.3482, var_loss: 417.7928, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 69 - Valid Loss: 68.3361\n",
      "Sub-losses: recon_loss: 63.6837, var_loss: 47.7955, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 70 - Train Loss: 576.0668\n",
      "Sub-losses: recon_loss: 535.2706, var_loss: 417.0878, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 70 - Valid Loss: 65.0539\n",
      "Sub-losses: recon_loss: 60.6973, var_loss: 44.5406, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 71 - Train Loss: 573.6833\n",
      "Sub-losses: recon_loss: 531.0436, var_loss: 434.2071, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 71 - Valid Loss: 62.3163\n",
      "Sub-losses: recon_loss: 57.6042, var_loss: 47.9846, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 72 - Train Loss: 570.8632\n",
      "Sub-losses: recon_loss: 530.6993, var_loss: 407.6615, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 72 - Valid Loss: 69.4309\n",
      "Sub-losses: recon_loss: 64.6166, var_loss: 48.8651, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 73 - Train Loss: 583.2887\n",
      "Sub-losses: recon_loss: 542.1393, var_loss: 416.5459, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 73 - Valid Loss: 66.7271\n",
      "Sub-losses: recon_loss: 61.9187, var_loss: 48.6744, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 74 - Train Loss: 556.1257\n",
      "Sub-losses: recon_loss: 514.0982, var_loss: 424.5002, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 74 - Valid Loss: 61.4892\n",
      "Sub-losses: recon_loss: 56.7561, var_loss: 47.8069, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 75 - Train Loss: 570.5501\n",
      "Sub-losses: recon_loss: 530.6206, var_loss: 402.5815, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 75 - Valid Loss: 73.3719\n",
      "Sub-losses: recon_loss: 68.7257, var_loss: 46.8440, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 76 - Train Loss: 562.3752\n",
      "Sub-losses: recon_loss: 522.3690, var_loss: 402.7580, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 76 - Valid Loss: 64.6320\n",
      "Sub-losses: recon_loss: 59.9863, var_loss: 46.7694, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 77 - Train Loss: 567.0345\n",
      "Sub-losses: recon_loss: 526.9325, var_loss: 403.2323, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 77 - Valid Loss: 75.1313\n",
      "Sub-losses: recon_loss: 70.6982, var_loss: 44.5763, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 78 - Train Loss: 559.6300\n",
      "Sub-losses: recon_loss: 520.3783, var_loss: 394.2892, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 78 - Valid Loss: 69.5887\n",
      "Sub-losses: recon_loss: 65.2072, var_loss: 44.0127, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Train Loss: 553.9037\n",
      "Sub-losses: recon_loss: 514.0314, var_loss: 400.1970, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Valid Loss: 68.5756\n",
      "Sub-losses: recon_loss: 63.9851, var_loss: 46.0747, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 80 - Train Loss: 530.1784\n",
      "Sub-losses: recon_loss: 490.9312, var_loss: 393.6603, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 80 - Valid Loss: 68.7562\n",
      "Sub-losses: recon_loss: 63.8028, var_loss: 49.6832, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 81 - Train Loss: 554.9686\n",
      "Sub-losses: recon_loss: 514.5997, var_loss: 404.6897, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 81 - Valid Loss: 68.0045\n",
      "Sub-losses: recon_loss: 63.4003, var_loss: 46.1564, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Train Loss: 557.1084\n",
      "Sub-losses: recon_loss: 519.5525, var_loss: 376.3213, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Valid Loss: 68.4055\n",
      "Sub-losses: recon_loss: 63.9173, var_loss: 44.9731, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Train Loss: 542.5640\n",
      "Sub-losses: recon_loss: 503.4329, var_loss: 391.9607, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Valid Loss: 63.4659\n",
      "Sub-losses: recon_loss: 58.7573, var_loss: 47.1639, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 84 - Train Loss: 558.4792\n",
      "Sub-losses: recon_loss: 517.4869, var_loss: 410.4802, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 84 - Valid Loss: 61.5419\n",
      "Sub-losses: recon_loss: 56.9834, var_loss: 45.6477, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Train Loss: 579.1247\n",
      "Sub-losses: recon_loss: 540.9020, var_loss: 382.6527, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Valid Loss: 67.8166\n",
      "Sub-losses: recon_loss: 63.2729, var_loss: 45.4877, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Train Loss: 569.1698\n",
      "Sub-losses: recon_loss: 528.9714, var_loss: 402.3505, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Valid Loss: 55.2912\n",
      "Sub-losses: recon_loss: 50.8258, var_loss: 44.6946, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Train Loss: 517.0664\n",
      "Sub-losses: recon_loss: 476.9368, var_loss: 401.5957, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Valid Loss: 62.9951\n",
      "Sub-losses: recon_loss: 58.3909, var_loss: 46.0760, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Train Loss: 552.5963\n",
      "Sub-losses: recon_loss: 512.7809, var_loss: 398.3968, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Valid Loss: 63.6724\n",
      "Sub-losses: recon_loss: 59.0263, var_loss: 46.4892, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Train Loss: 565.4030\n",
      "Sub-losses: recon_loss: 523.6285, var_loss: 417.9541, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Valid Loss: 56.8860\n",
      "Sub-losses: recon_loss: 52.1085, var_loss: 47.7989, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 90 - Train Loss: 547.1600\n",
      "Sub-losses: recon_loss: 505.7769, var_loss: 414.0009, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 90 - Valid Loss: 62.0154\n",
      "Sub-losses: recon_loss: 56.7790, var_loss: 52.3849, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Train Loss: 568.2726\n",
      "Sub-losses: recon_loss: 527.3250, var_loss: 409.6128, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Valid Loss: 56.9453\n",
      "Sub-losses: recon_loss: 51.8956, var_loss: 50.5135, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Train Loss: 533.7599\n",
      "Sub-losses: recon_loss: 496.3342, var_loss: 374.3591, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Valid Loss: 60.7307\n",
      "Sub-losses: recon_loss: 55.9166, var_loss: 48.1544, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Train Loss: 532.8760\n",
      "Sub-losses: recon_loss: 495.1536, var_loss: 377.3091, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Valid Loss: 69.1817\n",
      "Sub-losses: recon_loss: 64.4887, var_loss: 46.9412, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Train Loss: 554.2622\n",
      "Sub-losses: recon_loss: 518.5009, var_loss: 357.6795, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Valid Loss: 61.4612\n",
      "Sub-losses: recon_loss: 56.7591, var_loss: 47.0293, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Train Loss: 548.2175\n",
      "Sub-losses: recon_loss: 507.1059, var_loss: 411.1774, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Valid Loss: 69.2828\n",
      "Sub-losses: recon_loss: 64.5901, var_loss: 46.9344, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Train Loss: 550.9335\n",
      "Sub-losses: recon_loss: 511.0471, var_loss: 398.9132, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Valid Loss: 66.6582\n",
      "Sub-losses: recon_loss: 61.9463, var_loss: 47.1250, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Train Loss: 543.7412\n",
      "Sub-losses: recon_loss: 507.0731, var_loss: 366.7179, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Valid Loss: 65.2100\n",
      "Sub-losses: recon_loss: 60.5233, var_loss: 46.8723, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Train Loss: 533.5161\n",
      "Sub-losses: recon_loss: 497.0671, var_loss: 364.5204, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Valid Loss: 66.4798\n",
      "Sub-losses: recon_loss: 61.5927, var_loss: 48.8752, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Train Loss: 556.7921\n",
      "Sub-losses: recon_loss: 516.4344, var_loss: 403.6042, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Valid Loss: 70.8039\n",
      "Sub-losses: recon_loss: 65.8895, var_loss: 49.1477, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Train Loss: 525.8300\n",
      "Sub-losses: recon_loss: 483.9321, var_loss: 419.0022, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Valid Loss: 75.1337\n",
      "Sub-losses: recon_loss: 70.3645, var_loss: 47.6946, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "['RESTING_002' 'RESTING_003' 'RESTING_005' 'RESTING_012' 'RESTING_013'\n",
      " 'RESTING_017' 'RESTING_018' 'RESTING_019' 'RESTING_020' 'RESTING_021'\n",
      " 'RESTING_024' 'RESTING_026' 'RESTING_028' 'RESTING_029' 'RESTING_030'\n",
      " 'RESTING_031' 'RESTING_033' 'RESTING_034' 'RESTING_036' 'RESTING_039'\n",
      " 'RESTING_040' 'RESTING_042' 'RESTING_045' 'RESTING_046' 'RESTING_048'\n",
      " 'RESTING_049' 'RESTING_050' 'RESTING_051' 'RESTING_052' 'RESTING_053'\n",
      " 'RESTING_056' 'RESTING_057' 'RESTING_058' 'RESTING_059' 'RESTING_060'\n",
      " 'RESTING_061' 'RESTING_063' 'RESTING_067' 'RESTING_068' 'RESTING_080'\n",
      " 'RESTING_087' 'RESTING_088' 'RESTING_091' 'RESTING_094' 'RESTING_097'\n",
      " 'RESTING_098' 'RESTING_100' 'RESTING_101' 'RESTING_106' 'RESTING_107'\n",
      " 'RESTING_111' 'RESTING_112' 'RESTING_113' 'RESTING_114' 'RESTING_116'\n",
      " 'RESTING_119' 'RESTING_121' 'RESTING_123' 'RESTING_126' 'RESTING_127'\n",
      " 'RESTING_128' 'RESTING_130' 'RESTING_131' 'RESTING_133' 'RESTING_135'\n",
      " 'RESTING_138' 'RESTING_139' 'RESTING_147' 'RESTING_149' 'RESTING_154'\n",
      " 'RESTING_159' 'RESTING_160' 'RESTING_161' 'RESTING_163' 'RESTING_164'\n",
      " 'RESTING_168' 'RESTING_169' 'RESTING_171' 'RESTING_173' 'RESTING_174'\n",
      " 'RESTING_180' 'RESTING_181' 'RESTING_182' 'RESTING_190' 'RESTING_191'\n",
      " 'RESTING_193' 'RESTING_196' 'RESTING_197' 'RESTING_203' 'RESTING_204'\n",
      " 'RESTING_205' 'RESTING_207' 'RESTING_211' 'RESTING_212' 'RESTING_222'\n",
      " 'RESTING_225' 'RESTING_226' 'RESTING_228' 'RESTING_233' 'RESTING_234'\n",
      " 'RESTING_235' 'RESTING_237' 'RESTING_255' 'RESTING_265' 'RESTING_271'\n",
      " 'RESTING_278' 'RESTING_280' 'RESTING_288' 'RESTING_295' 'RESTING_296'\n",
      " 'RESTING_299']\n",
      "['RESTING_196' 'RESTING_059' 'RESTING_191' 'RESTING_164' 'RESTING_088'\n",
      " 'RESTING_019' 'RESTING_053' 'RESTING_204' 'RESTING_111' 'RESTING_127'\n",
      " 'RESTING_138' 'RESTING_050' 'RESTING_163' 'RESTING_149' 'RESTING_003'\n",
      " 'RESTING_221' 'RESTING_159' 'RESTING_017' 'RESTING_205' 'RESTING_295'\n",
      " 'RESTING_139' 'RESTING_031' 'RESTING_028' 'RESTING_106' 'RESTING_100'\n",
      " 'RESTING_135' 'RESTING_226' 'RESTING_173' 'RESTING_212' 'RESTING_039'\n",
      " 'RESTING_259' 'RESTING_057' 'RESTING_107' 'RESTING_048' 'RESTING_180'\n",
      " 'RESTING_061' 'RESTING_087' 'RESTING_161' 'RESTING_114' 'RESTING_101'\n",
      " 'RESTING_234' 'RESTING_021' 'RESTING_171' 'RESTING_113' 'RESTING_126'\n",
      " 'RESTING_067' 'RESTING_299' 'RESTING_013' 'RESTING_024' 'RESTING_203'\n",
      " 'RESTING_121' 'RESTING_280' 'RESTING_052' 'RESTING_058' 'RESTING_235'\n",
      " 'RESTING_034' 'RESTING_112' 'RESTING_026' 'RESTING_296' 'RESTING_265'\n",
      " 'RESTING_080' 'RESTING_288' 'RESTING_068' 'RESTING_271' 'RESTING_160'\n",
      " 'RESTING_097' 'RESTING_128' 'RESTING_046' 'RESTING_174' 'RESTING_225'\n",
      " 'RESTING_040' 'RESTING_055' 'RESTING_042' 'RESTING_133' 'RESTING_049'\n",
      " 'RESTING_222' 'RESTING_237' 'RESTING_063' 'RESTING_278' 'RESTING_030'\n",
      " 'RESTING_002' 'RESTING_012' 'RESTING_169' 'RESTING_033' 'RESTING_094'\n",
      " 'RESTING_130' 'RESTING_193' 'RESTING_051' 'RESTING_060' 'RESTING_036'\n",
      " 'RESTING_190' 'RESTING_233' 'RESTING_098' 'RESTING_056' 'RESTING_029'\n",
      " 'RESTING_020' 'RESTING_207' 'RESTING_181' 'RESTING_091' 'RESTING_045'\n",
      " 'RESTING_119' 'RESTING_206' 'RESTING_168' 'RESTING_116' 'RESTING_197'\n",
      " 'RESTING_131' 'RESTING_123' 'RESTING_211' 'RESTING_182' 'RESTING_018'\n",
      " 'RESTING_147' 'RESTING_154' 'RESTING_005' 'RESTING_228']\n",
      "['RESTING_002' 'RESTING_005' 'RESTING_012' 'RESTING_013' 'RESTING_018'\n",
      " 'RESTING_026' 'RESTING_030' 'RESTING_042' 'RESTING_049' 'RESTING_067'\n",
      " 'RESTING_068' 'RESTING_087' 'RESTING_088' 'RESTING_091' 'RESTING_094'\n",
      " 'RESTING_097' 'RESTING_100' 'RESTING_111' 'RESTING_112' 'RESTING_114'\n",
      " 'RESTING_116' 'RESTING_118' 'RESTING_126' 'RESTING_138' 'RESTING_147'\n",
      " 'RESTING_149' 'RESTING_168' 'RESTING_173' 'RESTING_175' 'RESTING_193'\n",
      " 'RESTING_211' 'RESTING_226' 'RESTING_235' 'RESTING_237' 'RESTING_271'\n",
      " 'RESTING_278' 'RESTING_280' 'RESTING_283' 'RESTING_288' 'RESTING_296'\n",
      " 'RESTING_299']\n",
      "['RESTING_002' 'RESTING_003' 'RESTING_005' 'RESTING_012' 'RESTING_013'\n",
      " 'RESTING_017' 'RESTING_018' 'RESTING_019' 'RESTING_020' 'RESTING_021'\n",
      " 'RESTING_024' 'RESTING_026' 'RESTING_028' 'RESTING_029' 'RESTING_030'\n",
      " 'RESTING_031' 'RESTING_033' 'RESTING_034' 'RESTING_036' 'RESTING_039'\n",
      " 'RESTING_040' 'RESTING_042' 'RESTING_045' 'RESTING_046' 'RESTING_048'\n",
      " 'RESTING_049' 'RESTING_050' 'RESTING_051' 'RESTING_052' 'RESTING_053'\n",
      " 'RESTING_056' 'RESTING_057' 'RESTING_058' 'RESTING_059' 'RESTING_060'\n",
      " 'RESTING_061' 'RESTING_063' 'RESTING_067' 'RESTING_068' 'RESTING_080'\n",
      " 'RESTING_087' 'RESTING_088' 'RESTING_091' 'RESTING_094' 'RESTING_097'\n",
      " 'RESTING_098' 'RESTING_100' 'RESTING_101' 'RESTING_106' 'RESTING_107'\n",
      " 'RESTING_111' 'RESTING_112' 'RESTING_113' 'RESTING_114' 'RESTING_116'\n",
      " 'RESTING_119' 'RESTING_121' 'RESTING_123' 'RESTING_126' 'RESTING_127'\n",
      " 'RESTING_128' 'RESTING_130' 'RESTING_131' 'RESTING_133' 'RESTING_135'\n",
      " 'RESTING_138' 'RESTING_139' 'RESTING_147' 'RESTING_149' 'RESTING_154'\n",
      " 'RESTING_159' 'RESTING_160' 'RESTING_161' 'RESTING_163' 'RESTING_164'\n",
      " 'RESTING_168' 'RESTING_169' 'RESTING_171' 'RESTING_173' 'RESTING_174'\n",
      " 'RESTING_180' 'RESTING_181' 'RESTING_182' 'RESTING_190' 'RESTING_191'\n",
      " 'RESTING_193' 'RESTING_196' 'RESTING_197' 'RESTING_203' 'RESTING_204'\n",
      " 'RESTING_205' 'RESTING_207' 'RESTING_211' 'RESTING_212' 'RESTING_222'\n",
      " 'RESTING_225' 'RESTING_226' 'RESTING_228' 'RESTING_233' 'RESTING_234'\n",
      " 'RESTING_235' 'RESTING_237' 'RESTING_255' 'RESTING_265' 'RESTING_271'\n",
      " 'RESTING_278' 'RESTING_280' 'RESTING_288' 'RESTING_295' 'RESTING_296'\n",
      " 'RESTING_299']\n",
      "Found 38 common samples for the stacked autoencoder.\n",
      "['RESTING_004' 'RESTING_008' 'RESTING_014' 'RESTING_027' 'RESTING_038'\n",
      " 'RESTING_044' 'RESTING_047' 'RESTING_054' 'RESTING_066' 'RESTING_117'\n",
      " 'RESTING_157' 'RESTING_158' 'RESTING_184' 'RESTING_188' 'RESTING_189'\n",
      " 'RESTING_195' 'RESTING_254' 'RESTING_284']\n",
      "['RESTING_158' 'RESTING_189' 'RESTING_188' 'RESTING_044' 'RESTING_157'\n",
      " 'RESTING_004' 'RESTING_027' 'RESTING_054' 'RESTING_117' 'RESTING_195'\n",
      " 'RESTING_284' 'RESTING_047' 'RESTING_184' 'RESTING_014' 'RESTING_066'\n",
      " 'RESTING_254' 'RESTING_038' 'RESTING_008']\n",
      "['RESTING_008' 'RESTING_014' 'RESTING_038' 'RESTING_047' 'RESTING_066'\n",
      " 'RESTING_117']\n",
      "['RESTING_004' 'RESTING_008' 'RESTING_014' 'RESTING_027' 'RESTING_038'\n",
      " 'RESTING_044' 'RESTING_047' 'RESTING_054' 'RESTING_066' 'RESTING_117'\n",
      " 'RESTING_157' 'RESTING_158' 'RESTING_184' 'RESTING_188' 'RESTING_189'\n",
      " 'RESTING_195' 'RESTING_254' 'RESTING_284']\n",
      "Found 6 common samples for the stacked autoencoder.\n",
      "finished training each modality model\n",
      "Epoch 1 - Train Loss: 4876.7694\n",
      "Sub-losses: recon_loss: 4876.7688, var_loss: 131.6621, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 1 - Valid Loss: 452.2407\n",
      "Sub-losses: recon_loss: 452.2407, var_loss: 6.7900, anneal_factor: 0.0000, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Train Loss: 4840.6680\n",
      "Sub-losses: recon_loss: 4840.6675, var_loss: 113.1882, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 2 - Valid Loss: 446.6128\n",
      "Sub-losses: recon_loss: 446.6128, var_loss: 4.9833, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Train Loss: 4834.6843\n",
      "Sub-losses: recon_loss: 4834.6832, var_loss: 128.5348, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 3 - Valid Loss: 444.4413\n",
      "Sub-losses: recon_loss: 444.4412, var_loss: 4.2578, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Train Loss: 4817.8853\n",
      "Sub-losses: recon_loss: 4817.8842, var_loss: 127.2373, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 4 - Valid Loss: 463.1962\n",
      "Sub-losses: recon_loss: 463.1962, var_loss: 4.2921, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Train Loss: 4886.7243\n",
      "Sub-losses: recon_loss: 4886.7231, var_loss: 129.0557, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 5 - Valid Loss: 461.8976\n",
      "Sub-losses: recon_loss: 461.8975, var_loss: 3.9209, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Train Loss: 4687.1869\n",
      "Sub-losses: recon_loss: 4687.1855, var_loss: 111.1282, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 6 - Valid Loss: 463.5771\n",
      "Sub-losses: recon_loss: 463.5770, var_loss: 4.2580, anneal_factor: 0.0001, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Train Loss: 4669.3834\n",
      "Sub-losses: recon_loss: 4669.3817, var_loss: 126.2356, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 7 - Valid Loss: 444.5062\n",
      "Sub-losses: recon_loss: 444.5062, var_loss: 4.9316, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Train Loss: 4606.1870\n",
      "Sub-losses: recon_loss: 4606.1848, var_loss: 124.0943, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 8 - Valid Loss: 479.7920\n",
      "Sub-losses: recon_loss: 479.7919, var_loss: 5.6472, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Train Loss: 4609.2975\n",
      "Sub-losses: recon_loss: 4609.2947, var_loss: 126.0321, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 9 - Valid Loss: 488.4105\n",
      "Sub-losses: recon_loss: 488.4104, var_loss: 5.7428, anneal_factor: 0.0002, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Train Loss: 4648.9866\n",
      "Sub-losses: recon_loss: 4648.9825, var_loss: 144.2658, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 10 - Valid Loss: 449.2253\n",
      "Sub-losses: recon_loss: 449.2252, var_loss: 6.2096, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Train Loss: 4640.9835\n",
      "Sub-losses: recon_loss: 4640.9780, var_loss: 165.6782, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 11 - Valid Loss: 461.5720\n",
      "Sub-losses: recon_loss: 461.5718, var_loss: 6.4933, anneal_factor: 0.0003, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Train Loss: 4533.9290\n",
      "Sub-losses: recon_loss: 4533.9231, var_loss: 140.9842, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 12 - Valid Loss: 465.9417\n",
      "Sub-losses: recon_loss: 465.9414, var_loss: 6.5243, anneal_factor: 0.0004, effective_beta_factor: 0.0000\n",
      "Epoch 13 - Train Loss: 4605.0192\n",
      "Sub-losses: recon_loss: 4605.0129, var_loss: 124.7209, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 13 - Valid Loss: 471.1382\n",
      "Sub-losses: recon_loss: 471.1378, var_loss: 6.6770, anneal_factor: 0.0005, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Train Loss: 4566.3260\n",
      "Sub-losses: recon_loss: 4566.3176, var_loss: 137.4620, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 14 - Valid Loss: 453.6273\n",
      "Sub-losses: recon_loss: 453.6269, var_loss: 6.8976, anneal_factor: 0.0006, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Train Loss: 4576.4048\n",
      "Sub-losses: recon_loss: 4576.3953, var_loss: 126.6419, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 15 - Valid Loss: 468.1551\n",
      "Sub-losses: recon_loss: 468.1546, var_loss: 6.9209, anneal_factor: 0.0007, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Train Loss: 4540.4124\n",
      "Sub-losses: recon_loss: 4540.3990, var_loss: 144.7581, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 16 - Valid Loss: 467.7357\n",
      "Sub-losses: recon_loss: 467.7350, var_loss: 7.0940, anneal_factor: 0.0009, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Train Loss: 4638.3051\n",
      "Sub-losses: recon_loss: 4638.2905, var_loss: 130.6837, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 17 - Valid Loss: 482.8143\n",
      "Sub-losses: recon_loss: 482.8135, var_loss: 6.7035, anneal_factor: 0.0011, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Train Loss: 4518.0862\n",
      "Sub-losses: recon_loss: 4518.0685, var_loss: 130.9253, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 18 - Valid Loss: 459.3390\n",
      "Sub-losses: recon_loss: 459.3380, var_loss: 6.9752, anneal_factor: 0.0014, effective_beta_factor: 0.0001\n",
      "Epoch 19 - Train Loss: 4536.1198\n",
      "Sub-losses: recon_loss: 4536.0962, var_loss: 142.5496, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 19 - Valid Loss: 461.7491\n",
      "Sub-losses: recon_loss: 461.7478, var_loss: 7.6551, anneal_factor: 0.0017, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Train Loss: 4476.9930\n",
      "Sub-losses: recon_loss: 4476.9639, var_loss: 143.3789, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 20 - Valid Loss: 456.3258\n",
      "Sub-losses: recon_loss: 456.3244, var_loss: 7.1321, anneal_factor: 0.0020, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Train Loss: 4453.3170\n",
      "Sub-losses: recon_loss: 4453.2856, var_loss: 126.5409, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 21 - Valid Loss: 444.2628\n",
      "Sub-losses: recon_loss: 444.2608, var_loss: 8.2476, anneal_factor: 0.0025, effective_beta_factor: 0.0002\n",
      "Epoch 22 - Train Loss: 4506.6613\n",
      "Sub-losses: recon_loss: 4506.6213, var_loss: 132.8611, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 22 - Valid Loss: 456.0523\n",
      "Sub-losses: recon_loss: 456.0502, var_loss: 6.8166, anneal_factor: 0.0030, effective_beta_factor: 0.0003\n",
      "Epoch 23 - Train Loss: 4491.0554\n",
      "Sub-losses: recon_loss: 4490.9951, var_loss: 163.8504, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 23 - Valid Loss: 445.7081\n",
      "Sub-losses: recon_loss: 445.7056, var_loss: 6.7719, anneal_factor: 0.0037, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Train Loss: 4461.9812\n",
      "Sub-losses: recon_loss: 4461.9195, var_loss: 137.3469, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 24 - Valid Loss: 452.8147\n",
      "Sub-losses: recon_loss: 452.8115, var_loss: 7.1157, anneal_factor: 0.0045, effective_beta_factor: 0.0004\n",
      "Epoch 25 - Train Loss: 4437.2630\n",
      "Sub-losses: recon_loss: 4437.1808, var_loss: 149.6551, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 25 - Valid Loss: 438.6387\n",
      "Sub-losses: recon_loss: 438.6346, var_loss: 7.5982, anneal_factor: 0.0055, effective_beta_factor: 0.0005\n",
      "Epoch 26 - Train Loss: 4435.9196\n",
      "Sub-losses: recon_loss: 4435.8358, var_loss: 125.1482, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 26 - Valid Loss: 436.0743\n",
      "Sub-losses: recon_loss: 436.0695, var_loss: 7.1568, anneal_factor: 0.0067, effective_beta_factor: 0.0007\n",
      "Epoch 27 - Train Loss: 4457.9278\n",
      "Sub-losses: recon_loss: 4457.8243, var_loss: 126.6254, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 27 - Valid Loss: 430.6986\n",
      "Sub-losses: recon_loss: 430.6924, var_loss: 7.5514, anneal_factor: 0.0082, effective_beta_factor: 0.0008\n",
      "Epoch 28 - Train Loss: 4320.8206\n",
      "Sub-losses: recon_loss: 4320.6859, var_loss: 135.3086, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 28 - Valid Loss: 444.6660\n",
      "Sub-losses: recon_loss: 444.6584, var_loss: 7.6769, anneal_factor: 0.0100, effective_beta_factor: 0.0010\n",
      "Epoch 29 - Train Loss: 4410.5524\n",
      "Sub-losses: recon_loss: 4410.3971, var_loss: 128.0544, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 29 - Valid Loss: 430.3497\n",
      "Sub-losses: recon_loss: 430.3402, var_loss: 7.7965, anneal_factor: 0.0121, effective_beta_factor: 0.0012\n",
      "Epoch 30 - Train Loss: 4362.4643\n",
      "Sub-losses: recon_loss: 4362.2296, var_loss: 158.9150, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 30 - Valid Loss: 445.5330\n",
      "Sub-losses: recon_loss: 445.5215, var_loss: 7.8086, anneal_factor: 0.0148, effective_beta_factor: 0.0015\n",
      "Epoch 31 - Train Loss: 4395.8627\n",
      "Sub-losses: recon_loss: 4395.5245, var_loss: 188.0414, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 31 - Valid Loss: 462.2696\n",
      "Sub-losses: recon_loss: 462.2562, var_loss: 7.4122, anneal_factor: 0.0180, effective_beta_factor: 0.0018\n",
      "Epoch 32 - Train Loss: 4324.9064\n",
      "Sub-losses: recon_loss: 4324.4910, var_loss: 189.8037, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 32 - Valid Loss: 444.8340\n",
      "Sub-losses: recon_loss: 444.8184, var_loss: 7.0991, anneal_factor: 0.0219, effective_beta_factor: 0.0022\n",
      "Epoch 33 - Train Loss: 4316.1863\n",
      "Sub-losses: recon_loss: 4315.7335, var_loss: 170.1995, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 33 - Valid Loss: 437.6721\n",
      "Sub-losses: recon_loss: 437.6541, var_loss: 6.7647, anneal_factor: 0.0266, effective_beta_factor: 0.0027\n",
      "Epoch 34 - Train Loss: 4291.9120\n",
      "Sub-losses: recon_loss: 4291.4872, var_loss: 131.5183, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 34 - Valid Loss: 444.4279\n",
      "Sub-losses: recon_loss: 444.4033, var_loss: 7.6090, anneal_factor: 0.0323, effective_beta_factor: 0.0032\n",
      "Epoch 35 - Train Loss: 4328.8539\n",
      "Sub-losses: recon_loss: 4328.2376, var_loss: 157.3454, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 35 - Valid Loss: 451.1355\n",
      "Sub-losses: recon_loss: 451.1057, var_loss: 7.6107, anneal_factor: 0.0392, effective_beta_factor: 0.0039\n",
      "Epoch 36 - Train Loss: 4383.0843\n",
      "Sub-losses: recon_loss: 4382.4392, var_loss: 136.0245, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 36 - Valid Loss: 437.9556\n",
      "Sub-losses: recon_loss: 437.9193, var_loss: 7.6576, anneal_factor: 0.0474, effective_beta_factor: 0.0047\n",
      "Epoch 37 - Train Loss: 4293.5780\n",
      "Sub-losses: recon_loss: 4292.5665, var_loss: 176.4578, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 37 - Valid Loss: 445.0609\n",
      "Sub-losses: recon_loss: 445.0187, var_loss: 7.3609, anneal_factor: 0.0573, effective_beta_factor: 0.0057\n",
      "Epoch 38 - Train Loss: 4275.9329\n",
      "Sub-losses: recon_loss: 4274.8434, var_loss: 157.5519, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 38 - Valid Loss: 445.3625\n",
      "Sub-losses: recon_loss: 445.3116, var_loss: 7.3488, anneal_factor: 0.0691, effective_beta_factor: 0.0069\n",
      "Epoch 39 - Train Loss: 4285.9677\n",
      "Sub-losses: recon_loss: 4284.8460, var_loss: 134.8704, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 39 - Valid Loss: 443.0238\n",
      "Sub-losses: recon_loss: 442.9593, var_loss: 7.7582, anneal_factor: 0.0832, effective_beta_factor: 0.0083\n",
      "Epoch 40 - Train Loss: 4347.6982\n",
      "Sub-losses: recon_loss: 4346.2173, var_loss: 148.4702, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 40 - Valid Loss: 446.9179\n",
      "Sub-losses: recon_loss: 446.8349, var_loss: 8.3217, anneal_factor: 0.0998, effective_beta_factor: 0.0100\n",
      "Epoch 41 - Train Loss: 4302.7653\n",
      "Sub-losses: recon_loss: 4301.0501, var_loss: 143.8993, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 41 - Valid Loss: 427.5467\n",
      "Sub-losses: recon_loss: 427.4453, var_loss: 8.5093, anneal_factor: 0.1192, effective_beta_factor: 0.0119\n",
      "Epoch 42 - Train Loss: 4309.9534\n",
      "Sub-losses: recon_loss: 4307.9098, var_loss: 144.0657, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 42 - Valid Loss: 435.3443\n",
      "Sub-losses: recon_loss: 435.2171, var_loss: 8.9661, anneal_factor: 0.1419, effective_beta_factor: 0.0142\n",
      "Epoch 43 - Train Loss: 4245.1815\n",
      "Sub-losses: recon_loss: 4242.6100, var_loss: 153.0861, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 43 - Valid Loss: 443.5840\n",
      "Sub-losses: recon_loss: 443.4529, var_loss: 7.8017, anneal_factor: 0.1680, effective_beta_factor: 0.0168\n",
      "Epoch 44 - Train Loss: 4178.0868\n",
      "Sub-losses: recon_loss: 4174.9336, var_loss: 159.3975, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 44 - Valid Loss: 436.2881\n",
      "Sub-losses: recon_loss: 436.1471, var_loss: 7.1289, anneal_factor: 0.1978, effective_beta_factor: 0.0198\n",
      "Epoch 45 - Train Loss: 4274.4489\n",
      "Sub-losses: recon_loss: 4271.2516, var_loss: 138.1328, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 45 - Valid Loss: 434.9469\n",
      "Sub-losses: recon_loss: 434.7785, var_loss: 7.2751, anneal_factor: 0.2315, effective_beta_factor: 0.0231\n",
      "Epoch 46 - Train Loss: 4264.3524\n",
      "Sub-losses: recon_loss: 4260.4200, var_loss: 146.2158, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 46 - Valid Loss: 446.4195\n",
      "Sub-losses: recon_loss: 446.2210, var_loss: 7.3775, anneal_factor: 0.2689, effective_beta_factor: 0.0269\n",
      "Epoch 47 - Train Loss: 4282.0464\n",
      "Sub-losses: recon_loss: 4277.9136, var_loss: 133.3052, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 47 - Valid Loss: 463.0612\n",
      "Sub-losses: recon_loss: 462.8261, var_loss: 7.5841, anneal_factor: 0.3100, effective_beta_factor: 0.0310\n",
      "Epoch 48 - Train Loss: 4190.2274\n",
      "Sub-losses: recon_loss: 4186.0153, var_loss: 118.8723, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 48 - Valid Loss: 429.7076\n",
      "Sub-losses: recon_loss: 429.4747, var_loss: 6.5733, anneal_factor: 0.3543, effective_beta_factor: 0.0354\n",
      "Epoch 49 - Train Loss: 4216.8616\n",
      "Sub-losses: recon_loss: 4209.9445, var_loss: 172.3632, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 49 - Valid Loss: 436.5579\n",
      "Sub-losses: recon_loss: 436.2848, var_loss: 6.8069, anneal_factor: 0.4013, effective_beta_factor: 0.0401\n",
      "Epoch 50 - Train Loss: 4256.9641\n",
      "Sub-losses: recon_loss: 4250.2888, var_loss: 148.2850, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 50 - Valid Loss: 429.8761\n",
      "Sub-losses: recon_loss: 429.5356, var_loss: 7.5645, anneal_factor: 0.4502, effective_beta_factor: 0.0450\n",
      "Epoch 51 - Train Loss: 4233.1521\n",
      "Sub-losses: recon_loss: 4224.9484, var_loss: 164.0739, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 51 - Valid Loss: 428.1699\n",
      "Sub-losses: recon_loss: 427.8182, var_loss: 7.0349, anneal_factor: 0.5000, effective_beta_factor: 0.0500\n",
      "Epoch 52 - Train Loss: 4239.4416\n",
      "Sub-losses: recon_loss: 4231.3477, var_loss: 147.2044, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 52 - Valid Loss: 430.5533\n",
      "Sub-losses: recon_loss: 430.1385, var_loss: 7.5443, anneal_factor: 0.5498, effective_beta_factor: 0.0550\n",
      "Epoch 53 - Train Loss: 4183.4487\n",
      "Sub-losses: recon_loss: 4175.2092, var_loss: 137.6272, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 53 - Valid Loss: 448.4281\n",
      "Sub-losses: recon_loss: 447.9792, var_loss: 7.4989, anneal_factor: 0.5987, effective_beta_factor: 0.0599\n",
      "Epoch 54 - Train Loss: 4218.0702\n",
      "Sub-losses: recon_loss: 4207.8021, var_loss: 159.0345, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 54 - Valid Loss: 443.9454\n",
      "Sub-losses: recon_loss: 443.4440, var_loss: 7.7667, anneal_factor: 0.6457, effective_beta_factor: 0.0646\n",
      "Epoch 55 - Train Loss: 4152.9474\n",
      "Sub-losses: recon_loss: 4142.9033, var_loss: 145.5702, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 55 - Valid Loss: 429.9874\n",
      "Sub-losses: recon_loss: 429.4422, var_loss: 7.9019, anneal_factor: 0.6900, effective_beta_factor: 0.0690\n",
      "Epoch 56 - Train Loss: 4133.3042\n",
      "Sub-losses: recon_loss: 4122.6665, var_loss: 145.5108, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 56 - Valid Loss: 424.0762\n",
      "Sub-losses: recon_loss: 423.5018, var_loss: 7.8573, anneal_factor: 0.7311, effective_beta_factor: 0.0731\n",
      "Epoch 57 - Train Loss: 4147.6581\n",
      "Sub-losses: recon_loss: 4134.6926, var_loss: 168.7058, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 57 - Valid Loss: 432.0899\n",
      "Sub-losses: recon_loss: 431.4915, var_loss: 7.7856, anneal_factor: 0.7685, effective_beta_factor: 0.0769\n",
      "Epoch 58 - Train Loss: 4160.1069\n",
      "Sub-losses: recon_loss: 4147.4416, var_loss: 157.8854, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 58 - Valid Loss: 434.2918\n",
      "Sub-losses: recon_loss: 433.7319, var_loss: 6.9792, anneal_factor: 0.8022, effective_beta_factor: 0.0802\n",
      "Epoch 59 - Train Loss: 4155.7067\n",
      "Sub-losses: recon_loss: 4142.2815, var_loss: 161.3566, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 59 - Valid Loss: 440.3143\n",
      "Sub-losses: recon_loss: 439.6469, var_loss: 8.0214, anneal_factor: 0.8320, effective_beta_factor: 0.0832\n",
      "Epoch 60 - Train Loss: 4159.1545\n",
      "Sub-losses: recon_loss: 4145.1203, var_loss: 163.5395, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 60 - Valid Loss: 455.6886\n",
      "Sub-losses: recon_loss: 454.9936, var_loss: 8.0994, anneal_factor: 0.8581, effective_beta_factor: 0.0858\n",
      "Epoch 61 - Train Loss: 4165.5126\n",
      "Sub-losses: recon_loss: 4151.2708, var_loss: 161.6938, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 61 - Valid Loss: 432.2148\n",
      "Sub-losses: recon_loss: 431.5191, var_loss: 7.8991, anneal_factor: 0.8808, effective_beta_factor: 0.0881\n",
      "Epoch 62 - Train Loss: 4148.7237\n",
      "Sub-losses: recon_loss: 4130.4772, var_loss: 202.6823, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 62 - Valid Loss: 440.5663\n",
      "Sub-losses: recon_loss: 439.8818, var_loss: 7.6036, anneal_factor: 0.9002, effective_beta_factor: 0.0900\n",
      "Epoch 63 - Train Loss: 4184.4449\n",
      "Sub-losses: recon_loss: 4172.0066, var_loss: 135.6661, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 63 - Valid Loss: 432.2863\n",
      "Sub-losses: recon_loss: 431.5876, var_loss: 7.6210, anneal_factor: 0.9168, effective_beta_factor: 0.0917\n",
      "Epoch 64 - Train Loss: 4188.0303\n",
      "Sub-losses: recon_loss: 4172.4071, var_loss: 167.8367, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 64 - Valid Loss: 427.8975\n",
      "Sub-losses: recon_loss: 427.2275, var_loss: 7.1975, anneal_factor: 0.9309, effective_beta_factor: 0.0931\n",
      "Epoch 65 - Train Loss: 4077.5746\n",
      "Sub-losses: recon_loss: 4062.8379, var_loss: 156.3282, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 65 - Valid Loss: 417.6337\n",
      "Sub-losses: recon_loss: 416.9573, var_loss: 7.1753, anneal_factor: 0.9427, effective_beta_factor: 0.0943\n",
      "Epoch 66 - Train Loss: 4208.8868\n",
      "Sub-losses: recon_loss: 4193.0661, var_loss: 166.0838, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 66 - Valid Loss: 426.2591\n",
      "Sub-losses: recon_loss: 425.6436, var_loss: 6.4609, anneal_factor: 0.9526, effective_beta_factor: 0.0953\n",
      "Epoch 67 - Train Loss: 4139.8770\n",
      "Sub-losses: recon_loss: 4124.5001, var_loss: 160.0356, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 67 - Valid Loss: 438.5075\n",
      "Sub-losses: recon_loss: 437.8698, var_loss: 6.6375, anneal_factor: 0.9608, effective_beta_factor: 0.0961\n",
      "Epoch 68 - Train Loss: 4103.1163\n",
      "Sub-losses: recon_loss: 4087.9210, var_loss: 157.0252, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 68 - Valid Loss: 428.5206\n",
      "Sub-losses: recon_loss: 427.8427, var_loss: 7.0051, anneal_factor: 0.9677, effective_beta_factor: 0.0968\n",
      "Epoch 69 - Train Loss: 4103.3015\n",
      "Sub-losses: recon_loss: 4090.5339, var_loss: 131.1650, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 69 - Valid Loss: 426.4485\n",
      "Sub-losses: recon_loss: 425.7556, var_loss: 7.1189, anneal_factor: 0.9734, effective_beta_factor: 0.0973\n",
      "Epoch 70 - Train Loss: 4106.1602\n",
      "Sub-losses: recon_loss: 4088.1783, var_loss: 183.8415, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 70 - Valid Loss: 442.3950\n",
      "Sub-losses: recon_loss: 441.6536, var_loss: 7.5799, anneal_factor: 0.9781, effective_beta_factor: 0.0978\n",
      "Epoch 71 - Train Loss: 4081.0242\n",
      "Sub-losses: recon_loss: 4068.1221, var_loss: 131.3839, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 71 - Valid Loss: 426.1335\n",
      "Sub-losses: recon_loss: 425.4033, var_loss: 7.4361, anneal_factor: 0.9820, effective_beta_factor: 0.0982\n",
      "Epoch 72 - Train Loss: 4118.1477\n",
      "Sub-losses: recon_loss: 4102.2702, var_loss: 161.1549, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 72 - Valid Loss: 445.6547\n",
      "Sub-losses: recon_loss: 444.7675, var_loss: 9.0058, anneal_factor: 0.9852, effective_beta_factor: 0.0985\n",
      "Epoch 73 - Train Loss: 4184.3741\n",
      "Sub-losses: recon_loss: 4171.9675, var_loss: 125.5893, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 73 - Valid Loss: 439.1498\n",
      "Sub-losses: recon_loss: 438.2529, var_loss: 9.0798, anneal_factor: 0.9879, effective_beta_factor: 0.0988\n",
      "Epoch 74 - Train Loss: 4082.8565\n",
      "Sub-losses: recon_loss: 4066.9736, var_loss: 160.4272, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 74 - Valid Loss: 429.4121\n",
      "Sub-losses: recon_loss: 428.5515, var_loss: 8.6932, anneal_factor: 0.9900, effective_beta_factor: 0.0990\n",
      "Epoch 75 - Train Loss: 4135.6397\n",
      "Sub-losses: recon_loss: 4120.8166, var_loss: 149.4501, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 75 - Valid Loss: 425.8320\n",
      "Sub-losses: recon_loss: 424.9546, var_loss: 8.8464, anneal_factor: 0.9918, effective_beta_factor: 0.0992\n",
      "Epoch 76 - Train Loss: 4094.3937\n",
      "Sub-losses: recon_loss: 4076.2495, var_loss: 182.6645, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 76 - Valid Loss: 431.8946\n",
      "Sub-losses: recon_loss: 430.9662, var_loss: 9.3456, anneal_factor: 0.9933, effective_beta_factor: 0.0993\n",
      "Epoch 77 - Train Loss: 4101.3682\n",
      "Sub-losses: recon_loss: 4086.7034, var_loss: 147.4563, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 77 - Valid Loss: 441.2578\n",
      "Sub-losses: recon_loss: 440.4687, var_loss: 7.9342, anneal_factor: 0.9945, effective_beta_factor: 0.0995\n",
      "Epoch 78 - Train Loss: 4133.4406\n",
      "Sub-losses: recon_loss: 4120.2023, var_loss: 132.9817, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 78 - Valid Loss: 418.9791\n",
      "Sub-losses: recon_loss: 418.1584, var_loss: 8.2440, anneal_factor: 0.9955, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Train Loss: 4092.1828\n",
      "Sub-losses: recon_loss: 4075.6631, var_loss: 165.8088, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 79 - Valid Loss: 431.7007\n",
      "Sub-losses: recon_loss: 430.9225, var_loss: 7.8106, anneal_factor: 0.9963, effective_beta_factor: 0.0996\n",
      "Epoch 80 - Train Loss: 4129.7450\n",
      "Sub-losses: recon_loss: 4115.4811, var_loss: 143.0695, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 80 - Valid Loss: 435.0383\n",
      "Sub-losses: recon_loss: 434.2332, var_loss: 8.0752, anneal_factor: 0.9970, effective_beta_factor: 0.0997\n",
      "Epoch 81 - Train Loss: 4107.4329\n",
      "Sub-losses: recon_loss: 4092.7507, var_loss: 147.1856, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 81 - Valid Loss: 437.9895\n",
      "Sub-losses: recon_loss: 437.1447, var_loss: 8.4692, anneal_factor: 0.9975, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Train Loss: 4095.1808\n",
      "Sub-losses: recon_loss: 4079.5748, var_loss: 156.3766, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 82 - Valid Loss: 423.9291\n",
      "Sub-losses: recon_loss: 423.1570, var_loss: 7.7362, anneal_factor: 0.9980, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Train Loss: 4045.0413\n",
      "Sub-losses: recon_loss: 4029.6965, var_loss: 153.7026, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 83 - Valid Loss: 431.9112\n",
      "Sub-losses: recon_loss: 431.1247, var_loss: 7.8782, anneal_factor: 0.9983, effective_beta_factor: 0.0998\n",
      "Epoch 84 - Train Loss: 4043.2841\n",
      "Sub-losses: recon_loss: 4028.8999, var_loss: 144.0383, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 84 - Valid Loss: 417.4498\n",
      "Sub-losses: recon_loss: 416.7324, var_loss: 7.1839, anneal_factor: 0.9986, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Train Loss: 4064.5099\n",
      "Sub-losses: recon_loss: 4049.6985, var_loss: 148.2800, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 85 - Valid Loss: 455.4240\n",
      "Sub-losses: recon_loss: 454.7343, var_loss: 6.9047, anneal_factor: 0.9989, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Train Loss: 4071.4572\n",
      "Sub-losses: recon_loss: 4056.1829, var_loss: 152.8818, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 86 - Valid Loss: 441.2662\n",
      "Sub-losses: recon_loss: 440.5433, var_loss: 7.2355, anneal_factor: 0.9991, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Train Loss: 4113.3237\n",
      "Sub-losses: recon_loss: 4096.0818, var_loss: 172.5467, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 87 - Valid Loss: 432.8467\n",
      "Sub-losses: recon_loss: 432.1728, var_loss: 6.7445, anneal_factor: 0.9993, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Train Loss: 4064.7393\n",
      "Sub-losses: recon_loss: 4048.4927, var_loss: 162.5657, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 88 - Valid Loss: 427.5818\n",
      "Sub-losses: recon_loss: 426.8755, var_loss: 7.0683, anneal_factor: 0.9994, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Train Loss: 4081.6834\n",
      "Sub-losses: recon_loss: 4064.5735, var_loss: 171.1847, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 89 - Valid Loss: 428.9532\n",
      "Sub-losses: recon_loss: 428.1907, var_loss: 7.6288, anneal_factor: 0.9995, effective_beta_factor: 0.0999\n",
      "Epoch 90 - Train Loss: 4060.7367\n",
      "Sub-losses: recon_loss: 4044.8347, var_loss: 159.0866, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 90 - Valid Loss: 433.5195\n",
      "Sub-losses: recon_loss: 432.6766, var_loss: 8.4317, anneal_factor: 0.9996, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Train Loss: 4123.5023\n",
      "Sub-losses: recon_loss: 4108.0360, var_loss: 154.7146, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 91 - Valid Loss: 447.4900\n",
      "Sub-losses: recon_loss: 446.5685, var_loss: 9.2178, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Train Loss: 3995.5009\n",
      "Sub-losses: recon_loss: 3979.0433, var_loss: 164.6208, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 92 - Valid Loss: 437.7686\n",
      "Sub-losses: recon_loss: 436.9600, var_loss: 8.0874, anneal_factor: 0.9997, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Train Loss: 4094.8786\n",
      "Sub-losses: recon_loss: 4076.5322, var_loss: 183.5051, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 93 - Valid Loss: 442.0356\n",
      "Sub-losses: recon_loss: 441.1885, var_loss: 8.4733, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Train Loss: 3970.1510\n",
      "Sub-losses: recon_loss: 3956.7923, var_loss: 133.6126, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 94 - Valid Loss: 432.0615\n",
      "Sub-losses: recon_loss: 431.2041, var_loss: 8.5754, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Train Loss: 4054.6205\n",
      "Sub-losses: recon_loss: 4039.9645, var_loss: 146.5820, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 95 - Valid Loss: 424.5535\n",
      "Sub-losses: recon_loss: 423.6881, var_loss: 8.6550, anneal_factor: 0.9998, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Train Loss: 3993.1394\n",
      "Sub-losses: recon_loss: 3975.4180, var_loss: 177.2357, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 96 - Valid Loss: 427.6548\n",
      "Sub-losses: recon_loss: 426.7163, var_loss: 9.3859, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Train Loss: 4137.2166\n",
      "Sub-losses: recon_loss: 4123.6530, var_loss: 135.6486, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 97 - Valid Loss: 460.2010\n",
      "Sub-losses: recon_loss: 459.2463, var_loss: 9.5475, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Train Loss: 4079.9727\n",
      "Sub-losses: recon_loss: 4064.9814, var_loss: 149.9243, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 98 - Valid Loss: 440.0411\n",
      "Sub-losses: recon_loss: 439.1328, var_loss: 9.0837, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Train Loss: 4000.9474\n",
      "Sub-losses: recon_loss: 3985.9005, var_loss: 150.4788, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 99 - Valid Loss: 434.4117\n",
      "Sub-losses: recon_loss: 433.5328, var_loss: 8.7891, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Train Loss: 4061.3641\n",
      "Sub-losses: recon_loss: 4045.3146, var_loss: 160.5044, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "Epoch 100 - Valid Loss: 426.5876\n",
      "Sub-losses: recon_loss: 425.6822, var_loss: 9.0551, anneal_factor: 0.9999, effective_beta_factor: 0.1000\n",
      "['RESTING_006' 'RESTING_041' 'RESTING_075' 'RESTING_090' 'RESTING_092'\n",
      " 'RESTING_109' 'RESTING_115' 'RESTING_137' 'RESTING_142' 'RESTING_143'\n",
      " 'RESTING_144' 'RESTING_152' 'RESTING_162' 'RESTING_170' 'RESTING_178'\n",
      " 'RESTING_183' 'RESTING_187' 'RESTING_192' 'RESTING_213' 'RESTING_214'\n",
      " 'RESTING_215' 'RESTING_220' 'RESTING_223' 'RESTING_229' 'RESTING_232'\n",
      " 'RESTING_236' 'RESTING_251' 'RESTING_257' 'RESTING_260' 'RESTING_262'\n",
      " 'RESTING_263' 'RESTING_285']\n",
      "['RESTING_187' 'RESTING_109' 'RESTING_220' 'RESTING_075' 'RESTING_263'\n",
      " 'RESTING_092' 'RESTING_142' 'RESTING_192' 'RESTING_041' 'RESTING_011'\n",
      " 'RESTING_214' 'RESTING_262' 'RESTING_257' 'RESTING_213' 'RESTING_285'\n",
      " 'RESTING_170' 'RESTING_183' 'RESTING_006' 'RESTING_178' 'RESTING_232'\n",
      " 'RESTING_137' 'RESTING_152' 'RESTING_162' 'RESTING_115' 'RESTING_090'\n",
      " 'RESTING_223' 'RESTING_215' 'RESTING_143' 'RESTING_251' 'RESTING_132'\n",
      " 'RESTING_229' 'RESTING_144' 'RESTING_260' 'RESTING_236']\n",
      "['RESTING_006' 'RESTING_090' 'RESTING_092' 'RESTING_099' 'RESTING_142'\n",
      " 'RESTING_143' 'RESTING_152' 'RESTING_187' 'RESTING_215' 'RESTING_232'\n",
      " 'RESTING_236' 'RESTING_251' 'RESTING_262']\n",
      "['RESTING_006' 'RESTING_041' 'RESTING_075' 'RESTING_090' 'RESTING_092'\n",
      " 'RESTING_109' 'RESTING_115' 'RESTING_137' 'RESTING_142' 'RESTING_143'\n",
      " 'RESTING_144' 'RESTING_152' 'RESTING_162' 'RESTING_170' 'RESTING_178'\n",
      " 'RESTING_183' 'RESTING_187' 'RESTING_192' 'RESTING_213' 'RESTING_214'\n",
      " 'RESTING_215' 'RESTING_220' 'RESTING_223' 'RESTING_229' 'RESTING_232'\n",
      " 'RESTING_236' 'RESTING_251' 'RESTING_257' 'RESTING_260' 'RESTING_262'\n",
      " 'RESTING_263' 'RESTING_285']\n",
      "Found 12 common samples for the stacked autoencoder.\n",
      "<autoencodix.data._numeric_dataset.NumericDataset object at 0x3df217100>\n",
      "Successfully created annotated latent space object (adata_latent).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result Object Public Attributes:\n",
       "------------------------------\n",
       "latentspaces: TrainingDynamics object\n",
       "sample_ids: TrainingDynamics object\n",
       "reconstructions: TrainingDynamics object\n",
       "mus: TrainingDynamics object\n",
       "sigmas: TrainingDynamics object\n",
       "losses: TrainingDynamics object\n",
       "sub_losses: LossRegistry(_losses={'recon_loss': TrainingDynamics(), 'var_loss': TrainingDynamics(), 'anneal_factor': TrainingDynamics(), 'effective_beta_factor': TrainingDynamics()})\n",
       "preprocessed_data: Tensor of shape (0,)\n",
       "model: VarixArchitecture\n",
       "model_checkpoints: TrainingDynamics object\n",
       "datasets: DatasetContainer(train=<autoencodix.data._multimodal_dataset.MultiModalDataset object at 0x40d0cd840>, valid=<autoencodix.data._multimodal_dataset.MultiModalDataset object at 0x40d0cd8a0>, test=<autoencodix.data._multimodal_dataset.MultiModalDataset object at 0x40d0cd600>)\n",
       "new_datasets: DatasetContainer(train=None, valid=None, test=None)\n",
       "adata_latent: AnnData object with n_obs  n_vars = 12  16\n",
       "final_reconstruction: <autoencodix.data._multimodal_dataset.MultiModalDataset object at 0x4282d5b40>\n",
       "sub_results: Dict with 4 items\n",
       "sub_reconstructions: Dict with 4 items\n",
       "embedding_evaluation: Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackix.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1dc220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plots ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "No annotation data found. Please provide a valid annotation data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstackix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:899\u001b[0m, in \u001b[0;36mBasePipeline.show_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating plots ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visualizer\u001b[38;5;241m.\u001b[39mshow_loss(plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 899\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_latent_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRidgeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visualizer\u001b[38;5;241m.\u001b[39mshow_latent_space(result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult, plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2D-scatter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/visualize/visualize.py:258\u001b[0m, in \u001b[0;36mVisualizer.show_latent_space\u001b[0;34m(self, result, plot_type, labels, param, epoch, split, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata is not a dictionary or DataFrame. Please provide a valid annotation data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m         )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Raise error no annotation given\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo annotation data found. Please provide a valid annotation data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     df_latent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m    264\u001b[0m         [\n\u001b[1;32m    265\u001b[0m             result\u001b[38;5;241m.\u001b[39mget_latent_df(epoch\u001b[38;5;241m=\u001b[39mepoch, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m         ]\n\u001b[1;32m    269\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No annotation data found. Please provide a valid annotation data type."
     ]
    }
   ],
   "source": [
    "stackix.show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945229b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:181: UserWarning: Your config is of type: <class 'autoencodix.configs.stackix_config.StackixConfig'>, for this pipeline the default params of: <class 'autoencodix.configs.xmodalix_config.XModalixConfig'> work best\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xmodalix = acx.XModalix(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52c6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stackix._trainer._orchestrator.modality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230f1a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RESTING_002', 'RESTING_003', 'RESTING_004', 'RESTING_017',\n",
       "       'RESTING_019', 'RESTING_020', 'RESTING_021', 'RESTING_024',\n",
       "       'RESTING_026', 'RESTING_033', 'RESTING_042', 'RESTING_044',\n",
       "       'RESTING_045', 'RESTING_046', 'RESTING_049', 'RESTING_051',\n",
       "       'RESTING_054', 'RESTING_056', 'RESTING_057', 'RESTING_058',\n",
       "       'RESTING_059', 'RESTING_061', 'RESTING_063', 'RESTING_087',\n",
       "       'RESTING_088', 'RESTING_092', 'RESTING_094', 'RESTING_097',\n",
       "       'RESTING_098', 'RESTING_100', 'RESTING_109', 'RESTING_111',\n",
       "       'RESTING_113', 'RESTING_115', 'RESTING_116', 'RESTING_117',\n",
       "       'RESTING_121', 'RESTING_123', 'RESTING_130', 'RESTING_135',\n",
       "       'RESTING_138', 'RESTING_152', 'RESTING_154', 'RESTING_157',\n",
       "       'RESTING_160', 'RESTING_163', 'RESTING_164', 'RESTING_168',\n",
       "       'RESTING_169', 'RESTING_182', 'RESTING_183', 'RESTING_189',\n",
       "       'RESTING_191', 'RESTING_192', 'RESTING_195', 'RESTING_196',\n",
       "       'RESTING_197', 'RESTING_203', 'RESTING_204', 'RESTING_205',\n",
       "       'RESTING_213', 'RESTING_214', 'RESTING_222', 'RESTING_223',\n",
       "       'RESTING_225', 'RESTING_228', 'RESTING_229', 'RESTING_233',\n",
       "       'RESTING_234', 'RESTING_235', 'RESTING_237', 'RESTING_254',\n",
       "       'RESTING_255', 'RESTING_257', 'RESTING_263', 'RESTING_271',\n",
       "       'RESTING_284', 'RESTING_296', 'RESTING_299'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"RNA\"].sample_ids.get(epoch=-1, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d54eb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([[-3.96348894e-01, -2.36419812e-01,  9.85036269e-02,\n",
       "         -1.30424380e-01,  2.90022671e-01],\n",
       "        [-2.20263861e-02, -1.84193850e-01,  1.53815567e-01,\n",
       "          2.63749629e-01,  1.89365491e-01],\n",
       "        [-2.24098980e-01, -6.34290397e-01, -1.64214760e-01,\n",
       "         -4.16576415e-01, -3.49925339e-01],\n",
       "        [-2.22063825e-01, -3.19974184e-01,  5.95994294e-01,\n",
       "          4.54409242e-01, -9.45839882e-01],\n",
       "        [ 2.00840458e-03,  2.23641425e-01,  5.35296686e-02,\n",
       "          1.34282678e-01, -7.09338114e-02],\n",
       "        [ 3.60440426e-02,  2.87551939e-01, -2.69520193e-01,\n",
       "         -1.78070456e-01,  2.76033610e-01],\n",
       "        [-5.37785709e-01, -4.37670052e-01,  7.59078622e-01,\n",
       "          1.48791730e-01, -1.11782685e-01],\n",
       "        [-1.28346711e-01,  1.68067694e-01,  1.36490405e-01,\n",
       "          4.54300046e-01, -1.90715641e-01],\n",
       "        [-1.31236863e+00,  7.69730061e-02, -1.84813172e-01,\n",
       "          4.10499722e-01,  2.91850567e-01],\n",
       "        [ 3.77366722e-01,  6.31521881e-01, -1.14850089e-01,\n",
       "         -4.07376550e-02,  2.72830784e-01],\n",
       "        [ 3.88547391e-01,  4.68373120e-01, -1.64774552e-01,\n",
       "         -7.42278039e-01,  2.29690522e-02],\n",
       "        [-2.49984451e-02, -5.42132020e-01, -2.84941718e-02,\n",
       "         -2.23469883e-01, -3.12019102e-02],\n",
       "        [ 2.01936156e-01,  2.98703909e-01, -1.34397954e-01,\n",
       "          3.39364231e-01,  1.76725373e-01],\n",
       "        [ 1.31435134e-02,  8.51520538e-01, -2.44407713e-01,\n",
       "         -1.17335580e-01, -1.07809901e-03],\n",
       "        [ 1.95370480e-01, -1.29521400e-01,  2.95088232e-01,\n",
       "          2.90989190e-01,  1.42343894e-01],\n",
       "        [ 1.19969875e-01,  3.15947503e-01, -3.68806183e-01,\n",
       "          1.85038485e-02,  1.34956300e-01],\n",
       "        [-2.64380366e-01, -1.54145971e-01,  2.80963242e-01,\n",
       "          1.85873970e-01, -1.77736402e-01],\n",
       "        [ 1.65192828e-01,  1.55695975e-01,  4.73329067e-01,\n",
       "         -3.59188676e-01,  1.34615436e-01],\n",
       "        [ 4.77542765e-02, -3.10235798e-01, -3.24419945e-01,\n",
       "         -2.12671712e-01,  9.26105827e-02],\n",
       "        [ 6.03423774e-01,  4.19666231e-01,  8.31261426e-02,\n",
       "         -2.26827078e-02,  1.69905618e-01],\n",
       "        [ 2.91936286e-02,  2.45422348e-01, -2.52732188e-01,\n",
       "         -6.64211750e-01, -1.57216385e-01],\n",
       "        [ 1.65235415e-01,  1.14781119e-01, -1.88393891e-01,\n",
       "         -2.38315165e-02,  1.98699027e-01],\n",
       "        [ 1.61848038e-01,  1.36179805e-01, -1.92894772e-01,\n",
       "         -6.26068860e-02,  7.01871932e-01],\n",
       "        [-1.75956637e-01, -4.56355512e-01,  1.10038266e-01,\n",
       "         -3.21130306e-01, -2.25775644e-01],\n",
       "        [ 8.36512864e-01,  3.27078879e-01,  2.87429951e-02,\n",
       "         -6.72459453e-02, -2.81616747e-02],\n",
       "        [-6.29666150e-02, -1.63392469e-01,  3.57306540e-01,\n",
       "          4.30582017e-01, -7.95344859e-02],\n",
       "        [-6.42895341e-01, -2.51360655e-01, -6.12584949e-01,\n",
       "         -7.18495548e-01,  2.15495482e-01],\n",
       "        [-3.91548984e-02, -1.03617840e-01,  4.09042299e-01,\n",
       "          2.95849323e-01, -7.84014642e-01],\n",
       "        [-5.77421904e-01, -2.93185651e-01,  4.71242130e-01,\n",
       "          1.06706202e-01, -3.13186705e-01],\n",
       "        [ 6.60429120e-01,  3.01751852e-01,  9.88849461e-01,\n",
       "         -1.61425799e-01, -2.16175511e-01],\n",
       "        [-7.22244143e-01, -4.42247629e-01,  8.82676601e-01,\n",
       "         -1.36506486e+00, -5.84267192e-02],\n",
       "        [ 2.58220434e-01,  3.07772979e-02,  1.79878548e-01,\n",
       "          2.62134463e-01,  1.58435538e-01],\n",
       "        [-3.57784301e-01, -1.96585909e-01,  6.73227906e-02,\n",
       "         -1.38402998e-01,  1.72154799e-01],\n",
       "        [-2.97478825e-01, -1.87516421e-01,  6.51703477e-02,\n",
       "          1.33194998e-01, -4.37053293e-02],\n",
       "        [-1.74125075e-01, -2.15062946e-01,  3.27603012e-01,\n",
       "         -1.01862088e-01, -1.49124101e-01],\n",
       "        [-4.55565043e-02, -1.20609835e-01,  3.90085548e-01,\n",
       "          8.39606076e-02,  2.46677577e-01],\n",
       "        [ 7.80398130e-01,  3.86902839e-01,  2.93472290e-01,\n",
       "          1.76109329e-01, -1.40957937e-01],\n",
       "        [ 4.04696912e-01,  2.87705690e-01,  3.35339233e-02,\n",
       "          2.39483356e-01, -1.48083940e-01],\n",
       "        [-2.06454366e-01, -4.10275936e-01, -1.03275143e-02,\n",
       "         -1.97182819e-01, -9.68014747e-02],\n",
       "        [-3.31865013e-01, -1.18944430e+00,  2.36968458e-01,\n",
       "         -1.31974086e-01, -1.10858306e-01],\n",
       "        [ 1.31056271e-02, -4.65198874e-01, -5.98093756e-02,\n",
       "          1.98088363e-01, -1.95520684e-01],\n",
       "        [-7.29354024e-02,  3.13660949e-02,  1.50606260e-02,\n",
       "         -3.20159197e-01,  1.02649167e-01],\n",
       "        [-2.83830285e-01,  2.16811240e-01, -1.21570528e-01,\n",
       "         -4.80842352e-01,  2.06652775e-01],\n",
       "        [ 7.96683550e-01,  1.09191068e-01,  1.71753854e-01,\n",
       "         -3.58969718e-01,  3.53043318e-01],\n",
       "        [ 3.71351898e-01, -9.44052711e-02,  2.73188263e-01,\n",
       "         -1.75462767e-01, -1.45838127e-01],\n",
       "        [-5.49297571e-01, -6.90571010e-01,  8.90643358e-01,\n",
       "         -9.39315081e-01, -1.25468627e-01],\n",
       "        [ 5.06266296e-01,  2.46849626e-01,  1.65567487e-01,\n",
       "          2.55630799e-02,  1.98815197e-01],\n",
       "        [ 1.22699991e-01,  1.94170341e-01, -2.34694451e-01,\n",
       "          3.06629874e-02,  2.55457878e-01],\n",
       "        [-2.08862871e-01,  2.10079849e-01,  1.47417635e-01,\n",
       "         -3.01081240e-01,  1.25770256e-01],\n",
       "        [-8.27698946e-01, -1.14092207e+00, -3.42402041e-01,\n",
       "         -2.54402936e-01, -2.56067276e-01],\n",
       "        [-1.17358848e-01,  2.69068182e-01,  2.15610325e-01,\n",
       "          1.63049266e-01, -2.19250962e-01],\n",
       "        [-4.33618754e-01, -4.02058244e-01,  2.19384044e-01,\n",
       "         -3.56217176e-02,  9.22712237e-02],\n",
       "        [ 1.74254589e-02,  2.53444910e-01, -1.82663262e-01,\n",
       "         -2.77016521e-01,  3.49456556e-02],\n",
       "        [ 2.14491919e-01,  3.15237105e-01, -5.80135323e-02,\n",
       "          1.46019205e-01, -5.51009551e-02],\n",
       "        [ 1.33877978e-01,  1.02960333e-01, -1.41833991e-01,\n",
       "          3.52657773e-02,  4.70293343e-01],\n",
       "        [-2.27676466e-01, -1.27830768e+00, -5.18573880e-01,\n",
       "         -1.11527309e-01, -7.78395087e-02],\n",
       "        [ 6.27901778e-03,  3.62056732e-01, -2.21911073e-02,\n",
       "          1.31727815e-01,  1.48699358e-01],\n",
       "        [ 1.06110013e+00,  4.54445720e-01, -9.24555540e-01,\n",
       "         -4.32197005e-01, -8.03861767e-02],\n",
       "        [ 2.94118255e-01,  3.98264825e-03, -3.59656453e-01,\n",
       "         -5.54157495e-02,  1.85128167e-01],\n",
       "        [-6.90555692e-01,  5.51832855e-01, -2.43373573e-01,\n",
       "         -1.28435349e+00,  4.50260162e-01],\n",
       "        [-1.72954336e-01, -8.73516023e-01, -1.43391624e-01,\n",
       "         -3.87640111e-02, -2.87547648e-01],\n",
       "        [ 5.32499611e-01,  2.98079729e-01,  1.50009453e-01,\n",
       "          1.40310824e-01, -6.01012222e-02],\n",
       "        [ 1.46099925e-01,  1.19735837e-01, -3.69752869e-02,\n",
       "         -7.62809068e-03,  3.84971857e-01],\n",
       "        [ 1.45635471e-01,  2.48468786e-01, -5.32869212e-02,\n",
       "          6.45315200e-02,  2.75943398e-01],\n",
       "        [ 4.02717948e-01,  1.14825182e-01,  1.10797003e-01,\n",
       "          1.05374053e-01,  1.70098841e-01],\n",
       "        [-9.85624269e-03, -2.55861461e-01,  2.75045559e-02,\n",
       "         -2.57674754e-02,  2.70212173e-01],\n",
       "        [-1.26376718e-01,  3.59920174e-01, -1.77714676e-01,\n",
       "         -2.06408650e-02, -2.26587549e-01],\n",
       "        [ 3.19810152e-01,  3.45461726e-01, -2.33808786e-01,\n",
       "          3.53083581e-01,  1.42238975e-01],\n",
       "        [-3.75033408e-01, -5.10719001e-01,  6.77372888e-03,\n",
       "         -5.81522405e-01,  1.04516909e-01],\n",
       "        [ 2.03004070e-02,  2.83973783e-01, -1.54404521e-01,\n",
       "          5.42961061e-03,  2.11110607e-01],\n",
       "        [-5.54057434e-02, -4.20275509e-01, -2.86503851e-01,\n",
       "          5.72978139e-01,  2.12985307e-01],\n",
       "        [-5.20397782e-01,  1.50376111e-01,  2.24658579e-01,\n",
       "          5.18656611e-01,  1.40363313e-02],\n",
       "        [-1.71776697e-01,  6.41503260e-02,  9.51101780e-02,\n",
       "         -2.95766741e-02, -8.76094848e-02],\n",
       "        [-8.67756158e-02,  3.24758500e-01, -2.33119801e-01,\n",
       "         -9.95756090e-02,  6.07879795e-02],\n",
       "        [-4.00540531e-01, -2.39582658e-01,  3.89857590e-01,\n",
       "          8.46156850e-03, -1.04157352e+00],\n",
       "        [ 2.47259110e-01,  2.33854249e-01, -1.95230059e-02,\n",
       "         -1.85723789e-02,  3.95169377e-01],\n",
       "        [ 6.20697923e-02,  1.30073756e-01,  2.44353935e-01,\n",
       "         -2.89765388e-01,  4.65856373e-01],\n",
       "        [ 4.79632497e-01,  3.83259654e-01,  8.83384943e-02,\n",
       "          4.80365194e-02,  3.00980330e-01],\n",
       "        [-2.95544088e-01,  1.45845979e-01,  1.11824445e-01,\n",
       "          5.86494654e-02, -2.41753273e-02]], dtype=float32),\n",
       " 'valid': array([[ 0.32929745, -0.01902956, -0.03441593,  0.14211437, -0.05762223],\n",
       "        [ 0.1194253 ,  0.24919373, -0.20546962,  0.08127952,  0.2023452 ],\n",
       "        [-0.18653534,  0.35786211, -0.03774549, -0.01365712,  0.20525631],\n",
       "        [-0.17512791, -0.11369281, -0.08084877, -0.42383876, -0.02185482],\n",
       "        [-0.15661547, -0.06542702, -0.08677021, -0.03242446,  0.12383132],\n",
       "        [ 0.06403361, -0.02325548,  0.2094696 ,  0.23012626, -0.15617302],\n",
       "        [ 0.10363515,  0.23385614, -0.08476701,  0.16274357, -0.09144059],\n",
       "        [-0.20486893, -0.34698248, -0.06599954,  0.27735472,  0.1986172 ],\n",
       "        [-0.07204005,  0.22080874, -0.12350303, -0.18994159,  0.17079061],\n",
       "        [ 0.00652398, -0.0056919 ,  0.02178174,  0.07490789,  0.282869  ],\n",
       "        [ 0.16114943,  0.15952805, -0.31748664, -0.07073923,  0.50684595],\n",
       "        [ 0.11914541,  0.12789431, -0.09414142,  0.11309854,  0.356481  ],\n",
       "        [ 0.15132996,  0.13028087,  0.10170828,  0.13193598, -0.16458198]],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"RNA\"].reconstructions.get(epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4238530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'RNA', 56 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_005', 'RESTING_008', 'RESTING_012', 'RESTING_013', 'RESTING_014', 'RESTING_018', 'RESTING_027', 'RESTING_028', 'RESTING_029', 'RESTING_030', 'RESTING_031', 'RESTING_036', 'RESTING_040', 'RESTING_047', 'RESTING_050', 'RESTING_060', 'RESTING_062', 'RESTING_066', 'RESTING_067', 'RESTING_068', 'RESTING_090', 'RESTING_091', 'RESTING_106', 'RESTING_107', 'RESTING_112', 'RESTING_114', 'RESTING_119', 'RESTING_127', 'RESTING_128', 'RESTING_129', 'RESTING_137', 'RESTING_140', 'RESTING_141', 'RESTING_143', 'RESTING_146', 'RESTING_149', 'RESTING_158', 'RESTING_162', 'RESTING_171', 'RESTING_174', 'RESTING_179', 'RESTING_181', 'RESTING_184', 'RESTING_185', 'RESTING_187', 'RESTING_207', 'RESTING_215', 'RESTING_226', 'RESTING_236', 'RESTING_253', 'RESTING_262', 'RESTING_265', 'RESTING_278', 'RESTING_285', 'RESTING_288', 'RESTING_318']\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'mutation', 52 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_005', 'RESTING_008', 'RESTING_012', 'RESTING_013', 'RESTING_014', 'RESTING_018', 'RESTING_027', 'RESTING_028', 'RESTING_029', 'RESTING_030', 'RESTING_031', 'RESTING_036', 'RESTING_040', 'RESTING_047', 'RESTING_050', 'RESTING_060', 'RESTING_062', 'RESTING_066', 'RESTING_067', 'RESTING_068', 'RESTING_090', 'RESTING_091', 'RESTING_106', 'RESTING_107', 'RESTING_112', 'RESTING_114', 'RESTING_119', 'RESTING_127', 'RESTING_128', 'RESTING_137', 'RESTING_140', 'RESTING_141', 'RESTING_143', 'RESTING_146', 'RESTING_149', 'RESTING_158', 'RESTING_162', 'RESTING_171', 'RESTING_174', 'RESTING_181', 'RESTING_184', 'RESTING_187', 'RESTING_207', 'RESTING_215', 'RESTING_226', 'RESTING_236', 'RESTING_253', 'RESTING_262', 'RESTING_265', 'RESTING_278', 'RESTING_285', 'RESTING_288']\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'radiology', 25 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_005', 'RESTING_008', 'RESTING_012', 'RESTING_013', 'RESTING_014', 'RESTING_018', 'RESTING_030', 'RESTING_047', 'RESTING_066', 'RESTING_067', 'RESTING_068', 'RESTING_090', 'RESTING_091', 'RESTING_112', 'RESTING_114', 'RESTING_118', 'RESTING_143', 'RESTING_149', 'RESTING_187', 'RESTING_215', 'RESTING_226', 'RESTING_236', 'RESTING_262', 'RESTING_278', 'RESTING_288']\n",
      "  warnings.warn(\n",
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_bulkreader.py:201: UserWarning: For data modality 'cell_deconvolution', 56 sample(s) were found without a corresponding annotation and will be dropped: ['RESTING_005', 'RESTING_008', 'RESTING_012', 'RESTING_013', 'RESTING_014', 'RESTING_018', 'RESTING_027', 'RESTING_028', 'RESTING_029', 'RESTING_030', 'RESTING_031', 'RESTING_036', 'RESTING_040', 'RESTING_047', 'RESTING_050', 'RESTING_060', 'RESTING_062', 'RESTING_066', 'RESTING_067', 'RESTING_068', 'RESTING_090', 'RESTING_091', 'RESTING_106', 'RESTING_107', 'RESTING_112', 'RESTING_114', 'RESTING_119', 'RESTING_127', 'RESTING_128', 'RESTING_129', 'RESTING_137', 'RESTING_140', 'RESTING_141', 'RESTING_143', 'RESTING_146', 'RESTING_149', 'RESTING_158', 'RESTING_162', 'RESTING_171', 'RESTING_174', 'RESTING_179', 'RESTING_181', 'RESTING_184', 'RESTING_185', 'RESTING_187', 'RESTING_207', 'RESTING_215', 'RESTING_226', 'RESTING_236', 'RESTING_253', 'RESTING_262', 'RESTING_265', 'RESTING_278', 'RESTING_285', 'RESTING_288', 'RESTING_318']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_dfs keys in process_multi_bulk: dict_keys(['RNA', 'mutation', 'radiology', 'cell_deconvolution'])\n",
      "--- Running Pairing-Aware Split ---\n",
      "Identified 32 fully paired samples across all modalities.\n",
      "Identified 91 samples present in at least one, but not all, modalities.\n",
      "Successfully generated synchronized indices for all modalities.\n",
      "key: train, type: <class 'dict'>\n",
      "key: valid, type: <class 'dict'>\n",
      "key: test, type: <class 'dict'>\n",
      "Check if we need to pretrain: multi_bulk.RNA\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.RNA\n",
      "Check if we need to pretrain: multi_bulk.mutation\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.mutation\n",
      "Check if we need to pretrain: multi_bulk.radiology\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.radiology\n",
      "Check if we need to pretrain: multi_bulk.cell_deconvolution\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.cell_deconvolution\n",
      "--- Epoch 1/100 ---\n",
      "split: train, n_samples: 918\n",
      "Epoch 1/100 - Train Loss: 18.5923\n",
      "split: valid, n_samples: 43\n",
      "Epoch 1/100 - Valid Loss: 17.3455\n",
      "--- Epoch 2/100 ---\n",
      "split: train, n_samples: 885\n",
      "Epoch 2/100 - Train Loss: 18.8771\n",
      "split: valid, n_samples: 43\n",
      "Epoch 2/100 - Valid Loss: 16.6911\n",
      "--- Epoch 3/100 ---\n",
      "split: train, n_samples: 887\n",
      "Epoch 3/100 - Train Loss: 18.4875\n",
      "split: valid, n_samples: 43\n",
      "Epoch 3/100 - Valid Loss: 18.7061\n",
      "--- Epoch 4/100 ---\n",
      "split: train, n_samples: 881\n",
      "Epoch 4/100 - Train Loss: 18.7072\n",
      "split: valid, n_samples: 43\n",
      "Epoch 4/100 - Valid Loss: 19.2863\n",
      "--- Epoch 5/100 ---\n",
      "split: train, n_samples: 905\n",
      "Epoch 5/100 - Train Loss: 18.7085\n",
      "split: valid, n_samples: 43\n",
      "Epoch 5/100 - Valid Loss: 18.1739\n",
      "--- Epoch 6/100 ---\n",
      "split: train, n_samples: 878\n",
      "Epoch 6/100 - Train Loss: 19.0436\n",
      "split: valid, n_samples: 43\n",
      "Epoch 6/100 - Valid Loss: 16.7952\n",
      "--- Epoch 7/100 ---\n",
      "split: train, n_samples: 877\n",
      "Epoch 7/100 - Train Loss: 18.8137\n",
      "split: valid, n_samples: 43\n",
      "Epoch 7/100 - Valid Loss: 17.9356\n",
      "--- Epoch 8/100 ---\n",
      "split: train, n_samples: 887\n",
      "Epoch 8/100 - Train Loss: 18.9753\n",
      "split: valid, n_samples: 43\n",
      "Epoch 8/100 - Valid Loss: 19.1857\n",
      "--- Epoch 9/100 ---\n",
      "split: train, n_samples: 900\n",
      "Epoch 9/100 - Train Loss: 18.5366\n",
      "split: valid, n_samples: 43\n",
      "Epoch 9/100 - Valid Loss: 17.5092\n",
      "--- Epoch 10/100 ---\n",
      "split: train, n_samples: 866\n",
      "Epoch 10/100 - Train Loss: 18.3431\n",
      "split: valid, n_samples: 43\n",
      "Epoch 10/100 - Valid Loss: 19.0555\n",
      "Storing checkpoint for epoch 9...\n",
      "--- Epoch 11/100 ---\n",
      "split: train, n_samples: 924\n",
      "Epoch 11/100 - Train Loss: 18.4502\n",
      "split: valid, n_samples: 43\n",
      "Epoch 11/100 - Valid Loss: 19.4461\n",
      "--- Epoch 12/100 ---\n",
      "split: train, n_samples: 891\n",
      "Epoch 12/100 - Train Loss: 18.1804\n",
      "split: valid, n_samples: 43\n",
      "Epoch 12/100 - Valid Loss: 17.6029\n",
      "--- Epoch 13/100 ---\n",
      "split: train, n_samples: 841\n",
      "Epoch 13/100 - Train Loss: 18.0218\n",
      "split: valid, n_samples: 43\n",
      "Epoch 13/100 - Valid Loss: 17.8341\n",
      "--- Epoch 14/100 ---\n",
      "split: train, n_samples: 885\n",
      "Epoch 14/100 - Train Loss: 18.1773\n",
      "split: valid, n_samples: 43\n",
      "Epoch 14/100 - Valid Loss: 18.3814\n",
      "--- Epoch 15/100 ---\n",
      "split: train, n_samples: 897\n",
      "Epoch 15/100 - Train Loss: 18.0759\n",
      "split: valid, n_samples: 43\n",
      "Epoch 15/100 - Valid Loss: 18.4122\n",
      "--- Epoch 16/100 ---\n",
      "split: train, n_samples: 899\n",
      "Epoch 16/100 - Train Loss: 18.4902\n",
      "split: valid, n_samples: 43\n",
      "Epoch 16/100 - Valid Loss: 18.4338\n",
      "--- Epoch 17/100 ---\n",
      "split: train, n_samples: 888\n",
      "Epoch 17/100 - Train Loss: 18.2517\n",
      "split: valid, n_samples: 43\n",
      "Epoch 17/100 - Valid Loss: 18.2214\n",
      "--- Epoch 18/100 ---\n",
      "split: train, n_samples: 927\n",
      "Epoch 18/100 - Train Loss: 17.9128\n",
      "split: valid, n_samples: 43\n",
      "Epoch 18/100 - Valid Loss: 17.6114\n",
      "--- Epoch 19/100 ---\n",
      "split: train, n_samples: 907\n",
      "Epoch 19/100 - Train Loss: 18.1178\n",
      "split: valid, n_samples: 43\n",
      "Epoch 19/100 - Valid Loss: 16.4423\n",
      "--- Epoch 20/100 ---\n",
      "split: train, n_samples: 884\n",
      "Epoch 20/100 - Train Loss: 17.9874\n",
      "split: valid, n_samples: 43\n",
      "Epoch 20/100 - Valid Loss: 16.4931\n",
      "Storing checkpoint for epoch 19...\n",
      "--- Epoch 21/100 ---\n",
      "split: train, n_samples: 905\n",
      "Epoch 21/100 - Train Loss: 17.8422\n",
      "split: valid, n_samples: 43\n",
      "Epoch 21/100 - Valid Loss: 17.8852\n",
      "--- Epoch 22/100 ---\n",
      "split: train, n_samples: 870\n",
      "Epoch 22/100 - Train Loss: 17.7587\n",
      "split: valid, n_samples: 43\n",
      "Epoch 22/100 - Valid Loss: 17.3751\n",
      "--- Epoch 23/100 ---\n",
      "split: train, n_samples: 892\n",
      "Epoch 23/100 - Train Loss: 17.9708\n",
      "split: valid, n_samples: 43\n",
      "Epoch 23/100 - Valid Loss: 18.3102\n",
      "--- Epoch 24/100 ---\n",
      "split: train, n_samples: 886\n",
      "Epoch 24/100 - Train Loss: 18.0962\n",
      "split: valid, n_samples: 43\n",
      "Epoch 24/100 - Valid Loss: 16.5740\n",
      "--- Epoch 25/100 ---\n",
      "split: train, n_samples: 881\n",
      "Epoch 25/100 - Train Loss: 17.5447\n",
      "split: valid, n_samples: 43\n",
      "Epoch 25/100 - Valid Loss: 17.6371\n",
      "--- Epoch 26/100 ---\n",
      "split: train, n_samples: 899\n",
      "Epoch 26/100 - Train Loss: 17.8070\n",
      "split: valid, n_samples: 43\n",
      "Epoch 26/100 - Valid Loss: 16.6315\n",
      "--- Epoch 27/100 ---\n",
      "split: train, n_samples: 852\n",
      "Epoch 27/100 - Train Loss: 17.9817\n",
      "split: valid, n_samples: 43\n",
      "Epoch 27/100 - Valid Loss: 18.0876\n",
      "--- Epoch 28/100 ---\n",
      "split: train, n_samples: 872\n",
      "Epoch 28/100 - Train Loss: 17.9263\n",
      "split: valid, n_samples: 43\n",
      "Epoch 28/100 - Valid Loss: 18.6351\n",
      "--- Epoch 29/100 ---\n",
      "split: train, n_samples: 886\n",
      "Epoch 29/100 - Train Loss: 18.1976\n",
      "split: valid, n_samples: 43\n",
      "Epoch 29/100 - Valid Loss: 15.7808\n",
      "--- Epoch 30/100 ---\n",
      "split: train, n_samples: 896\n",
      "Epoch 30/100 - Train Loss: 17.8459\n",
      "split: valid, n_samples: 43\n",
      "Epoch 30/100 - Valid Loss: 18.1074\n",
      "Storing checkpoint for epoch 29...\n",
      "--- Epoch 31/100 ---\n",
      "split: train, n_samples: 851\n",
      "Epoch 31/100 - Train Loss: 17.5485\n",
      "split: valid, n_samples: 43\n",
      "Epoch 31/100 - Valid Loss: 16.7653\n",
      "--- Epoch 32/100 ---\n",
      "split: train, n_samples: 878\n",
      "Epoch 32/100 - Train Loss: 17.7907\n",
      "split: valid, n_samples: 43\n",
      "Epoch 32/100 - Valid Loss: 17.6169\n",
      "--- Epoch 33/100 ---\n",
      "split: train, n_samples: 860\n",
      "Epoch 33/100 - Train Loss: 17.7614\n",
      "split: valid, n_samples: 43\n",
      "Epoch 33/100 - Valid Loss: 17.1410\n",
      "--- Epoch 34/100 ---\n",
      "split: train, n_samples: 875\n",
      "Epoch 34/100 - Train Loss: 17.6811\n",
      "split: valid, n_samples: 43\n",
      "Epoch 34/100 - Valid Loss: 17.6487\n",
      "--- Epoch 35/100 ---\n",
      "split: train, n_samples: 914\n",
      "Epoch 35/100 - Train Loss: 17.4675\n",
      "split: valid, n_samples: 43\n",
      "Epoch 35/100 - Valid Loss: 16.6772\n",
      "--- Epoch 36/100 ---\n",
      "split: train, n_samples: 864\n",
      "Epoch 36/100 - Train Loss: 17.9612\n",
      "split: valid, n_samples: 43\n",
      "Epoch 36/100 - Valid Loss: 18.5687\n",
      "--- Epoch 37/100 ---\n",
      "split: train, n_samples: 867\n",
      "Epoch 37/100 - Train Loss: 17.5691\n",
      "split: valid, n_samples: 43\n",
      "Epoch 37/100 - Valid Loss: 18.3356\n",
      "--- Epoch 38/100 ---\n",
      "split: train, n_samples: 869\n",
      "Epoch 38/100 - Train Loss: 17.5634\n",
      "split: valid, n_samples: 43\n",
      "Epoch 38/100 - Valid Loss: 16.3741\n",
      "--- Epoch 39/100 ---\n",
      "split: train, n_samples: 915\n",
      "Epoch 39/100 - Train Loss: 17.8169\n",
      "split: valid, n_samples: 43\n",
      "Epoch 39/100 - Valid Loss: 18.0275\n",
      "--- Epoch 40/100 ---\n",
      "split: train, n_samples: 846\n",
      "Epoch 40/100 - Train Loss: 18.0074\n",
      "split: valid, n_samples: 43\n",
      "Epoch 40/100 - Valid Loss: 17.2471\n",
      "Storing checkpoint for epoch 39...\n",
      "--- Epoch 41/100 ---\n",
      "split: train, n_samples: 856\n",
      "Epoch 41/100 - Train Loss: 17.5576\n",
      "split: valid, n_samples: 43\n",
      "Epoch 41/100 - Valid Loss: 16.2934\n",
      "--- Epoch 42/100 ---\n",
      "split: train, n_samples: 828\n",
      "Epoch 42/100 - Train Loss: 17.2472\n",
      "split: valid, n_samples: 43\n",
      "Epoch 42/100 - Valid Loss: 17.6919\n",
      "--- Epoch 43/100 ---\n",
      "split: train, n_samples: 865\n",
      "Epoch 43/100 - Train Loss: 17.4665\n",
      "split: valid, n_samples: 43\n",
      "Epoch 43/100 - Valid Loss: 17.7696\n",
      "--- Epoch 44/100 ---\n",
      "split: train, n_samples: 904\n",
      "Epoch 44/100 - Train Loss: 17.3782\n",
      "split: valid, n_samples: 43\n",
      "Epoch 44/100 - Valid Loss: 16.7028\n",
      "--- Epoch 45/100 ---\n",
      "split: train, n_samples: 921\n",
      "Epoch 45/100 - Train Loss: 17.6431\n",
      "split: valid, n_samples: 43\n",
      "Epoch 45/100 - Valid Loss: 16.7879\n",
      "--- Epoch 46/100 ---\n",
      "split: train, n_samples: 855\n",
      "Epoch 46/100 - Train Loss: 17.3898\n",
      "split: valid, n_samples: 43\n",
      "Epoch 46/100 - Valid Loss: 17.0062\n",
      "--- Epoch 47/100 ---\n",
      "split: train, n_samples: 933\n",
      "Epoch 47/100 - Train Loss: 17.8777\n",
      "split: valid, n_samples: 43\n",
      "Epoch 47/100 - Valid Loss: 19.0150\n",
      "--- Epoch 48/100 ---\n",
      "split: train, n_samples: 913\n",
      "Epoch 48/100 - Train Loss: 17.5559\n",
      "split: valid, n_samples: 43\n",
      "Epoch 48/100 - Valid Loss: 17.1474\n",
      "--- Epoch 49/100 ---\n",
      "split: train, n_samples: 863\n",
      "Epoch 49/100 - Train Loss: 17.6589\n",
      "split: valid, n_samples: 43\n",
      "Epoch 49/100 - Valid Loss: 17.9707\n",
      "--- Epoch 50/100 ---\n",
      "split: train, n_samples: 890\n",
      "Epoch 50/100 - Train Loss: 17.4348\n",
      "split: valid, n_samples: 43\n",
      "Epoch 50/100 - Valid Loss: 17.7804\n",
      "Storing checkpoint for epoch 49...\n",
      "--- Epoch 51/100 ---\n",
      "split: train, n_samples: 903\n",
      "Epoch 51/100 - Train Loss: 17.5346\n",
      "split: valid, n_samples: 43\n",
      "Epoch 51/100 - Valid Loss: 16.8311\n",
      "--- Epoch 52/100 ---\n",
      "split: train, n_samples: 901\n",
      "Epoch 52/100 - Train Loss: 17.3227\n",
      "split: valid, n_samples: 43\n",
      "Epoch 52/100 - Valid Loss: 16.1142\n",
      "--- Epoch 53/100 ---\n",
      "split: train, n_samples: 912\n",
      "Epoch 53/100 - Train Loss: 17.4667\n",
      "split: valid, n_samples: 43\n",
      "Epoch 53/100 - Valid Loss: 19.3748\n",
      "--- Epoch 54/100 ---\n",
      "split: train, n_samples: 884\n",
      "Epoch 54/100 - Train Loss: 17.6630\n",
      "split: valid, n_samples: 43\n",
      "Epoch 54/100 - Valid Loss: 16.8261\n",
      "--- Epoch 55/100 ---\n",
      "split: train, n_samples: 899\n",
      "Epoch 55/100 - Train Loss: 17.7133\n",
      "split: valid, n_samples: 43\n",
      "Epoch 55/100 - Valid Loss: 18.0299\n",
      "--- Epoch 56/100 ---\n",
      "split: train, n_samples: 887\n",
      "Epoch 56/100 - Train Loss: 17.4777\n",
      "split: valid, n_samples: 43\n",
      "Epoch 56/100 - Valid Loss: 16.1457\n",
      "--- Epoch 57/100 ---\n",
      "split: train, n_samples: 938\n",
      "Epoch 57/100 - Train Loss: 17.5571\n",
      "split: valid, n_samples: 43\n",
      "Epoch 57/100 - Valid Loss: 16.7655\n",
      "--- Epoch 58/100 ---\n",
      "split: train, n_samples: 922\n",
      "Epoch 58/100 - Train Loss: 17.7497\n",
      "split: valid, n_samples: 43\n",
      "Epoch 58/100 - Valid Loss: 18.3790\n",
      "--- Epoch 59/100 ---\n",
      "split: train, n_samples: 879\n",
      "Epoch 59/100 - Train Loss: 17.5456\n",
      "split: valid, n_samples: 43\n",
      "Epoch 59/100 - Valid Loss: 17.4218\n",
      "--- Epoch 60/100 ---\n",
      "split: train, n_samples: 904\n",
      "Epoch 60/100 - Train Loss: 17.7391\n",
      "split: valid, n_samples: 43\n",
      "Epoch 60/100 - Valid Loss: 18.3798\n",
      "Storing checkpoint for epoch 59...\n",
      "--- Epoch 61/100 ---\n",
      "split: train, n_samples: 870\n",
      "Epoch 61/100 - Train Loss: 17.3674\n",
      "split: valid, n_samples: 43\n",
      "Epoch 61/100 - Valid Loss: 17.2848\n",
      "--- Epoch 62/100 ---\n",
      "split: train, n_samples: 906\n",
      "Epoch 62/100 - Train Loss: 17.6335\n",
      "split: valid, n_samples: 43\n",
      "Epoch 62/100 - Valid Loss: 19.2472\n",
      "--- Epoch 63/100 ---\n",
      "split: train, n_samples: 877\n",
      "Epoch 63/100 - Train Loss: 17.4381\n",
      "split: valid, n_samples: 43\n",
      "Epoch 63/100 - Valid Loss: 17.6729\n",
      "--- Epoch 64/100 ---\n",
      "split: train, n_samples: 892\n",
      "Epoch 64/100 - Train Loss: 17.7022\n",
      "split: valid, n_samples: 43\n",
      "Epoch 64/100 - Valid Loss: 18.2730\n",
      "--- Epoch 65/100 ---\n",
      "split: train, n_samples: 875\n",
      "Epoch 65/100 - Train Loss: 17.7373\n",
      "split: valid, n_samples: 43\n",
      "Epoch 65/100 - Valid Loss: 17.9204\n",
      "--- Epoch 66/100 ---\n",
      "split: train, n_samples: 888\n",
      "Epoch 66/100 - Train Loss: 17.4502\n",
      "split: valid, n_samples: 43\n",
      "Epoch 66/100 - Valid Loss: 17.9302\n",
      "--- Epoch 67/100 ---\n",
      "split: train, n_samples: 892\n",
      "Epoch 67/100 - Train Loss: 17.8096\n",
      "split: valid, n_samples: 43\n",
      "Epoch 67/100 - Valid Loss: 16.8057\n",
      "--- Epoch 68/100 ---\n",
      "split: train, n_samples: 927\n",
      "Epoch 68/100 - Train Loss: 17.3244\n",
      "split: valid, n_samples: 43\n",
      "Epoch 68/100 - Valid Loss: 16.9935\n",
      "--- Epoch 69/100 ---\n",
      "split: train, n_samples: 909\n",
      "Epoch 69/100 - Train Loss: 17.5585\n",
      "split: valid, n_samples: 43\n",
      "Epoch 69/100 - Valid Loss: 15.9056\n",
      "--- Epoch 70/100 ---\n",
      "split: train, n_samples: 875\n",
      "Epoch 70/100 - Train Loss: 17.1766\n",
      "split: valid, n_samples: 43\n",
      "Epoch 70/100 - Valid Loss: 16.9111\n",
      "Storing checkpoint for epoch 69...\n",
      "--- Epoch 71/100 ---\n",
      "split: train, n_samples: 917\n",
      "Epoch 71/100 - Train Loss: 17.9147\n",
      "split: valid, n_samples: 43\n",
      "Epoch 71/100 - Valid Loss: 16.9490\n",
      "--- Epoch 72/100 ---\n",
      "split: train, n_samples: 865\n",
      "Epoch 72/100 - Train Loss: 17.2647\n",
      "split: valid, n_samples: 43\n",
      "Epoch 72/100 - Valid Loss: 18.3380\n",
      "--- Epoch 73/100 ---\n",
      "split: train, n_samples: 857\n",
      "Epoch 73/100 - Train Loss: 17.9413\n",
      "split: valid, n_samples: 43\n",
      "Epoch 73/100 - Valid Loss: 16.5874\n",
      "--- Epoch 74/100 ---\n",
      "split: train, n_samples: 882\n",
      "Epoch 74/100 - Train Loss: 17.7146\n",
      "split: valid, n_samples: 43\n",
      "Epoch 74/100 - Valid Loss: 16.5467\n",
      "--- Epoch 75/100 ---\n",
      "split: train, n_samples: 903\n",
      "Epoch 75/100 - Train Loss: 17.2090\n",
      "split: valid, n_samples: 43\n",
      "Epoch 75/100 - Valid Loss: 18.6009\n",
      "--- Epoch 76/100 ---\n",
      "split: train, n_samples: 866\n",
      "Epoch 76/100 - Train Loss: 17.6968\n",
      "split: valid, n_samples: 43\n",
      "Epoch 76/100 - Valid Loss: 16.5453\n",
      "--- Epoch 77/100 ---\n",
      "split: train, n_samples: 903\n",
      "Epoch 77/100 - Train Loss: 17.8664\n",
      "split: valid, n_samples: 43\n",
      "Epoch 77/100 - Valid Loss: 18.4470\n",
      "--- Epoch 78/100 ---\n",
      "split: train, n_samples: 843\n",
      "Epoch 78/100 - Train Loss: 17.5829\n",
      "split: valid, n_samples: 43\n",
      "Epoch 78/100 - Valid Loss: 16.2573\n",
      "--- Epoch 79/100 ---\n",
      "split: train, n_samples: 901\n",
      "Epoch 79/100 - Train Loss: 17.6683\n",
      "split: valid, n_samples: 43\n",
      "Epoch 79/100 - Valid Loss: 19.0679\n",
      "--- Epoch 80/100 ---\n",
      "split: train, n_samples: 925\n",
      "Epoch 80/100 - Train Loss: 17.6864\n",
      "split: valid, n_samples: 43\n",
      "Epoch 80/100 - Valid Loss: 16.9333\n",
      "Storing checkpoint for epoch 79...\n",
      "--- Epoch 81/100 ---\n",
      "split: train, n_samples: 912\n",
      "Epoch 81/100 - Train Loss: 17.4204\n",
      "split: valid, n_samples: 43\n",
      "Epoch 81/100 - Valid Loss: 17.6023\n",
      "--- Epoch 82/100 ---\n",
      "split: train, n_samples: 914\n",
      "Epoch 82/100 - Train Loss: 17.4418\n",
      "split: valid, n_samples: 43\n",
      "Epoch 82/100 - Valid Loss: 18.5580\n",
      "--- Epoch 83/100 ---\n",
      "split: train, n_samples: 947\n",
      "Epoch 83/100 - Train Loss: 17.6311\n",
      "split: valid, n_samples: 43\n",
      "Epoch 83/100 - Valid Loss: 18.6257\n",
      "--- Epoch 84/100 ---\n",
      "split: train, n_samples: 878\n",
      "Epoch 84/100 - Train Loss: 17.3853\n",
      "split: valid, n_samples: 43\n",
      "Epoch 84/100 - Valid Loss: 18.5675\n",
      "--- Epoch 85/100 ---\n",
      "split: train, n_samples: 899\n",
      "Epoch 85/100 - Train Loss: 17.2791\n",
      "split: valid, n_samples: 43\n",
      "Epoch 85/100 - Valid Loss: 16.4449\n",
      "--- Epoch 86/100 ---\n",
      "split: train, n_samples: 901\n",
      "Epoch 86/100 - Train Loss: 17.5120\n",
      "split: valid, n_samples: 43\n",
      "Epoch 86/100 - Valid Loss: 18.4052\n",
      "--- Epoch 87/100 ---\n",
      "split: train, n_samples: 867\n",
      "Epoch 87/100 - Train Loss: 17.6105\n",
      "split: valid, n_samples: 43\n",
      "Epoch 87/100 - Valid Loss: 16.9395\n",
      "--- Epoch 88/100 ---\n",
      "split: train, n_samples: 885\n",
      "Epoch 88/100 - Train Loss: 17.3866\n",
      "split: valid, n_samples: 43\n",
      "Epoch 88/100 - Valid Loss: 17.8229\n",
      "--- Epoch 89/100 ---\n",
      "split: train, n_samples: 936\n",
      "Epoch 89/100 - Train Loss: 17.5457\n",
      "split: valid, n_samples: 43\n",
      "Epoch 89/100 - Valid Loss: 16.7966\n",
      "--- Epoch 90/100 ---\n",
      "split: train, n_samples: 886\n",
      "Epoch 90/100 - Train Loss: 17.6853\n",
      "split: valid, n_samples: 43\n",
      "Epoch 90/100 - Valid Loss: 16.5889\n",
      "Storing checkpoint for epoch 89...\n",
      "--- Epoch 91/100 ---\n",
      "split: train, n_samples: 855\n",
      "Epoch 91/100 - Train Loss: 17.7373\n",
      "split: valid, n_samples: 43\n",
      "Epoch 91/100 - Valid Loss: 16.7680\n",
      "--- Epoch 92/100 ---\n",
      "split: train, n_samples: 891\n",
      "Epoch 92/100 - Train Loss: 17.3618\n",
      "split: valid, n_samples: 43\n",
      "Epoch 92/100 - Valid Loss: 17.7772\n",
      "--- Epoch 93/100 ---\n",
      "split: train, n_samples: 908\n",
      "Epoch 93/100 - Train Loss: 17.5570\n",
      "split: valid, n_samples: 43\n",
      "Epoch 93/100 - Valid Loss: 18.7175\n",
      "--- Epoch 94/100 ---\n",
      "split: train, n_samples: 884\n",
      "Epoch 94/100 - Train Loss: 17.5950\n",
      "split: valid, n_samples: 43\n",
      "Epoch 94/100 - Valid Loss: 16.6918\n",
      "--- Epoch 95/100 ---\n",
      "split: train, n_samples: 932\n",
      "Epoch 95/100 - Train Loss: 17.5666\n",
      "split: valid, n_samples: 43\n",
      "Epoch 95/100 - Valid Loss: 18.3796\n",
      "--- Epoch 96/100 ---\n",
      "split: train, n_samples: 868\n",
      "Epoch 96/100 - Train Loss: 17.9173\n",
      "split: valid, n_samples: 43\n",
      "Epoch 96/100 - Valid Loss: 17.6388\n",
      "--- Epoch 97/100 ---\n",
      "split: train, n_samples: 875\n",
      "Epoch 97/100 - Train Loss: 17.3917\n",
      "split: valid, n_samples: 43\n",
      "Epoch 97/100 - Valid Loss: 16.3162\n",
      "--- Epoch 98/100 ---\n",
      "split: train, n_samples: 873\n",
      "Epoch 98/100 - Train Loss: 17.6753\n",
      "split: valid, n_samples: 43\n",
      "Epoch 98/100 - Valid Loss: 16.9010\n",
      "--- Epoch 99/100 ---\n",
      "split: train, n_samples: 943\n",
      "Epoch 99/100 - Train Loss: 17.6990\n",
      "split: valid, n_samples: 43\n",
      "Epoch 99/100 - Valid Loss: 17.1502\n",
      "--- Epoch 100/100 ---\n",
      "split: train, n_samples: 849\n",
      "Epoch 100/100 - Train Loss: 17.7332\n",
      "split: valid, n_samples: 43\n",
      "Epoch 100/100 - Valid Loss: 17.3363\n",
      "Storing checkpoint for epoch 99...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No modality with a 'from' direction was specified in the config.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxmodalix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:918\u001b[0m, in \u001b[0;36mBasePipeline.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess()\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m--> 918\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisualize()\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:498\u001b[0m, in \u001b[0;36mBasePipeline.predict\u001b[0;34m(self, data, config, from_key, to_key, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m original_input \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    496\u001b[0m predict_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_prediction_data(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 498\u001b[0m predictor_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_key\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_latent_results(\n\u001b[1;32m    503\u001b[0m     predictor_results\u001b[38;5;241m=\u001b[39mpredictor_results, predict_data\u001b[38;5;241m=\u001b[39mpredict_data\n\u001b[1;32m    504\u001b[0m )\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_reconstruction(\n\u001b[1;32m    506\u001b[0m     predictor_results\u001b[38;5;241m=\u001b[39mpredictor_results,\n\u001b[1;32m    507\u001b[0m     original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[1;32m    508\u001b[0m     predict_data\u001b[38;5;241m=\u001b[39mpredict_data,\n\u001b[1;32m    509\u001b[0m )\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:606\u001b[0m, in \u001b[0;36mBasePipeline._generate_predictions\u001b[0;34m(self, predict_data, from_key, to_key)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate predictions using the trained model.\"\"\"\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_data(predict_data\u001b[38;5;241m=\u001b[39mpredict_data)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_xmodal_trainer.py:435\u001b[0m, in \u001b[0;36mXModalTrainer.predict\u001b[0;34m(self, data, model, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m from_key \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    434\u001b[0m to_key \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 435\u001b[0m predict_keys \u001b[38;5;241m=\u001b[39m \u001b[43mfind_translation_keys\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrained_modalities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modality_dynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m from_key, to_key \u001b[38;5;241m=\u001b[39m predict_keys[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m], predict_keys[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    442\u001b[0m from_modality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modality_dynamics[from_key]\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/utils/_utils.py:465\u001b[0m, in \u001b[0;36mfind_translation_keys\u001b[0;34m(config, trained_modalities, from_key, to_key)\u001b[0m\n\u001b[1;32m    462\u001b[0m         from_key_final \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_key_final \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo modality with a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m direction was specified in the config.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_key_final \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo modality with a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m direction was specified in the config.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No modality with a 'from' direction was specified in the config."
     ]
    }
   ],
   "source": [
    "xmodalix.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75798f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9598fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
