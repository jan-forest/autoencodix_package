{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfac618",
   "metadata": {},
   "source": [
    "## Profiling and Benchmarking XModalix\n",
    "XModalix is rather slow compared to Varix, we assume this is because of the MultiModalDataSet and the CustomSampler. \n",
    "Before improving the code we profile and benchmark the components of the XModalix pipeline. We think the following modules could be relevant:\n",
    "- MultiModalDataset\n",
    "  - which is comprised of NumericDataset, or ImageDataset\n",
    "- CoverageEnsuringSampler\n",
    "- XModlixTrainer\n",
    "  - which calls multiple GeneralTrainers\n",
    "    - which is a child of BaseTrainer\n",
    "\n",
    "\n",
    "We should also profile for four different cases:\n",
    "  - single cell vs standard tabular\n",
    "  - paired vs unpaired\n",
    "  - image vs standard tabulas\n",
    "  - image vs single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded5a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: /Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "p = os.getcwd()\n",
    "d = \"autoencodix_package\"\n",
    "if d not in p:\n",
    "    raise FileNotFoundError(f\"'{d}' not found in path: {p}\")\n",
    "os.chdir(os.sep.join(p.split(os.sep)[: p.split(os.sep).index(d) + 1]))\n",
    "print(f\"Changed to: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5beaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "import autoencodix as acx\n",
    "from autoencodix.trainers import _xmodal_trainer, _general_trainer\n",
    "from autoencodix.base import BaseTrainer, BaseDataset\n",
    "from autoencodix.data import NumericDataset, MultiModalDataset, ImageDataset\n",
    "from autoencodix.data._multimodal_dataset import CoverageEnsuringSampler\n",
    "from autoencodix.utils.example_data import EXAMPLE_MULTI_SC, EXAMPLE_MULTI_BULK\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df41551",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_file = os.path.join(\"data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\")\n",
    "img_root = os.path.join(\"data/XModalix-Tut-data/images/tcga_fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b689ffe",
   "metadata": {},
   "source": [
    "#### Run XModalix to get access to all attributes we want to benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935dcf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6586896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading parquet: data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\n",
      "reading parquet: ./data/XModalix-Tut-data/combined_clin_formatted.parquet\n",
      "Given image size is possible, rescaling images to: 32x32\n",
      "Successfully loaded 3230 images for img\n",
      "anno key: paired\n",
      "anno key: img\n",
      "Converting 2261 images to torch.float32 tensors...\n",
      "Converting 646 images to torch.float32 tensors...\n",
      "Converting 323 images to torch.float32 tensors...\n",
      "key: train, type: <class 'dict'>\n",
      "key: valid, type: <class 'dict'>\n",
      "key: test, type: <class 'dict'>\n",
      "Check if we need to pretrain: multi_bulk.rna\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna\n",
      "Check if we need to pretrain: img.img\n",
      "pretrain epochs : 0\n",
      "No pretraining for img.img\n",
      "--- Epoch 1/1 ---\n",
      "split: train, n_samples: 2048.0\n",
      "Epoch 1/1 - Train Loss: 3305.5685\n",
      "Sub-losses - adver_loss: 14.4374, aggregated_sub_losses: 2571.7772, paired_loss: 424.5181, class_loss: 294.8359, multi_bulk.rna.recon_loss: 1177.7159, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 1177.7159, img.img.recon_loss: 1394.0613, img.img.var_loss: 0.0000, img.img.loss: 1394.0613, clf_loss: 1.4356\n",
      "split: valid, n_samples: 323\n",
      "Epoch 1/1 - Valid Loss: 2704.9766\n",
      "Sub-losses - adver_loss: 13.9133, aggregated_sub_losses: 2042.3851, paired_loss: 390.7518, class_loss: 257.9263, multi_bulk.rna.recon_loss: 1019.1509, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 1019.1509, img.img.recon_loss: 1023.2341, img.img.var_loss: 0.0000, img.img.loss: 1023.2341, clf_loss: 1.3666\n",
      "Storing checkpoint for epoch 0...\n",
      "Prediction complete.\n",
      "Processing latent space results into a single AnnData object...\n",
      "Identified source modality for latent space: 'multi_bulk.rna'\n",
      "  - Added 1000 source feature IDs to .uns\n",
      "Finished processing latent results.\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.configs.xmodalix_config import XModalixConfig\n",
    "from autoencodix.configs.default_config import DataConfig, DataInfo, DataCase\n",
    "\n",
    "clin_file = os.path.join(\"./data/XModalix-Tut-data/combined_clin_formatted.parquet\")\n",
    "rna_file = os.path.join(\"data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\")\n",
    "img_root = os.path.join(\"data/XModalix-Tut-data/images/tcga_fake\")\n",
    "\n",
    "xmodalix_config = XModalixConfig(\n",
    "    checkpoint_interval=100,\n",
    "    class_param=\"CANCER_TYPE\",\n",
    "    epochs=1,\n",
    "    beta=0.1,\n",
    "    gamma=10,\n",
    "    delta_class=100,\n",
    "    delta_pair=300,\n",
    "    latent_dim=6,\n",
    "    k_filter=1000,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.0005,\n",
    "    requires_paired=False,\n",
    "    device=\"mps\",\n",
    "    loss_reduction=\"sum\",\n",
    "    data_case=DataCase.IMG_TO_BULK,\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"img\": DataInfo(\n",
    "                file_path=img_root,\n",
    "                img_height_resize=32,\n",
    "                img_width_resize=32,\n",
    "                data_type=\"IMG\",\n",
    "                scaling=\"STANDARD\",\n",
    "                translate_direction=\"to\",\n",
    "                pretrain_epochs=0,\n",
    "            ),\n",
    "            \"rna\": DataInfo(\n",
    "                file_path=rna_file,\n",
    "                data_type=\"NUMERIC\",\n",
    "                scaling=\"STANDARD\",\n",
    "                pretrain_epochs=0,\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"anno\": DataInfo(file_path=clin_file, data_type=\"ANNOTATION\", sep=\"\\t\"),\n",
    "        },\n",
    "        annotation_columns=[\"CANCER_TYPE_ACRONYM\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "xmodalix = acx.XModalix(config=xmodalix_config)\n",
    "result = xmodalix.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a57e8",
   "metadata": {},
   "source": [
    "#### Getting attributes I want to profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa30578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._multimodal_dataset import create_multimodal_collate_fn, CoverageEnsuringSampler\n",
    "model = result.model\n",
    "forward_fn = xmodalix._trainer._modalities_forward\n",
    "loader = xmodalix._trainer._trainloader\n",
    "dataset: MultiModalDataset = CoverageEnsuringSampler(multimodal_dataset=loader.dataset, batch_size=xmodalix_config.batch_size)\n",
    "sampler = xmodalix._trainer\n",
    "collate_fn = create_multimodal_collate_fn(multimodal_dataset=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5d2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-12-04 16:02:42 85278:25291824 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if we need to pretrain: multi_bulk.rna\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna\n",
      "Check if we need to pretrain: img.img\n",
      "pretrain epochs : 0\n",
      "No pretraining for img.img\n",
      "--- Epoch 1/1 ---\n",
      "split: train, n_samples: 2048.0\n",
      "Epoch 1/1 - Train Loss: 3270.3477\n",
      "Sub-losses - adver_loss: 15.2660, aggregated_sub_losses: 2497.1506, paired_loss: 449.6098, class_loss: 308.3213, multi_bulk.rna.recon_loss: 1185.0723, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 1185.0723, img.img.recon_loss: 1312.0783, img.img.var_loss: 0.0000, img.img.loss: 1312.0783, clf_loss: 1.5220\n",
      "split: valid, n_samples: 323\n",
      "Epoch 1/1 - Valid Loss: 2676.2175\n",
      "Sub-losses - adver_loss: 14.6965, aggregated_sub_losses: 2042.6459, paired_loss: 366.8947, class_loss: 251.9804, multi_bulk.rna.recon_loss: 1018.4878, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 1018.4878, img.img.recon_loss: 1024.1581, img.img.var_loss: 0.0000, img.img.loss: 1024.1581, clf_loss: 1.4365\n",
      "Storing checkpoint for epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-12-04 16:02:42 85278:25291824 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-12-04 16:02:42 85278:25291824 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        10.02%      84.782ms        96.31%     815.085ms     815.085ms         288 b     -44.00 Mb             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        15.12%     127.966ms        24.10%     203.973ms      29.139ms      18.31 Mb     -35.34 Kb             7  \n",
      "                                             aten::mean        15.84%     134.022ms        15.84%     134.022ms       3.622ms           0 b           0 b            37  \n",
      "                                             collate_fn         8.33%      70.518ms         8.95%      75.739ms       7.574ms      18.31 Mb           0 b            10  \n",
      "                              Optimizer.step#AdamW.step         0.92%       7.758ms         8.31%      70.367ms       5.864ms         272 b      -3.79 Kb            12  \n",
      "                                          aten::randint         0.02%     197.000us         6.99%      59.178ms       1.259ms           0 b           0 b            47  \n",
      "                                          aten::random_         6.97%      59.031ms         6.97%      59.031ms       1.181ms           0 b           0 b            50  \n",
      "                                             aten::item         0.54%       4.604ms         6.15%      52.086ms      27.299us         164 b        -196 b          1908  \n",
      "                              aten::_local_scalar_dense         6.10%      51.614ms         6.13%      51.861ms      27.181us         360 b        -928 b          1908  \n",
      "                                               aten::to         0.53%       4.527ms         5.74%      48.615ms       8.999us      18.61 Mb       5.95 Mb          5402  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 846.324ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU]\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    activities += [ProfilerActivity.CUDA]\n",
    "\n",
    "\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "\n",
    "with profile(activities=activities, record_shapes=True, profile_memory=True, with_stack=False,\n",
    "    experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True)) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        \n",
    "        xmodalix.fit()\n",
    "        #forward_fn(next(iter(loader)))\n",
    "\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c69b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        10.02%      84.782ms        96.31%     815.085ms     815.085ms         288 b     -44.00 Mb             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        15.12%     127.966ms        24.10%     203.973ms      29.139ms      18.31 Mb     -35.34 Kb             7  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 846.324ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daf2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b54e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencodix_package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
