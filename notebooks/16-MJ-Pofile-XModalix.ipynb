{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfac618",
   "metadata": {},
   "source": [
    "## Profiling and Benchmarking XModalix\n",
    "XModalix is rather slow compared to Varix, we assume this is because of the MultiModalDataSet and the CustomSampler. \n",
    "Before improving the code we profile and benchmark the components of the XModalix pipeline. We think the following modules could be relevant:\n",
    "- MultiModalDataset\n",
    "  - which is comprised of NumericDataset, or ImageDataset\n",
    "- CoverageEnsuringSampler\n",
    "- XModlixTrainer\n",
    "  - which calls multiple GeneralTrainers\n",
    "    - which is a child of BaseTrainer\n",
    "\n",
    "\n",
    "We should also profile for four different cases:\n",
    "  - single cell vs standard tabular\n",
    "  - paired vs unpaired\n",
    "  - image vs standard tabulas\n",
    "  - image vs single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded5a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: /Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "p = os.getcwd()\n",
    "d = \"autoencodix_package\"\n",
    "if d not in p:\n",
    "    raise FileNotFoundError(f\"'{d}' not found in path: {p}\")\n",
    "os.chdir(os.sep.join(p.split(os.sep)[: p.split(os.sep).index(d) + 1]))\n",
    "print(f\"Changed to: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5beaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "import autoencodix as acx\n",
    "from autoencodix.trainers import _xmodal_trainer, _general_trainer\n",
    "from autoencodix.base import BaseTrainer, BaseDataset\n",
    "from autoencodix.data import NumericDataset, MultiModalDataset, ImageDataset\n",
    "from autoencodix.data._multimodal_dataset import CoverageEnsuringSampler\n",
    "from autoencodix.utils.example_data import EXAMPLE_MULTI_SC, EXAMPLE_MULTI_BULK\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df41551",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_file = os.path.join(\"data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\")\n",
    "img_root = os.path.join(\"data/XModalix-Tut-data/images/tcga_fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b689ffe",
   "metadata": {},
   "source": [
    "#### Run XModalix to get access to all attributes we want to benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935dcf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6586896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading parquet: data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\n",
      "reading parquet: data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\n",
      "reading parquet: ./data/XModalix-Tut-data/combined_clin_formatted.parquet\n",
      "anno key: rna\n",
      "anno key: rna2\n",
      "key: train, type: <class 'dict'>\n",
      "key: valid, type: <class 'dict'>\n",
      "key: test, type: <class 'dict'>\n",
      "Check if we need to pretrain: multi_bulk.rna\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna\n",
      "Check if we need to pretrain: multi_bulk.rna2\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna2\n",
      "--- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/autograd/profiler.py:228: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2025-12-05 14:15:32 50262:556503 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2025-12-05 14:15:32 50262:556503 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-12-05 14:15:32 50262:556503 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROFILER SUMMARY - Top Operations by CPU Time\n",
      "================================================================================\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        22.46%      18.707ms       100.00%      83.276ms      27.759ms       7.01 Mb      -1.95 Mb             3  \n",
      "                                            total_batch         0.26%     214.000us        58.65%      48.843ms      24.422ms       5.05 Mb           0 b             2  \n",
      "                                     modalities_forward         4.68%       3.894ms        22.27%      18.545ms       9.273ms      11.83 Mb      -9.96 Mb             2  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.39%      13.647ms        18.88%      15.726ms       5.242ms       3.91 Mb     -19.42 Kb             3  \n",
      "                                          backward_pass         1.90%       1.586ms        12.83%      10.688ms       5.344ms      -8.17 Mb      -1.11 Mb             2  \n",
      "                              Optimizer.step#AdamW.step         4.85%       4.040ms         9.17%       7.633ms       1.272ms           0 b      -4.10 Mb             6  \n",
      "                                     train_autoencoders         4.73%       3.941ms         7.92%       6.598ms       3.299ms       1.35 Mb    -942.24 Kb             2  \n",
      "                                         optimizer_step         0.11%      95.000us         7.59%       6.318ms       3.159ms           0 b           0 b             2  \n",
      "                                       train_classifier         2.22%       1.851ms         7.56%       6.296ms       3.148ms      10.13 Kb      -1.02 Mb             2  \n",
      "                                          aten::dropout         0.40%     332.000us         6.65%       5.535ms     172.969us       8.09 Mb      -1.44 Mb            32  \n",
      "                                           aten::linear         0.70%     579.000us         5.19%       4.322ms      90.042us       8.08 Mb     172.00 Kb            48  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.54%     451.000us         5.16%       4.300ms      89.583us      -3.35 Mb      -9.36 Mb            48  \n",
      "                                       aten::batch_norm        -0.03%     -21.000us         5.04%       4.201ms     175.042us       2.56 Mb           0 b            24  \n",
      "                           aten::_batch_norm_impl_index         0.34%     281.000us         5.00%       4.162ms     173.417us       2.56 Mb     250.98 Kb            24  \n",
      "                                aten::native_batch_norm         4.76%       3.961ms         4.90%       4.080ms     170.000us       2.56 Mb    -773.64 Kb            24  \n",
      "                                       aten::bernoulli_         4.72%       3.934ms         4.72%       3.934ms     122.938us     440.00 Kb     440.00 Kb            32  \n",
      "                                            aten::addmm         3.52%       2.931ms         4.52%       3.767ms      78.479us       8.08 Mb       7.03 Mb            48  \n",
      "                                         AddmmBackward0         0.29%     239.000us         3.75%       3.124ms      65.083us       6.27 Mb     -29.79 Kb            48  \n",
      "                                               aten::mm         3.21%       2.669ms         3.21%       2.669ms      29.656us       6.27 Mb       1.53 Mb            90  \n",
      "autograd::engine::evaluate_function: NativeBatchNorm...         0.08%      64.000us         3.06%       2.547ms     106.125us      -2.55 Mb      -5.59 Mb            24  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 83.276ms\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PROFILER SUMMARY - Top Operations by CUDA Time\n",
      "================================================================================\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        22.46%      18.707ms       100.00%      83.276ms      27.759ms       7.01 Mb      -1.95 Mb             3  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.39%      13.647ms        18.88%      15.726ms       5.242ms       3.91 Mb     -19.42 Kb             3  \n",
      "                                           aten::select         0.45%     377.000us         0.49%     411.000us       0.196us      36.98 Kb      36.98 Kb          2097  \n",
      "                                       aten::as_strided         0.08%      64.000us         0.08%      64.000us       0.025us     254.24 Kb     254.24 Kb          2538  \n",
      "                                            aten::stack         0.33%     272.000us         2.27%       1.888ms     157.333us       3.95 Mb           0 b            12  \n",
      "                                              aten::cat         1.95%       1.628ms         1.98%       1.646ms      91.444us       4.06 Mb       4.06 Mb            18  \n",
      "                                           aten::narrow         0.03%      21.000us         0.03%      26.000us       2.167us           0 b           0 b            12  \n",
      "                                            aten::slice         0.03%      26.000us         0.03%      26.000us       1.300us           0 b           0 b            20  \n",
      "                                             aten::view         0.03%      21.000us         0.03%      21.000us       0.241us    -276.02 Kb    -276.02 Kb            87  \n",
      "                                               aten::to         0.58%     484.000us         1.56%       1.296ms       0.445us     195.97 Kb       4.18 Kb          2911  \n",
      "                                            total_batch         0.26%     214.000us        58.65%      48.843ms      24.422ms       5.05 Mb           0 b             2  \n",
      "                                     modalities_forward         4.68%       3.894ms        22.27%      18.545ms       9.273ms      11.83 Mb      -9.96 Mb             2  \n",
      "                                           aten::linear         0.70%     579.000us         5.19%       4.322ms      90.042us       8.08 Mb     172.00 Kb            48  \n",
      "                                                aten::t         0.35%     291.000us         0.54%     453.000us       1.936us      29.79 Kb      29.79 Kb           234  \n",
      "                                        aten::transpose         0.18%     151.000us         0.20%     166.000us       0.709us           0 b           0 b           234  \n",
      "                                            aten::addmm         3.52%       2.931ms         4.52%       3.767ms      78.479us       8.08 Mb       7.03 Mb            48  \n",
      "                                           aten::expand         0.05%      42.000us         0.06%      48.000us       0.750us     828.00 Kb     828.00 Kb            64  \n",
      "                                            aten::copy_         1.03%     857.000us         1.03%     857.000us       0.973us     122.11 Kb     114.11 Kb           881  \n",
      "                                     aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us       4.74 Mb       4.74 Mb           319  \n",
      "                                             aten::add_         0.57%     475.000us         1.05%     875.000us       2.604us     -82.00 Kb     -81.15 Kb           336  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 83.276ms\n",
      "\n",
      "split: train, n_samples: 2048.0\n",
      "Epoch 1/3 - Train Loss: 1892.9218\n",
      "Sub-losses - adver_loss: 14.4392, aggregated_sub_losses: 1145.4093, paired_loss: 432.4154, class_loss: 300.6579, multi_bulk.rna.recon_loss: 573.6927, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 573.6927, multi_bulk.rna2.recon_loss: 571.7166, multi_bulk.rna2.var_loss: 0.0000, multi_bulk.rna2.loss: 571.7166, clf_loss: 1.4110\n",
      "split: valid, n_samples: 355\n",
      "Epoch 1/3 - Valid Loss: 1697.0938\n",
      "Sub-losses - adver_loss: 13.9544, aggregated_sub_losses: 1025.3759, paired_loss: 388.0267, class_loss: 269.7369, multi_bulk.rna.recon_loss: 512.6607, multi_bulk.rna.var_loss: 0.0000, multi_bulk.rna.loss: 512.6607, multi_bulk.rna2.recon_loss: 512.7152, multi_bulk.rna2.var_loss: 0.0000, multi_bulk.rna2.loss: 512.7152, clf_loss: 1.3882\n",
      "--- Epoch 2/3 ---\n",
      "split: train, n_samples: 2048.0\n",
      "Epoch 2/3 - Train Loss: 1874.5107\n",
      "Sub-losses - adver_loss: 14.4265, aggregated_sub_losses: 1133.9387, paired_loss: 426.5804, class_loss: 299.5651, multi_bulk.rna.recon_loss: 568.9346, multi_bulk.rna.var_loss: 0.0097, multi_bulk.rna.loss: 568.9443, multi_bulk.rna2.recon_loss: 564.9896, multi_bulk.rna2.var_loss: 0.0048, multi_bulk.rna2.loss: 564.9943, clf_loss: 1.4171\n",
      "split: valid, n_samples: 355\n",
      "Epoch 2/3 - Valid Loss: 1701.8933\n",
      "Sub-losses - adver_loss: 14.0505, aggregated_sub_losses: 1025.9923, paired_loss: 389.4142, class_loss: 272.4364, multi_bulk.rna.recon_loss: 512.4597, multi_bulk.rna.var_loss: 0.0025, multi_bulk.rna.loss: 512.4622, multi_bulk.rna2.recon_loss: 513.5273, multi_bulk.rna2.var_loss: 0.0027, multi_bulk.rna2.loss: 513.5300, clf_loss: 1.3951\n",
      "--- Epoch 3/3 ---\n",
      "split: train, n_samples: 2048.0\n",
      "Epoch 3/3 - Train Loss: 1834.1037\n",
      "Sub-losses - adver_loss: 14.2874, aggregated_sub_losses: 1111.7586, paired_loss: 416.8710, class_loss: 291.1867, multi_bulk.rna.recon_loss: 557.8341, multi_bulk.rna.var_loss: 0.1322, multi_bulk.rna.loss: 557.9663, multi_bulk.rna2.recon_loss: 553.6604, multi_bulk.rna2.var_loss: 0.1319, multi_bulk.rna2.loss: 553.7923, clf_loss: 1.3949\n",
      "split: valid, n_samples: 355\n",
      "Epoch 3/3 - Valid Loss: 1701.5972\n",
      "Sub-losses - adver_loss: 14.3654, aggregated_sub_losses: 1028.1121, paired_loss: 386.4129, class_loss: 272.7069, multi_bulk.rna.recon_loss: 514.1965, multi_bulk.rna.var_loss: 0.0633, multi_bulk.rna.loss: 514.2599, multi_bulk.rna2.recon_loss: 513.7709, multi_bulk.rna2.var_loss: 0.0813, multi_bulk.rna2.loss: 513.8522, clf_loss: 1.3848\n",
      "Storing checkpoint for epoch 2...\n",
      "Prediction complete.\n",
      "Processing latent space results into a single AnnData object...\n",
      "Identified source modality for latent space: 'multi_bulk.rna'\n",
      "  - Added 500 source feature IDs to .uns\n",
      "Finished processing latent results.\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.configs.xmodalix_config import XModalixConfig\n",
    "from autoencodix.configs.default_config import DataConfig, DataInfo, DataCase\n",
    "from autoencodix.modeling._imgfast_architecture import ImageVAEArchitecture\n",
    "\n",
    "clin_file = os.path.join(\"./data/XModalix-Tut-data/combined_clin_formatted.parquet\")\n",
    "rna_file = os.path.join(\"data/XModalix-Tut-data/combined_rnaseq_formatted.parquet\")\n",
    "img_root = os.path.join(\"data/XModalix-Tut-data/images/tcga_fake\")\n",
    "\n",
    "xmodalix_config = XModalixConfig(\n",
    "    checkpoint_interval=100,\n",
    "    class_param=\"CANCER_TYPE\",\n",
    "    epochs=3,\n",
    "    beta=0.1,\n",
    "    gamma=10,\n",
    "    delta_class=100,\n",
    "    delta_pair=300,\n",
    "    latent_dim=6,\n",
    "    k_filter=1000,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.0005,\n",
    "    requires_paired=False,\n",
    "    device=\"cpu\",\n",
    "    loss_reduction=\"sum\",\n",
    "    data_case=DataCase.IMG_TO_BULK,\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            # \"img\": DataInfo(\n",
    "            #     file_path=img_root,\n",
    "            #     img_height_resize=32,\n",
    "            #     img_width_resize=32,\n",
    "            #     data_type=\"IMG\",\n",
    "            #     scaling=\"STANDARD\",\n",
    "            #     translate_direction=\"to\",\n",
    "            #     pretrain_epochs=0,\n",
    "            # ),\n",
    "            \"rna\": DataInfo(\n",
    "                file_path=rna_file,\n",
    "                data_type=\"NUMERIC\",\n",
    "                scaling=\"STANDARD\",\n",
    "                pretrain_epochs=0,\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"rna2\": DataInfo(\n",
    "                file_path=rna_file,\n",
    "                data_type=\"NUMERIC\",\n",
    "                scaling=\"STANDARD\",\n",
    "                pretrain_epochs=0,\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    " \n",
    "            \"anno\": DataInfo(file_path=clin_file, data_type=\"ANNOTATION\", sep=\"\\t\"),\n",
    "        },\n",
    "        annotation_columns=[\"CANCER_TYPE_ACRONYM\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "xmodalix = acx.XModalix(config=xmodalix_config, model_type=ImageVAEArchitecture)\n",
    "result = xmodalix.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a57e8",
   "metadata": {},
   "source": [
    "#### Getting attributes I want to profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa30578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._multimodal_dataset import create_multimodal_collate_fn, CoverageEnsuringSampler\n",
    "model = result.model\n",
    "forward_fn = xmodalix._trainer._modalities_forward\n",
    "loader = xmodalix._trainer._trainloader\n",
    "dataset: MultiModalDataset = CoverageEnsuringSampler(multimodal_dataset=loader.dataset, batch_size=xmodalix_config.batch_size)\n",
    "sampler = xmodalix._trainer\n",
    "collate_fn = create_multimodal_collate_fn(multimodal_dataset=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5d2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-12-05 14:15:34 50262:556503 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/autograd/profiler.py:228: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2025-12-05 14:15:34 50262:556503 ActivityProfilerController.cpp:320] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if we need to pretrain: multi_bulk.rna\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna\n",
      "Check if we need to pretrain: multi_bulk.rna2\n",
      "pretrain epochs : 0\n",
      "No pretraining for multi_bulk.rna2\n",
      "--- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-12-05 14:15:34 50262:556503 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[W collection.cpp:940] Warning: Failed to recover relationship between all profiler and kineto events: 24106 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mxmodalix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#forward_fn(next(iter(loader)))\u001b[39;00m\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:484\u001b[0m, in \u001b[0;36mBasePipeline.fit\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_type(\n\u001b[1;32m    471\u001b[0m     trainset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[1;32m    472\u001b[0m     validset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mvalid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m     ),\n\u001b[1;32m    482\u001b[0m )\n\u001b[0;32m--> 484\u001b[0m trainer_result: Result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mupdate(other\u001b[38;5;241m=\u001b[39mtrainer_result)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_xmodal_trainer.py:482\u001b[0m, in \u001b[0;36mXModalTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_one_epoch_with_profiling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m train_epoch_dynamics, train_sub_losses, n_samples_train \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_one_epoch()\n\u001b[1;32m    485\u001b[0m )\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_xmodal_trainer.py:952\u001b[0m, in \u001b[0;36mXModalTrainer._train_one_epoch_with_profiling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Step the profiler\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Stop profiling after a few batches to avoid huge logs\u001b[39;00m\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:727\u001b[0m, in \u001b[0;36mprofile.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_num)\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transit_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m prof\u001b[38;5;241m.\u001b[39mKinetoStepTracker\u001b[38;5;241m.\u001b[39mincrement_step(PROFILER_STEP_NAME)\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:744\u001b[0m, in \u001b[0;36mprofile._transit_action\u001b[0;34m(self, prev_action, current_action)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m action_list:\n\u001b[0;32m--> 744\u001b[0m     \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:161\u001b[0m, in \u001b[0;36m_KinetoProfile.start_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofile_memory:\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/autograd/profiler.py:289\u001b[0m, in \u001b[0;36mprofile._start_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m _run_on_profiler_start()\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_enable_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkineto_activities\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Profiler is already enabled on this thread.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m     activities \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [ProfilerActivity\u001b[38;5;241m.\u001b[39mCUDA]\n\u001b[1;32m      8\u001b[0m sort_by_keyword \u001b[38;5;241m=\u001b[39m device \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_time_total\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profile(activities\u001b[38;5;241m=\u001b[39mactivities, record_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, profile_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, with_stack\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     experimental_config\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_profiler\u001b[38;5;241m.\u001b[39m_ExperimentalConfig(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m record_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     14\u001b[0m         xmodalix\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:699\u001b[0m, in \u001b[0;36mprofile.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m     prof\u001b[38;5;241m.\u001b[39mKinetoStepTracker\u001b[38;5;241m.\u001b[39merase_step_count(PROFILER_STEP_NAME)\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_trace_observer:\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:715\u001b[0m, in \u001b[0;36mprofile.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_steps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_rec_fn:\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_rec_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transit_action\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:744\u001b[0m, in \u001b[0;36mprofile._transit_action\u001b[0;34m(self, prev_action, current_action)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_list:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m action_list:\n\u001b[0;32m--> 744\u001b[0m         \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/profiler/profiler.py:199\u001b[0m, in \u001b[0;36m_KinetoProfile.stop_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_trace_observer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/autoencodix_package/.venv/lib/python3.10/site-packages/torch/autograd/profiler.py:296\u001b[0m, in \u001b[0;36mprofile.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cuda:\n\u001b[1;32m    295\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkineto_results \u001b[38;5;241m=\u001b[39m \u001b[43m_disable_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m _run_on_profiler_stop()\n\u001b[1;32m    298\u001b[0m parsed_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_kineto_results(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkineto_results)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU]\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    activities += [ProfilerActivity.CUDA]\n",
    "\n",
    "\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "\n",
    "\n",
    "with profile(activities=activities, record_shapes=True, profile_memory=True, with_stack=False,\n",
    "    experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True)) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        xmodalix.fit()\n",
    "        #forward_fn(next(iter(loader)))\n",
    "\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c69b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        15.49%        2.889s        86.51%       16.135s       16.135s         288 b    -238.10 Mb             1  \n",
      "                                       aten::batch_norm         0.00%     693.000us        29.43%        5.488s       7.687ms           0 b           0 b           714  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 18.650s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daf2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca71be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
