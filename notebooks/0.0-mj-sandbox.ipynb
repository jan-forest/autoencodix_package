{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODIX PACKAGE HANDBOOK\n",
    "This notebook demonstrates the usage of the autoencodix package.\n",
    "For now it serves as an internal guideline with the goal to:\n",
    "- test the package from a user perspective\n",
    "- serve as a first draft of user documentation\n",
    "- serve a developer guideline \n",
    "  - developer guide will be derrived from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Generate mock data\n",
    "We provide a variable for example data that can be imported easily. Later we show how to use your own data and what do keep in mind when doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/notebooks\n",
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(notebook_dir)\n",
    "os.chdir(notebook_dir)\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "# os.chdir(os.path.join(notebook_dir, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 General Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.configs.default_config import DefaultConfig, DataCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:189: UserWarning: Your config is of type: <class 'autoencodix.configs.default_config.DefaultConfig'>, for this pipeline the default params of: <class 'autoencodix.configs.vanillix_config.VanillixConfig'> work best\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in handle_direct_user_data with data: <class 'autoencodix.data.datapackage.DataPackage'>\n",
      "anno key: transcriptomics\n",
      "anno key: proteomics\n",
      "Epoch 1 - Train Loss: 17.2189\n",
      "Sub-losses: recon_loss: 17.2189\n",
      "Epoch 1 - Valid Loss: 6.4176\n",
      "Sub-losses: recon_loss: 6.4176\n",
      "Epoch 2 - Train Loss: 14.6462\n",
      "Sub-losses: recon_loss: 14.6462\n",
      "Epoch 2 - Valid Loss: 6.5787\n",
      "Sub-losses: recon_loss: 6.5787\n",
      "Epoch 3 - Train Loss: 12.6661\n",
      "Sub-losses: recon_loss: 12.6661\n",
      "Epoch 3 - Valid Loss: 6.5692\n",
      "Sub-losses: recon_loss: 6.5692\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GeneralTrainer' object has no attribute '_latentspace_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m van\u001b[38;5;241m.\u001b[39mpreprocess()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m### MODEL TRAINING ### --------------------------\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# job of old make model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# calls self.Trainer class to init and train model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# populates self._model attribute with trained model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# populates self.result attribute with training results (model, losses, etc)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mvan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m### PREDICTION ### -------------------------------\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# job of old make predict\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# if no data is passed, used the test split from preprocessing\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# otherwise, uses the data passed, and preprocesses it\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# updates self.result attribute with predictions (latent space, reconstructions, etc)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m res \u001b[38;5;241m=\u001b[39m van\u001b[38;5;241m.\u001b[39mpredict()\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/base/_base_pipeline.py:473\u001b[0m, in \u001b[0;36mBasePipeline.fit\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets not built. Please run the preprocess method first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_type(\n\u001b[1;32m    465\u001b[0m     trainset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[1;32m    466\u001b[0m     validset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets\u001b[38;5;241m.\u001b[39mvalid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m     ontologies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ontologies,  \u001b[38;5;66;03m# Ontix\u001b[39;00m\n\u001b[1;32m    472\u001b[0m )\n\u001b[0;32m--> 473\u001b[0m trainer_result: Result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mupdate(other\u001b[38;5;241m=\u001b[39mtrainer_result)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_general_trainer.py:200\u001b[0m, in \u001b[0;36mGeneralTrainer.train\u001b[0;34m(self, epochs_overwrite)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_losses(epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, valid_loss, valid_sub_losses)\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m should_checkpoint:\n\u001b[0;32m--> 200\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mchildren())\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_general_trainer.py:338\u001b[0m, in \u001b[0;36mGeneralTrainer._store_checkpoint\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stores model checkpoints and training dynamics to result object.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    epoch: The current epoch number.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mmodel_checkpoints\u001b[38;5;241m.\u001b[39madd(epoch\u001b[38;5;241m=\u001b[39mepoch, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamics_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validset:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamics_to_result(epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/trainers/_general_trainer.py:405\u001b[0m, in \u001b[0;36mGeneralTrainer._dynamics_to_result\u001b[0;34m(self, epoch, split)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer[split] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m buffer[split]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    398\u001b[0m         target\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    399\u001b[0m             epoch\u001b[38;5;241m=\u001b[39mepoch, split\u001b[38;5;241m=\u001b[39msplit, data\u001b[38;5;241m=\u001b[39mbuffer[split]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    400\u001b[0m         )\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mlatentspaces\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    403\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    404\u001b[0m     split\u001b[38;5;241m=\u001b[39msplit,\n\u001b[0;32m--> 405\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_latentspace_buffer\u001b[49m[split]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mreconstructions\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    408\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    409\u001b[0m     split\u001b[38;5;241m=\u001b[39msplit,\n\u001b[1;32m    410\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reconstruction_buffer[split]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    411\u001b[0m )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39msample_ids\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    413\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch, split\u001b[38;5;241m=\u001b[39msplit, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_ids_buffer[split]\n\u001b[1;32m    414\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneralTrainer' object has no attribute '_latentspace_buffer'"
     ]
    }
   ],
   "source": [
    "#### --------------------------------------------\n",
    "### INITIALIZATION ### --------------------------\n",
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "# config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL, scaling=\"MINMAX\", batch_size=699)\n",
    "config = DefaultConfig(\n",
    "    data_case=DataCase.MULTI_BULK, scaling=\"MINMAX\", save_memory=True\n",
    ")\n",
    "\n",
    "# van = acx.Vanillix(data=raw_sc, config=config)\n",
    "van = acx.Vanillix(data=raw_bulk, config=config)\n",
    "# ------------------------------------------------\n",
    "### DATA PROCESSING ### --------------------------\n",
    "# job of old make data\n",
    "# populates self._datasets attribute with torch datase\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# ------------------------------------------------\n",
    "### MODEL TRAINING ### --------------------------\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (model, losses, etc)\n",
    "van.fit()\n",
    "# ------------------------------------------------\n",
    "### PREDICTION ### -------------------------------\n",
    "# job of old make predict\n",
    "# if no data is passed, used the test split from preprocessing\n",
    "# otherwise, uses the data passed, and preprocesses it\n",
    "# updates self.result attribute with predictions (latent space, reconstructions, etc)\n",
    "res = van.predict()\n",
    "# ------------------------------------------------\n",
    "### EVALUATION ### -------------------------------\n",
    "# job of old make ml_task\n",
    "# populates self.result attribute with ml task results\n",
    "# van.evaluate()  # not implemented yet\n",
    "# ------------------------------------------------\n",
    "### VISUALIZATION ### ---------------------------\n",
    "# job of old make visualize\n",
    "# populates self.result attribute with visualizations\n",
    "van.visualize()\n",
    "# show visualizations for notebook use\n",
    "van.show_result()\n",
    "# --------------------------\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bulk.annotation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(van._datasets.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.feature_importance import do_feature_importance_Vanillix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CaptumForward:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.base._base_autoencoder import BaseAutoencoder\n",
    "\n",
    "from autoencodix.utils._model_output import ModelOutput\n",
    "import torch\n",
    "\n",
    "\n",
    "class CaptumForward:\n",
    "    def __init__(self, model: BaseAutoencoder, dim: int):\n",
    "        self.model = model\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        mp: ModelOutput = self.model(x=x)\n",
    "        latent = mp.latentspace\n",
    "        output = latent[:, self.dim]\n",
    "        return output.unsqueeze(1)  # Equivalent to output.reshape(output.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.predict()\n",
    "r = van.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_mb = res.datasets.train\n",
    "ds_train_mb.metadata[\"transcriptomics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.sample_ids.get(split=\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or run all steps in one command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "van = acx.Vanillix(data=raw_sc, config=config)\n",
    "\n",
    "result = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = result.datasets.train\n",
    "ds_train.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.save(file_path=\"van.pkl\", save_all=True)\n",
    "van2 = acx.Vanillix.load(\"van.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van2.result.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "recon = van.decode(latent=torch.zeros((10, 16)))\n",
    "recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = van.decode(latent=van.result.adata_latent)\n",
    "print(recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = result.reconstructions.get(split=\"train\", epoch=2)\n",
    "recons_val = result.reconstructions.get(split=\"valid\", epoch=2)\n",
    "recons_test = result.reconstructions.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(f\"Training reconstruction shape: {recons.shape} (samples x features)\")\n",
    "print(f\"Validation reconstruction shape: {recons_val.shape} (samples x features)\")\n",
    "print(f\"Test reconstruction shape: {recons_test.shape} (samples x features)\")\n",
    "print(\n",
    "    f\"Total reconstructed samples: {recons.shape[0] + recons_val.shape[0] + recons_test.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = result.latentspaces.get(split=\"train\", epoch=2)\n",
    "latents_val = result.latentspaces.get(split=\"valid\", epoch=2)\n",
    "latents_test = result.latentspaces.get(split=\"test\", epoch=-1)\n",
    "\n",
    "print(\n",
    "    f\"Training latent representations: {latents.shape} (n_samples={latents.shape[0]}, latent_dim={latents.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation latent representations: {latents_val.shape} (n_samples={latents_val.shape[0]}, latent_dim={latents_val.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test latent representations: {latents_test.shape} (n_samples={latents_test.shape[0]}, latent_dim={latents_test.shape[1]})\"\n",
    ")\n",
    "print(\n",
    "    f\"Total encoded samples: {latents.shape[0] + latents_val.shape[0] + latents_test.shape[0]}\"\n",
    ")\n",
    "print(f\"Latent space dimensionality: {latents.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a custom train, test, valid split\n",
    "When you pass the data to the pipeline, autoencodix, internally splits the data for you based on the train,test, valid ratios provided in the config (defaults are 70%/10%/20% train/valid/test).\n",
    "You can either pass custom ratios (see next section) or provide the indices directly as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autoencodix.configs.default_config import DataCase\n",
    "\n",
    "sample_data = np.random.rand(100, 10)\n",
    "custom_train_indices = np.arange(75)  # we won't allow overlap between splits\n",
    "custom_valid_indices = np.arange(75, 80)\n",
    "custom_test_indices = np.arange(80, 100)\n",
    "\n",
    "# the custom split needs to be a dictionary with keys \"train\", \"valid\", and \"test\" and indices of the samples to be included in each split as numpy arrays\n",
    "custom_split = {\n",
    "    \"train\": custom_train_indices,\n",
    "    \"valid\": custom_valid_indices,\n",
    "    \"test\": custom_test_indices,\n",
    "}\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = acx.Vanillix(data=raw_bulk, custom_splits=custom_split, config=config)\n",
    "van.preprocess()\n",
    "van.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass empty splits, but depending on how you'll use the autoencodix pipeline, this will throw an error at some point. So it is possible to call `fit` with only training data, but if you want to call `predict` and don't provide new data, this won't work without a data in the test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predict with new data\n",
    "The standard case is to train the model with the train data and then predict with the test split.\n",
    "However, it is possible to pass new data to the predict method to perform inference on this data with the already trained model.\n",
    "\n",
    "Here you have two options:\n",
    "1. Provide a fully processed dataset (similiar to `EXAMPLE_PROCESSED_DATA`) See the section `Work with you own data` for details.\n",
    "2. Provide raw data, which will be processed before predicting (also see `Work with your own data`)\n",
    "\n",
    "You pass the data with the keyword argument `data`, and depending on the datatype, the pipeline knows whether to preprocess or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume new data\n",
    "new_data = raw_bulk\n",
    "van.predict(data=new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the result of the pipeline\n",
    "Each step in the pipeline writes its results in the result object of the Vanillix instance.\n",
    "In this section we explore how to access and make sense of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = van.result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TrainingDynamics object in result\n",
    "The training dynamics object has the followinf form:\n",
    "<epoch><split><data>\n",
    "So if you want to access the train loss for the 5th epoch, you would:\n",
    "`result.lossss.get(epoch=5, split=\"train\")`\n",
    "\n",
    "##### The `.get()` Method Explained\n",
    "\n",
    "The `reconstructions.get()` method provides flexible access to reconstruction data stored during training. It can retrieve data for specific epochs, specific splits, or any combination of these parameters.\n",
    "\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "- **`epoch`** (Optional[int]): \n",
    "  - Positive integer (e.g., `2`): Get reconstructions from that specific epoch\n",
    "  - Negative integer (e.g., `-1`): Get the latest epoch (-1), second-to-last (-2), etc.\n",
    "  - `None`: Return data for all epochs\n",
    "\n",
    "- **`split`** (Optional[str]):\n",
    "  - Valid values: \"train\", \"valid\", \"test\"\n",
    "  - `None`: Return data for all splits\n",
    "\n",
    "##### Return Value Behavior:\n",
    "\n",
    "The method returns different types depending on the parameters:\n",
    "\n",
    "1. **Both `epoch` and `split` specified**:\n",
    "   - Returns a NumPy array for that specific epoch and split\n",
    "   - Example: `get(epoch=2, split=\"train\")` → `array([...])` \n",
    "\n",
    "2. **Only `epoch` specified**:\n",
    "   - Returns a dictionary of all splits for that epoch\n",
    "   - Example: `get(epoch=2)` → `{\"train\": array([...]), \"valid\": array([...]), ...}`\n",
    "\n",
    "3. **Only `split` specified**:\n",
    "   - Returns a NumPy array containing data for that split across all epochs\n",
    "   - Example: `get(split=\"train\")` → `array([[...], [...], ...])` (first dimension represents epochs)\n",
    "\n",
    "4. **Neither specified**:\n",
    "   - Returns the complete nested dictionary structure\n",
    "   - Example: `get()` → `{0: {\"train\": array([...])}, 1: {...}, ...}`\n",
    "\n",
    "##### Special Handling:\n",
    "\n",
    "- If an invalid split is provided, a `KeyError` is raised\n",
    "- Negative epoch indices work like Python list indexing (-1 is the last epoch)\n",
    "- If an epoch doesn't exist, an empty array or dictionary is returned\n",
    "\n",
    "##### Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_ep2 = result.losses.get(epoch=2, split=\"train\")\n",
    "print(loss_train_ep2)\n",
    "valid_loss = result.losses.get(split=\"valid\")\n",
    "print(valid_loss)\n",
    "print(result.losses.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.example_data import (\n",
    "    EXAMPLE_MULTI_BULK,\n",
    "    # EXAMPLE_MULTI_SC,\n",
    "    EXAMPLE_PROCESSED_DATA,\n",
    ")\n",
    "\n",
    "# EXAMPLE_DATA hold PyTorch Datasets (child with extra info) with metdata for train, test and valid splits\n",
    "processed_data = EXAMPLE_PROCESSED_DATA\n",
    "raw_bulk = EXAMPLE_MULTI_BULK\n",
    "# raw_sc = EXAMPLE_MULTI_SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this schema works for every TrainingDynamics instance in the results object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 How to get information about the default config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see what config parameters are used in the default config you can do it like:\n",
    "default_config = DefaultConfig()\n",
    "default_config.print_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02.1 Documentation Config class\n",
    "You can update the config with your own values by:\n",
    "- passing arguments as:\n",
    "    - dict\n",
    "    - single arguments\n",
    "- passing a file (sample configs and data can be found [here](https://cloud.scadsai.uni-leipzig.de/index.php/s/54aL6E6QebHDXPy))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# METHOD 1: override the default config with a dictionary\n",
    "my_args = {\"learning_rate\": 0.0234, \"batch_size\": 13, \"epochs\": 12}\n",
    "my_config = DefaultConfig(**my_args)\n",
    "# METHOD 2: override signle parameters\n",
    "my_new_conig = DefaultConfig(latent_dim=23, n_gpus=13)\n",
    "\n",
    "# METHOD 3: from a file:\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Use the Varix model\n",
    "Now we show how easy it is to use a variational autoencoder instead of a vanilla version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "from autoencodix.configs.default_config import DataCase\n",
    "import autoencodix as acx\n",
    "\n",
    "my_config = DefaultConfig(\n",
    "    learning_rate=0.001, epochs=3, pretrain_epochs=0, checkpoint_interval=1\n",
    ")\n",
    "my_config.data_case = DataCase.MULTI_BULK\n",
    "van = acx.Varix(data=processed_data, config=my_config)\n",
    "result = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config.pretrain_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.datasets.train.feature_ids)\n",
    "print(my_config.data_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine Variational result\n",
    "Here, we have more info in our results object than in the Vanillix case. We have the learned paramters mu and logvar of the normal distirbution, in addition to the losses and reconstructions. We provide also the sampled latentspaces at each epoch and split.\n",
    "\n",
    "You can resample new latenspaces (shown in next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not train for the test split, so we don't need to pass an epoch\n",
    "# technically the epoch is -1\n",
    "mu_test_ep_last = result.latentspaces.get(split=\"test\")\n",
    "print(mu_test_ep_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different loss types\n",
    "For our variation autoencoder, the total loss consists of a reconstruction loss and a distribution loss i.e. kl-divergence. To investigate these losses, the result_obj has the attribute `sub_losses`. This is a `LossRegistry` withe the name of the loss as key and the value is of class `TrainingDynamics` and can be accessed as shown for the Vanillix part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_losses = result.sub_losses\n",
    "print(f\"keys: {sub_losses.keys()}\")\n",
    "recon_dyn = sub_losses.get(key=\"recon_loss\")\n",
    "print(recon_dyn.get(split=\"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample new latentspaces\n",
    "You might want to use the trained model and the fitted parameters mu, and logvar to sample latentspaces. Therefore, the Varix pipeline has the additional method `sample_latent_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = van.sample_latent_space()\n",
    "\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also select a specific epoch and split to sample from (default is last epoch and test split)\n",
    "sampled = van.sample_latent_space(epoch=2, split=\"valid\")\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or sample multiple times\n",
    "for _ in range(5):\n",
    "    sampled = van.sample_latent_space()\n",
    "    print(sampled[:3, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Work with your own data\n",
    "In the above steps we showed how to use `Autoencodix` with mock data. Nowe we demonstrate how to use real-world data. There are three main use cases:\n",
    "1. Use data from raw files and define the path and metainfo via the config (file or DefaultConfig class).\n",
    "2. Provide the raw data directly in Python and pass it to our `DataPackage` structure. This `DataPackage` then can be passed to to our Pipeline where it will pre preprocessed.\n",
    "3. Take care of the preprocessing yourself and pass the `DatasetContainer` to our pipeline. We show how to fill this `DatasetContainer` object with your preprocsedded data.\n",
    "\n",
    "### 04.1 Working with data from files\n",
    "Here we specialize on different kind of omics data. We cover:\n",
    "1. combining multi-omics data from bulk sequencing (e.g. mRNA and methylation).\n",
    "2. combining multi-omics data from single cell sequencing.\n",
    "3. \"Translating\" between multi-omics data e.g. scRNA <-> scATAC, or bulkmRNA <-> bulkmiRNA\n",
    "4. Working with image data\n",
    "5. \"translating\" between data-modalities\n",
    "  - one bulk-omics modality to another\n",
    "  - omics to image an vice versa\n",
    "\n",
    "#### 04.1.1 Combining mulit-omics data from bulk-sequencing\n",
    "First we need to prepare our config object. We can (a) directly provide an object in python, or (b) provide an YAML file. We show both\n",
    "\n",
    "##### YAML config\n",
    "Assume we have the file in `./config.yaml`.\n",
    "We can keep the yaml file structure to define our input data like:\n",
    "```yaml\n",
    "data_config: # has to be named data_config\n",
    "  data_info: # has to be named data_infor\n",
    "   RNA: # name can be chosen by user\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   METHYLATION: # can be chosen by user\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   CLINICAL: # can be chosen by user\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\" # default NUMERIC (as for RNA and METHYLATION)\n",
    "```\n",
    "ATTENTION:\n",
    "If you use `.txt` or `.csv` files, it is best practice to add the `sep` parameter. If none is given, the reader will try to auto-detect the separator, which is error prone.\n",
    "This would loke like:\n",
    "```YAML\n",
    "    RNA:\n",
    "      ...\n",
    "      sep: \"\\t\" # for tab, \";\" or \",\" would be also possible (as in pandas)\n",
    "\n",
    "```\n",
    "**IMPORTANT**\n",
    "\n",
    "For all your bulk data files, we expect the first column to be some kind of unique sample id. Please prepare the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# this fills the data_config attribute of the DefaultConfig object\n",
    "# we can also change the default values in the config.yaml file\n",
    "# or via the DefaultConfig object\n",
    "bulk_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text())\n",
    ")\n",
    "# this bulk_config object can then be passed to a Pipeline (Varix, Vanillix, etc)\n",
    "var_bulk = acx.Varix(config=bulk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_bulk.config.print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.model.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = var_bulk.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overwrite or add values to our config from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with custom values\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create DataConfig in Python\n",
    "Instead of reading the config from the file, we can also create it directly in Ptyon\n",
    "We will only use one way of config creation for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.default_config import DataConfig, DataInfo\n",
    "\n",
    "root_dir = os.path.join(\"data/raw\")\n",
    "meth_file = \"data_methylation_per_gene_formatted.parquet\"\n",
    "mrna_file = \"data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "clin_file = \"data_clinical_formatted.parquet\"\n",
    "\n",
    "bulk_config = DefaultConfig(\n",
    "    scaling=\"MINMAX\",\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, mrna_file), scaling=\"STANDARD\"\n",
    "            ),\n",
    "            \"METHYLATION\": DataInfo(file_path=os.path.join(root_dir, meth_file)),\n",
    "            \"CLINICAL\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, clin_file), data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van = acx.Vanillix(config=bulk_config)\n",
    "r = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    van._preprocessor._datapackage_dict[\"train\"][\"data\"].multi_bulk[\"METHYLATION\"].max()\n",
    ")\n",
    "print(\n",
    "    van._preprocessor._datapackage_dict[\"train\"][\"data\"].multi_bulk[\"METHYLATION\"].min()\n",
    ")\n",
    "\n",
    "\n",
    "print(van._preprocessor._datapackage_dict[\"train\"][\"data\"].multi_bulk[\"RNA\"].mean())\n",
    "print(van._preprocessor._datapackage_dict[\"train\"][\"data\"].multi_bulk[\"RNA\"].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.2 Working with single cell data from different sequencing processes\n",
    "First we define our config again, then we use the reader object to build the MuData object (this will look more familar for single cell practioners)\n",
    "\n",
    "We can provide a config yaml like:\n",
    "```yaml\n",
    "# config.yaml\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\" # we request h5ad files\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "scconfig = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/largesc.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "\n",
    "sc_van = acx.Vanillix(config=scconfig)\n",
    "\n",
    "sc_van.preprocess()\n",
    "# result = sc_van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "filepath = \"data/raw/Sc-2-mini.h5ad\"\n",
    "adata = sc.read(filepath)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pympler import asizeof\n",
    "from scipy import sparse\n",
    "\n",
    "print((sparse.issparse(adata.X)))\n",
    "print(adata.X.toarray().shape)\n",
    "sparse.issparse(adata.X.toarray())\n",
    "\n",
    "size_sparse = asizeof.asizeof(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dense = asizeof.asizeof(adata.X.toarray(), detail=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dense > size_sparse\n",
    "(size_sparse - size_dense) / size_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van._datasets.test.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_van._datasets.train.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can pass the `scconfig` to our Pipeline as shown with the bulk example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.3 Translating between omics data\n",
    "We only allow bulk to bulk and single-cell to single cell. The config is almost identical to the case before, we only add the direction of the translation like:\n",
    "```YAML\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "     translate_direction: \"FROM\"\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     translate_direction: \"TO\"\n",
    "\n",
    "```\n",
    "\n",
    "For the bulk case we can keep annotation data without including it in the translation like:\n",
    "```YAML\n",
    "# config.yaml\n",
    "data_config:\n",
    "  data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"FROM\"\n",
    "   METHYLATION:\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"TO\"\n",
    "   CLINICAL:\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\"\n",
    "     # default translate_direction is  NONE, so we don't need to specify it here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1.4 Working with images\n",
    "When working with images, we need have two cases:\n",
    "- pure image, without translating\n",
    "- translating between omics and images\n",
    "\n",
    "In the first case we need to provide the folder path of the images. In the second case we need to provide the folder path of the images and an annotation file that maps the metadata for the images to the image filenames. In this file we also need to map the sample_ids of the other data modality to the image filename and metadata. Later we will add support for an unpaired case, where we only provide image metadata without mapping to the other data modality.\n",
    "The file should look like this:\n",
    "**important**: this file needs to contain the columns `sample_ids` and `img_paths`\n",
    "```text\n",
    "sample_ids\timg_paths\tMETADATA1\tMETADATA2\n",
    "TCGA-05-4244-01\t0_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4249-01\t1_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4250-01\t2_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4382-01\t3_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4384-01\t4_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4389-01\t5_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4390-01\t6_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4395-01\t7_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4396-01\t8_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image only case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.default_config import DataConfig, DataInfo\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(file_path=\"data/raw/images/tcga_fake\", data_type=\"IMG\"),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\", data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Images and omics data\n",
    "If you want to translate between image and another data modality you need to provide the same files as above. For the Annotation files you have two possibilities: (a) you provide one annotation file (as shown above), in this file you match the metadata of the two data modalites, by an shared sample_id / mapping of sample_id and image_path and other metadata. (b) you can have supply an extra annotation file for the images with the attribute `img_anno_file`. If None is given, we will use the shared file. This is only allowed for unpaired translation.\n",
    "So for the unpaired translation the `DataConfig` should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "\n",
    "imgreader = ImageDataReader(config=img_config)\n",
    "imgdata, img_anno = imgreader.read_data(config=img_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgdata.keys())\n",
    "print(f\"Number of images: {len(imgdata['IMG'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unpaired case\n",
    "This case is not implemented in the old version of `autoencodix` and will be added after the other translating features, we still show how the config can look like:\n",
    "```python\n",
    "from autoencodix.configs.default_config import DataConfig, DataInfo\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake.txt\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\"\n",
    "                extra_anno_file=\"path/to/file\"\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\"\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data_clinical_formatted.parquet\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.1 How to use raw data \n",
    "If you don't want to provide files via config, you can create a DataPackage directly in Python. First you need to decide what kind of data you use. We currently support the following cases:\n",
    "- Multi-Bulk (or any other numeric data)\n",
    "- Multi-SingleCell (or standard Single Cell)\n",
    "- Bulk-to-Bulk translation\n",
    "- SingleCell-to-SingleCell translation\n",
    "- Image-Bulk translation or vice versa\n",
    "- SingleCell-Image translation or vice versa\n",
    "\n",
    "With Multi-Bulk (Multi-Numeric) we mean combining different types of  sequencing data e.g. mRNA and ATAC. We define Multi-Single-Cell analogous. \n",
    "Now we show how to prepare the data in Python. While we will perform basic preprocessing like NaN removal, and scaling and filtering (if specified), we expect a certain amount of preprocessing for omics data:\n",
    "**For Bulk**:\n",
    "- TODO\n",
    "- TODO\n",
    "\n",
    "**For Single Cell**\n",
    "- TODO \n",
    "- TODO\n",
    "\n",
    "##### Multi-Bulk / Multi-Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.configs.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "\n",
    "# Create fake methylation data\n",
    "# you would normally load your data here\n",
    "meth_data = pd.DataFrame(\n",
    "    np.random.rand(100, 50),  # 100 samples, 50 features\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"Meth_Feature_{j}\" for j in range(50)],\n",
    ")\n",
    "\n",
    "# Create fake RNA data\n",
    "# you would normally load your data here\n",
    "rna_data = pd.DataFrame(\n",
    "    np.random.rand(100, 100),  # TODO align\n",
    "    index=[f\"Sample_{i}\" for i in range(100)],\n",
    "    columns=[f\"RNA_Feature_{j}\" for j in range(100)],\n",
    ")\n",
    "\n",
    "# Create fake clinical annotations\n",
    "# you would normally load your data here\n",
    "clinical_annotations = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample_ID\": [f\"Sample_{i}\" for i in range(100)],\n",
    "        \"Age\": np.random.randint(20, 80, size=100),\n",
    "        \"Gender\": np.random.choice([\"Male\", \"Female\"], size=100),\n",
    "        \"Disease_Status\": np.random.choice([\"Healthy\", \"Diseased\"], size=100),\n",
    "    }\n",
    ").set_index(\"Sample_ID\")\n",
    "\n",
    "# multi_bulk is a dict with \"name/identifier\" of the dataset as key\n",
    "# the key for annotation needs to be \"paired\" if only one annotation is given, otherwise it has to have the same keys as multi_bulk\n",
    "my_data = DataPackage(\n",
    "    multi_bulk={\"RNA\": rna_data, \"METH\": meth_data},\n",
    "    annotation={\"paired\": clinical_annotations},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pass this data to our Autoencodix. \n",
    "\n",
    "**IMPORTANT**: In you config you need specify the usecase (see code) \n",
    "The preprocessing will be done according to the values in the DefaultConfig. We show how to adjust this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DefaultConfig(data_case=DataCase.MULTI_BULK)\n",
    "van = Vanillix(config=config, data=my_data)\n",
    "# USE ONE OF THESE FOR data_case\n",
    "for case in DataCase:\n",
    "    print(case.name, case.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = van.result.datasets\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Single-Cell case\n",
    "Here you can provide one MuData object an don't need an extra annotation file, because the annotation info is stored in `obs` of the modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mudata\n",
    "\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "# IMPORTANT specify datacase\n",
    "config = DefaultConfig(data_case=DataCase.MULTI_SINGLE_CELL)\n",
    "# Number of samples and features\n",
    "n_samples = 100\n",
    "n_rna_features = 200\n",
    "n_atac_features = 50\n",
    "\n",
    "# Create sparse matrices instead of dense arrays\n",
    "rna_X = sparse.csr_matrix(np.random.rand(n_samples, n_rna_features))\n",
    "atac_X = sparse.csr_matrix(np.random.rand(n_samples, n_atac_features))\n",
    "\n",
    "# Create observation and variable DataFrames\n",
    "obs_df = pd.DataFrame(index=[f\"Sample_{i}\" for i in range(n_samples)])\n",
    "rna_var_df = pd.DataFrame(index=[f\"Gene_{i}\" for i in range(n_rna_features)])\n",
    "atac_var_df = pd.DataFrame(index=[f\"ATAC_Feature_{i}\" for i in range(n_atac_features)])\n",
    "\n",
    "# Try creating AnnData objects with sparse matrices\n",
    "rna_adata = ad.AnnData(X=rna_X, obs=obs_df, var=rna_var_df, dtype=np.float32)\n",
    "\n",
    "atac_adata = ad.AnnData(\n",
    "    X=atac_X,\n",
    "    obs=obs_df,\n",
    "    var=atac_var_df,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "# Create MuData object\n",
    "mdata = mudata.MuData({\"RNA\": rna_adata, \"ATAC\": atac_adata})\n",
    "\n",
    "dp = DataPackage(multi_sc={\"multi_sc\": mdata})\n",
    "# Print the object\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix import Varix\n",
    "\n",
    "van = Varix(data=dp, config=config)\n",
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translation between modalities.\n",
    "If you want to translate between modalties i.e. mRNA to ATAC, you can populate the `from_modality` and `to_modality` attributes of the DataPackage. For the `annotation` attribute you need to add at leas one annotation file for the bulk/numeric case. Details see code:\n",
    "\n",
    "As of March 2025, we've not implemented models that support Translation in the new package, so we only show how to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data.datapackage import DataPackage\n",
    "from autoencodix.configs.default_config import (\n",
    "    DefaultConfig,\n",
    "    DataInfo,\n",
    "    DataConfig,\n",
    "    DataCase,\n",
    ")\n",
    "from autoencodix.vanillix import Vanillix\n",
    "\n",
    "dp = DataPackage(\n",
    "    multi_bulk={\"rna\": rna_data, \"meth\": meth_data},\n",
    "    annotation={\"paired\": clinical_annotations},\n",
    ")\n",
    "data_info = {\n",
    "    \"RNA\": DataInfo(translate_direction=\"from\"),\n",
    "    \"METH\": DataInfo(translate_direction=\"to\"),\n",
    "}\n",
    "config = DefaultConfig(\n",
    "    requires_paired=True,  # we want to have matched samples in this case\n",
    "    data_case=DataCase.BULK_TO_BULK,\n",
    "    data_config=DataConfig(data_info=data_info),\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    van = Vanillix(data=dp, config=config)\n",
    "    van.preprocess()\n",
    "    datasets = van.result.datasets\n",
    "except NotImplementedError as e:\n",
    "    print(f\"Expected error occurred: {e}\")\n",
    "    # Optionally, you can still assign None or some default value\n",
    "    datasets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with Images\n",
    "When you want to use images for our pipelines, it is the easiest to pass the folder and annotations files via config params as shown above. For some usecases, however users want to. Therefore you need create a list of ImgData objects and pass them to the DataPackage.img attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._imgdataclass import ImgData\n",
    "from autoencodix.data.datapackage import DataPackage\n",
    "import numpy as np\n",
    "\n",
    "imgdata = [ImgData(img=np.array(1), sample_id=\"myImg\", annotation=pd.DataFrame())]\n",
    "dp = DataPackage({\"IMG\": imgdata})\n",
    "# in real applications this will be a longer list of images\n",
    "# you probably also would add other data modalites to the datapackge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.3 Working with Processed data\n",
    "If you do all your processing yourself, you can just pass the torch tensor and metadata to our `DatasetContainer` data structure. The  DatasetContainer hold a dataset for each split (train, test, valid). This will skip our internal preprocessing. Here you need to know which Dataset (Pytorch Dataset child), you need for which Autoencodix. For now we only support Varix and Vanillix, which uses the class `NumericDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from autoencodix.data._datasetcontainer import DatasetContainer\n",
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "from autoencodix import Varix\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "container = DatasetContainer()\n",
    "# fill the attributes with your data\n",
    "ds = NumericDataset(\n",
    "    data=torch.tensor(1), config=DefaultConfig(), sample_ids=[], metadata=pd.DataFrame()\n",
    ")\n",
    "container.train = ds\n",
    "container.valid = ds  # your valid data\n",
    "\n",
    "# if you want to run the predict step, you need to also fill the test attribute of\n",
    "container.test = ds  # your test data\n",
    "\n",
    "# now you can just pass the container as user data\n",
    "van = Varix(data=container)\n",
    "# valls var.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add example (see already existing configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 How to add a new architecture\n",
    "### High level workflow\n",
    "To add a new autoencoder architecture, you need to at least code two things:\n",
    "- the model architecture itself in  `src/autoencodix/modeling/` - anlogous to `_varix_architecture.py`\n",
    "- the pipeline itself in `src/autoencodix/` - analgous to `varix.py`\n",
    "Depending on the complexity and data requirements you might also want to provide the following:\n",
    "- a new custom dataset class in `src/autoencodix/data` - analogous to `numeric_dataset.py`\n",
    "- a new custom preprocessor in `src/autoencodix/data` - as in `preprocessor.py`\n",
    "- a new custom trainer in `src/autoencodix/trainers` - as in `_general_trainer.py`\n",
    "  - including a custom predict method of your trainer\n",
    "- a custom loss for your model\n",
    "- a custom visualizer (no example implemented yet)\n",
    "- a custom evaluator for downstream tasks (no example implemented yet)\n",
    "- a custom tuner (not sure if this will be part of the package)\n",
    "### High level structure\n",
    "- Each autoencodix model in our family is based on our base classes in `src/autoencodix/base`. Here we have (often abstract) classes that define the general structure of each step (preprocess, fit, predict, evaluate, visualize) in our pipeline, as well as additional classes e.g. losses.\n",
    "- In these base classes we've implemented shared functionalities, like calling the corresponding trainer, or preprocessor.\n",
    "- The base classes also guide you to the structure of your new class. The methods of the base classes should not be changed. Rather overwrite the method in the implementation of your child class in case you need to make changes.\n",
    "\n",
    "### Must-do files details\n",
    "We'll illustrate this by an example. We want to add the new architecture with the name MySpecial to our package. First we add the actual architecture:\n",
    "- create the file `src/autoencodix/modeling/_myspecialix_architecture.py` (note files that should not be imported at end-user lever have a leading underscore).\n",
    "- for each newly created file, add the classes to the `__init__.py` in the corresponding folder. Example for the pipeline file in  `src/autoencodix`:\n",
    "```python\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "try:\n",
    "    __version__ = version(\"autoencodix\")\n",
    "except PackageNotFoundError:\n",
    "    __version__ = \"unknown\"\n",
    "\n",
    "# Import key classes to make them directly accessible\n",
    "from .vanillix import Vanillix\n",
    "from .varix import Varix\n",
    "from .stackix import Stackix\n",
    "# NEW: -------------------------------------\n",
    "from .MyNewSpecialix imiport MyNewSpecialix\n",
    "# -----------------------------------------\n",
    "\n",
    "__all__ = [\"Vanillix\", \"Varix\", \"Stackix\"] # TODO add \"MyNewSpecialx\"\n",
    "```\n",
    "\n",
    "- create the file `tests/test_modelling/test_myspecialix_architecture`\n",
    "- we write the class itself that might look like:\n",
    "```python\n",
    "from autoencodix.base._base_autoencoder import BaseAutoencoder\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "\n",
    "# needs to inherit from BaseAutoencoder\n",
    "class MySpecialArchitecture(BaseAutoencoder):\n",
    "    \"\"\"\n",
    "    MySpecial implementation accroding to (cite paper, yourself, etc)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.input_dim : int\n",
    "        number of input features\n",
    "    self.config: DefaultConfig\n",
    "        Configuration object containing model architecture parameters\n",
    "    self._encoder: nn.Module\n",
    "        Encoder network of the autoencoder\n",
    "    self._decoder: nn.Module\n",
    "        Decoder network of the autoencoder\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    my_super_special_method():\n",
    "        does cool stuff\n",
    "    _build_network()\n",
    "        Construct the encoder and decoder networks via the LayerFactory\n",
    "    encode(x: torch.Tensor) -> torch.Tensor\n",
    "        Encode the input tensor x\n",
    "    decode(x: torch.Tensor) -> torch.Tensor\n",
    "        Decode the latent tensor x\n",
    "    forward(x: torch.Tensor) -> ModelOutput\n",
    "        Forward pass of the model, fills in the reconstruction and latentspace attributes of ModelOutput class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, config: Optional[Union[None, DefaultConfig]], input_dim: int\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = DefaultConfig()\n",
    "        self._config = config\n",
    "        super().__init__(config, input_dim)\n",
    "        self.input_dim = input_dim # we always base the input dimension (usually number of features in your dataset)\n",
    "\n",
    "        # populate self.encoder and self.decoder\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Construct the encoder and decoder networks.\n",
    "        See your _layer_factory.py file that could help you here.\n",
    "        Also check other implementation to see how to use _layer_factory.py\n",
    "        \"\"\"\n",
    "        self._encoder = TODO\n",
    "        self._decoder = TODO\n",
    "\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encode the input tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Encoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        encoded = self._encoder(x)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode the latent tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Latent tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Decoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        return self._decoder(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> ModelOutput:\n",
    "        \"\"\"\n",
    "        Forward pass of the model, fill\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelOutput\n",
    "            ModelOutput object containing the reconstructed tensor and latent tensor\n",
    "\n",
    "        \"\"\"\n",
    "        latent = self.encode(x)\n",
    "        x_hat = self.decode(z)\n",
    "        # fill model output arcodding to your needs (we need reconstruction and a latentspace, see ModelOuput class for required output)\n",
    "        return ModelOutput(\n",
    "            reconstruction=x_hat,\n",
    "            latentspace=latent\n",
    "            latent_mean=None,\n",
    "            latent_logvar=None,\n",
    "            additional_info=None,\n",
    "        )\n",
    "\n",
    "```\n",
    "- adjust the `__init__.py` in `src/autoencodix/modelling` to import `MySpecialArchitecture\n",
    "- next we write tests for the newly created file in the test file\n",
    "- lastly, we need to create the pipeline file:\n",
    "  - create `src/autoencodix/myspecialix.py`\n",
    "  - create `tests/test_myspecialix.py`\n",
    "- the `myspecialix.py` might look like this\n",
    "```python\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "class MySpecialix(BasePipeline): # must inherit from BasePipeline\n",
    "    \"\"\"\n",
    "    MySpecialix specific version of the BasePipeline class.\n",
    "    Inherits preprocess, fit, predict, evaluate, and visualize methods from BasePipeline.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : Optional[Union[DatasetContainer, DataPackage]]\n",
    "        Input data from the user\n",
    "    config : Optional[Union[None, DefaultConfig]]\n",
    "        Configuration object containing customizations for the pipeline\n",
    "    _preprocessor_type : BasePreprocessor\n",
    "        Preprocessor object to preprocess the input data (custom for Vanillix)\n",
    "    _visualizer_type : Visualizer\n",
    "        Visualizer object to visualize the model output (custom for Vanillix)\n",
    "    _trainer_type : BaseTrainer\n",
    "        Trainer object that trains the model (custom for Vanillix)\n",
    "    _evaluator : Evaluator\n",
    "        Evaluator object that evaluates the model performance or downstream tasks (custom for Vanillix)\n",
    "    result : Result\n",
    "        Result object to store the pipeline results\n",
    "    _datasets : Optional[DatasetContainer]\n",
    "        Container for train, validation, and test datasets (preprocessed)\n",
    "    data_splitter : DataSplitter\n",
    "        DataSplitter object to split the data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[np.ndarray, AnnData, pd.DataFrame],\n",
    "        # this can be also a custom Type like MySpecialixDataset\n",
    "        dataset_type: Type[BaseDataset] = NumericDataset,\n",
    "        # This will be the Type MySpecialixArchitecture that we created before\n",
    "        model_type: Type[BaseAutoencoder] = MySpecialixArchitecture,\n",
    "        # This can be a custom Loss class, or an exisiting one see _losses.py\n",
    "        loss_type: Type[BaseLoss] = VanillixLoss,\n",
    "        preprocessor: Optional[Preprocessor] = None,\n",
    "        visualizer: Optional[BaseVisualizer] = None,\n",
    "        evaluator: Optional[Evaluator] = None,\n",
    "        result: Optional[Result] = None,\n",
    "        datasplitter_type: Type[DataSplitter] = DataSplitter,\n",
    "        custom_splits: Optional[Dict[str, np.ndarray]] = None,\n",
    "        config: Optional[DefaultConfig] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize MySpecialix pipeline with customizable components.\n",
    "\n",
    "        Some components are passed as types rather than instances because they require\n",
    "        data that is only available after preprocessing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "            Input data to be processed\n",
    "        trainer_type : Type[BaseTrainer]\n",
    "            Type of trainer to be instantiated during fit step, default is GeneralTrainer\n",
    "        dataset_type : Type[BaseDataset]\n",
    "            Type of dataset to be instantiated post-preprocessing, default is NumericDataset\n",
    "        loss_type : Type[BaseLoss], which loss to use for Vanillix, default is VanillaAutoencoderLoss\n",
    "        preprocessor : Optional[Preprocessor]\n",
    "            For data preprocessing, default creates new Preprocessor\n",
    "        visualizer : Optional[Visualizer]\n",
    "            For result visualization, default creates new Visualizer\n",
    "        evaluator : Optional[Evaluator]\n",
    "            For model evaluation, default creates new Evaluator\n",
    "        result : Optional[Result]\n",
    "            Container for pipeline results, default creates new Result\n",
    "        datasplitter_type : Type[DataSplitter], optional\n",
    "            Type of splitter to be instantiated during preprocessing, default is DataSplitter\n",
    "        custom_splits : Optional[Dict[str, np.ndarray]]\n",
    "            Custom train/valid/test split indices\n",
    "        config : Optional[DefaultConfig]\n",
    "            Configuration for all pipeline components\n",
    "        \"\"\"\n",
    "        # BEFORE CALLING SUPER DEFINE WHICH CONFIG CLASS IS THE FALLBACK\n",
    "        # IF YOU DON'T DEFINE THE ATTRIBUTE _default_config here, you get a ValueError in DefaultConfig()\n",
    "        self._default_config = DefaultConfig()\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            dataset_type=dataset_type,\n",
    "            trainer_type=trainer_type,\n",
    "            model_type=model_type,\n",
    "            loss_type=loss_type,\n",
    "            preprocessor=preprocessor or Preprocessor(),\n",
    "            visualizer=visualizer or Visualizer(),\n",
    "            evaluator=evaluator or Evaluator(),\n",
    "            result=result or Result(),\n",
    "            datasplitter_type=datasplitter_type,\n",
    "            config=config or DefaultConfig(),\n",
    "            custom_split=custom_splits,\n",
    "        )\n",
    "\n",
    "```\n",
    "##### More explaination to the passing of Types instead of classes:\n",
    "Most functionality of the pipeline comes from the BasePipeline. To make the methods custom to our specific architecture that we use in our `MySpecial` pipeline, we need to pass our specializes subclasses. Since we don't have all required parameters for this subclasses when calling the init method of the parent class, we pass only the type of the subclasses. These types need to be childs of the corresponding base class. Inside the BasePipeline we instantiate the specific classes with the required paramters as soon as we have them\n",
    "### Optional files details\n",
    "The optional files work from the same principle as the mandatory files, so we can always create a special class based on the baseclass and then we pass the type of our special class to our MySpecialix Pipeline e.g MySpecialTrainer n the init mehtod of MySpecialix (same as we did with MySpecialArchitecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- show how to update and work with the config object (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANDBOX \n",
    "testing Varix and losses, especially sub_losses in result_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tests after pre-postsplit refactor\n",
    "\n",
    "- same modality\n",
    "    - bulkconfig (multi_bulk):\n",
    "        - technical: works\n",
    "        - biological: TODO\n",
    "    - scconfig (multi_sc)\n",
    "        - technical: workds\n",
    "        - biological: TODO\n",
    "\n",
    "- paired:\n",
    "    - bulk-bulk:\n",
    "        -technical: workds\n",
    "        -biological: TODO\n",
    "    - sc-sc:\n",
    "        -TODO\n",
    "    - IMG-IMG:\n",
    "        -TODO\n",
    "    - BULK-IMG:\n",
    "        -TODO\n",
    "    - SC-IMG:\n",
    "        -TODO\n",
    "\n",
    "- unpaired\n",
    "    - bulk-bulk:\n",
    "        -technical: workds\n",
    "        -biological: TODO\n",
    "    - sc-sc:\n",
    "        -TODO\n",
    "    - IMG-IMG:\n",
    "        -TODO\n",
    "    - BULK-IMG:\n",
    "        -TODO\n",
    "    - SC-IMG:\n",
    "        -TODO\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### config paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stackix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "from autoencodix.configs import StackixConfig\n",
    "\n",
    "stackix = acx.Stackix(\n",
    "    data=raw_bulk,\n",
    "    config=StackixConfig(\n",
    "        data_case=DataCase.MULTI_BULK,\n",
    "        latent_dim=16,\n",
    "        epochs=1,\n",
    "        batch_size=32,\n",
    "        learning_rate=0.001,\n",
    "    ),\n",
    ")\n",
    "stackix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.result.final_reconstruction.datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_path = \"configs/largebulk.yaml\"\n",
    "scpath = \"configs/largesc.yaml\"\n",
    "tranpath = \"configs/sc_img_tran_config.yaml\"\n",
    "unpaired_path = \"configs/bulk_img_up.yaml\"\n",
    "bulk_bulk_path = \"configs/bulk_bulk_tran_config.yaml\"\n",
    "sc_sc_path = \"configs/sc_sc_tran_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_config = DefaultConfig.model_validate(yaml.safe_load(Path(bulk_path).read_text()))\n",
    "scconfig = DefaultConfig.model_validate(yaml.safe_load(Path(scpath).read_text()))\n",
    "tranconfig = DefaultConfig.model_validate(yaml.safe_load(Path(tranpath).read_text()))\n",
    "unpaired_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(unpaired_path).read_text())\n",
    ")\n",
    "bulk_bulk_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(bulk_bulk_path).read_text())\n",
    ")\n",
    "sc_sc_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(sc_sc_path).read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test multi_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scconfig.skip_preprocessing = True\n",
    "van = acx.Vanillix(config=scconfig)\n",
    "scconfig.scaling = \"MINMAX\"\n",
    "van.preprocess()\n",
    "van.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test sc-sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van = acx.Vanillix(config=sc_sc_config)\n",
    "van.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from pympler import asizeof\n",
    "\n",
    "# Create sparse matrix\n",
    "sparse_mat = sp.random(10000, 5000, density=0.01, format=\"csr\")\n",
    "\n",
    "# Single row (what you're doing now)\n",
    "single_sparse = sparse_mat[0]\n",
    "single_dense = single_sparse.toarray()\n",
    "print(f\"Single sparse row: {asizeof.asizeof(single_sparse)} bytes\")\n",
    "print(f\"Single dense row: {asizeof.asizeof(single_dense)} bytes\")\n",
    "\n",
    "# Batch of 128 rows\n",
    "batch_sparse = sparse_mat[0:128]\n",
    "batch_dense = batch_sparse.toarray()\n",
    "print(f\"\\nBatch sparse (128 rows): {asizeof.asizeof(batch_sparse)} bytes\")\n",
    "print(f\"Batch dense (128 rows): {asizeof.asizeof(batch_dense)} bytes\")\n",
    "print(f\"Sparse per row: {asizeof.asizeof(batch_sparse) / 128:.1f} bytes\")\n",
    "print(f\"Dense per row: {asizeof.asizeof(batch_dense) / 128:.1f} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid confgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = os.path.join(\"configs/invalid\")\n",
    "invalid_configs = [\n",
    "    \"invalid_modalities_config.yaml\",\n",
    "    \"invalid_one_config.yaml\",\n",
    "    \"invalid_sc_bulk_config.yaml\",\n",
    "    \"invalid_three_config.yaml\",\n",
    "]\n",
    "invalid_config_objects = []\n",
    "for i, c in enumerate(invalid_configs):\n",
    "    print(c)\n",
    "    try:\n",
    "        data_info = DefaultConfig.model_validate(\n",
    "            yaml.safe_load(Path(os.path.join(base_path, c)).read_text())\n",
    "        )\n",
    "        invalid_config_objects.append(data_info)\n",
    "    except Exception as e:\n",
    "        print(invalid_configs[i])\n",
    "        print(e)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = StackixConfig(data_case=DataCase.MULTI_SINGLE_CELL, epochs=1)\n",
    "stackix = acx.Stackix(data=raw_sc, config=config)\n",
    "stackix.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_config.data_info[\"multi_sc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = stackix._datasets.train.datasets.keys()\n",
    "ds\n",
    "# ds.datasets_dict[\"transcriptomics\"].data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.sample_latent_space(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = stackix._trainer.testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.feature_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = stackix._datasets.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.result.datasets.test.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.k_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackix.result.final_reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.configs.stackix_config import StackixConfig\n",
    "from autoencodix.configs.vanillix_config import VanillixConfig\n",
    "from autoencodix.configs.ontix_config import OntixConfig\n",
    "from autoencodix.configs.xmodalix_config import XModalixConfig\n",
    "from autoencodix.configs.varix_config import VarixConfig\n",
    "from autoencodix.configs.default_config import DefaultConfig\n",
    "\n",
    "default_config = DefaultConfig()\n",
    "stackix_config = StackixConfig()\n",
    "ontix_config = OntixConfig()\n",
    "xmodalix_config = XModalixConfig()\n",
    "varix_config = VarixConfig()\n",
    "vanillix_config = VanillixConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencodix as acx\n",
    "\n",
    "van = acx.Vanillix()\n",
    "var = acx.Varix()\n",
    "stackix = acx.Stackix()\n",
    "xmodalix = acx.XModalix()\n",
    "ontix = acx.Ontix(ontologies=(None, None))\n",
    "print(f\" type of van config: {type(van.config)}\")\n",
    "print(f\" type of var config: {type(var.config)}\")\n",
    "print(f\" type of stackix config: {type(stackix.config)}\")\n",
    "print(f\" type of xmodalix config: {type(xmodalix.config)}\")\n",
    "print(f\" type of ontix config: {type(ontix.config)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "van = acx.Vanillix(config=DefaultConfig())\n",
    "var = acx.Varix(config=DefaultConfig())\n",
    "stackix = acx.Stackix(config=StackixConfig())\n",
    "xmodalix = acx.XModalix(config=DefaultConfig())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ontix = acx.Ontix(ontologies=(None, None), config=DefaultConfig())\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Memory Save Saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "\n",
    "for attr, value in van.__dict__.items():\n",
    "    print(attr)\n",
    "    print(attr, asizeof.asizeof(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "to_clean_result = copy.deepcopy(van.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import fields, is_dataclass, MISSING\n",
    "\n",
    "\n",
    "def reset_to_defaults(obj):\n",
    "    if not is_dataclass(obj):\n",
    "        raise ValueError(\"Object must be a dataclass\")\n",
    "\n",
    "    for f in fields(obj):\n",
    "        if f.name == \"model\" or f.name == \"adata_latent\":\n",
    "            print(f)\n",
    "            continue\n",
    "        if f.default_factory is not MISSING:\n",
    "            setattr(obj, f.name, f.default_factory())\n",
    "        elif f.default is not MISSING:\n",
    "            setattr(obj, f.name, f.default)\n",
    "        else:\n",
    "            setattr(obj, f.name, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_to_defaults(to_clean_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean_result.adata_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.adata_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencodix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
