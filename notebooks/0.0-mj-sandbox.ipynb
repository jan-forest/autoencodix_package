{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODIX PACKAGE HANDBOOK\n",
    "This notebook demonstrates the usage of the autoencodix package.\n",
    "For now it serves as an internal guideline with the goal to:\n",
    "- test the package from a user perspective\n",
    "- serve as a first draft of user documentation\n",
    "- serve a developer guideline \n",
    "  - developer guide will be derrived from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Generate mock data\n",
    "When  development proceeds this section should be used to  show how to use different datatypes\n",
    "for now we only use a mock numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_data = np.random.rand(100, 10)\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 General Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autoencodix.data.preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# imports\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01macx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefault_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultConfig\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Import key classes to make them directly accessible\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvanillix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Vanillix\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvarix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Varix\n\u001b[1;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVanillix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVarix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/varix.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_datasplitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataSplitter\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_numeric_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumericDataset\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Preprocessor\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Evaluator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautoencodix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_varix_architecture\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VarixArchitecture\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autoencodix.data.preprocessor'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import DefaultConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class Preprocessor with abstract method preprocess",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### --------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO user prepares data or config\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m### INITIALIZATION ### --------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# data should be a numpy array, pandas dataframe or AnnData object\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# possible to pass a custom Config object\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m van \u001b[38;5;241m=\u001b[39m \u001b[43macx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVanillix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m### DATA PROCESSING ### --------------------------\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# job of old make data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# (important for training with dataloader)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# possible to pass a custom Config object, or keyword arguments\u001b[39;00m\n\u001b[1;32m     16\u001b[0m van\u001b[38;5;241m.\u001b[39mpreprocess()\n",
      "File \u001b[0;32m~/development/autoencodix_package/src/autoencodix/vanillix.py:102\u001b[0m, in \u001b[0;36mVanillix.__init__\u001b[0;34m(self, data, trainer_type, dataset_type, model_type, loss_type, preprocessor, visualizer, evaluator, result, datasplitter_type, custom_splits, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     data: Union[np\u001b[38;5;241m.\u001b[39mndarray, AnnData, pd\u001b[38;5;241m.\u001b[39mDataFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     config: Optional[DefaultConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize Vanillix pipeline with customizable components.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Some components are passed as types rather than instances because they require\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m        Configuration for all pipeline components\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     97\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     98\u001b[0m         dataset_type\u001b[38;5;241m=\u001b[39mdataset_type,\n\u001b[1;32m     99\u001b[0m         trainer_type\u001b[38;5;241m=\u001b[39mtrainer_type,\n\u001b[1;32m    100\u001b[0m         model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[1;32m    101\u001b[0m         loss_type\u001b[38;5;241m=\u001b[39mloss_type,\n\u001b[0;32m--> 102\u001b[0m         preprocessor\u001b[38;5;241m=\u001b[39mpreprocessor \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mPreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    103\u001b[0m         visualizer\u001b[38;5;241m=\u001b[39mvisualizer \u001b[38;5;129;01mor\u001b[39;00m Visualizer(),\n\u001b[1;32m    104\u001b[0m         evaluator\u001b[38;5;241m=\u001b[39mevaluator \u001b[38;5;129;01mor\u001b[39;00m Evaluator(),\n\u001b[1;32m    105\u001b[0m         result\u001b[38;5;241m=\u001b[39mresult \u001b[38;5;129;01mor\u001b[39;00m Result(),\n\u001b[1;32m    106\u001b[0m         datasplitter_type\u001b[38;5;241m=\u001b[39mdatasplitter_type,\n\u001b[1;32m    107\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig \u001b[38;5;129;01mor\u001b[39;00m DefaultConfig(),\n\u001b[1;32m    108\u001b[0m         custom_split\u001b[38;5;241m=\u001b[39mcustom_splits,\n\u001b[1;32m    109\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class Preprocessor with abstract method preprocess"
     ]
    }
   ],
   "source": [
    "#### --------------------------------------------\n",
    "# TODO user prepares data or config\n",
    "### INITIALIZATION ### --------------------------\n",
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "van = acx.Vanillix(data=sample_data)\n",
    "# ------------------------------------------------\n",
    "### DATA PROCESSING ### --------------------------\n",
    "# job of old make data\n",
    "# populates self._features attrbute with torch tensor\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# ------------------------------------------------\n",
    "### MODEL TRAINING ### --------------------------\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (model, losses, etc)\n",
    "van.fit()\n",
    "# ------------------------------------------------\n",
    "### PREDICTION ### -------------------------------\n",
    "# job of old make predict\n",
    "# if no data is passed, used the test split from preprocessing\n",
    "# otherwise, uses the data passed, and preprocesses it\n",
    "# updates self.result attribute with predictions (latent space, reconstructions, etc)\n",
    "van.predict()\n",
    "# ------------------------------------------------\n",
    "### EVALUATION ### -------------------------------\n",
    "# job of old make ml_task\n",
    "# populates self.result attribute with ml task results\n",
    "van.evaluate()  # not implemented yet\n",
    "# ------------------------------------------------\n",
    "### VISUALIZATION ### ---------------------------\n",
    "# job of old make visualize\n",
    "# populates self.result attribute with visualizations\n",
    "van.visualize()\n",
    "# show visualizations for notebook use\n",
    "van.show_result()\n",
    "# --------------------------\n",
    "# --------------------------\n",
    "# run all steps in the pipeline\n",
    "result_object = van.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 10) (10, 10) (20, 10)\n"
     ]
    }
   ],
   "source": [
    "recons = result_object.reconstructions.get(split=\"train\", epoch=2)\n",
    "recons_val = result_object.reconstructions.get(split=\"valid\", epoch=2)\n",
    "recons_test = result_object.reconstructions.get(split=\"test\", epoch=-1)\n",
    "print(recons.shape, recons_val.shape, recons_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 16) (10, 16) (20, 16)\n"
     ]
    }
   ],
   "source": [
    "latents = result_object.latentspaces.get(split=\"train\", epoch=2)\n",
    "latents_val = result_object.latentspaces.get(split=\"valid\", epoch=2)\n",
    "latents_test = result_object.latentspaces.get(split=\"test\", epoch=-1)\n",
    "print(latents.shape, latents_val.shape, latents_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a custom train, test, valid split\n",
    "When you pass the data to the pipeline, autoencodix, internally splits the data for you based on the train,test, valid ratios provided in the config (defaults are 70%/10%/20% train/valid/test).\n",
    "You can either pass custom ratios (see next section) or provide the indices directly as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.367237627506256\n",
      "Epoch: 1, Loss: 2.1364158391952515\n",
      "Epoch: 2, Loss: 2.140314042568207\n"
     ]
    }
   ],
   "source": [
    "sample_data = np.random.rand(100, 10)\n",
    "custom_train_indices = np.arange(75)  # we won't allow overlap between splits\n",
    "custom_valid_indices = np.arange(75, 80)\n",
    "custom_test_indices = np.arange(80, 100)\n",
    "\n",
    "# the custom split needs to be a dictionary with keys \"train\", \"valid\", and \"test\" and indices of the samples to be included in each split as numpy arrays\n",
    "custom_split = {\n",
    "    \"train\": custom_train_indices,\n",
    "    \"valid\": custom_valid_indices,\n",
    "    \"test\": custom_test_indices,\n",
    "}\n",
    "van = acx.Vanillix(data=sample_data, custom_splits=custom_split)\n",
    "van.preprocess()\n",
    "van.fit(epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass empty splits, but depending on how you'll use the autoencodix pipeline, this will throw an error at some point. So it is possible to call `fit` with only training data, but if you want to call `predict` and don't provide new data, this won't work without a data in the test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predict with new data\n",
    "The standard case is to train the model with the train data and then predict with the test split.\n",
    "However, it is possible to pass new data to the predict method to perform inference on this data with the already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "new_unseen_data = np.random.rand(10, 10)\n",
    "van.predict(data=new_unseen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the result of the pipeline\n",
    "Each step in the pipeline writes its results in the result object of the Vanillix instance.\n",
    "In this section we explore how to access and make sense of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Object Public Attributes:\n",
      "------------------------------\n",
      "latentspaces: TrainingDynamics object\n",
      "reconstructions: TrainingDynamics object\n",
      "mus: TrainingDynamics object\n",
      "sigmas: TrainingDynamics object\n",
      "losses: TrainingDynamics object\n",
      "preprocessed_data: Tensor of shape (100, 10)\n",
      "model: _FabricModule\n",
      "model_checkpoints: TrainingDynamics object\n",
      "datasets: DatasetContainer(train=<autoencodix.data._numeric_dataset.NumericDataset object at 0x1053f1e70>, valid=<autoencodix.data._numeric_dataset.NumericDataset object at 0x10626cd90>, test=<autoencodix.data._numeric_dataset.NumericDataset object at 0x10626ce20>)\n"
     ]
    }
   ],
   "source": [
    "result = van.result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TrainingDynamics object in result\n",
    "The training dynamics object has the followinf form:\n",
    "<epoch><split><data>\n",
    "So if you want to access the train loss for the 5th epoch, you would:\n",
    "`result.lossss.get(epoch=5, split=\"train\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134380141894022\n",
      "[0.27492604 0.24243712 0.23720634]\n",
      "{0: {'train': array(0.78907921), 'valid': array(0.27492604)}, 1: {'train': array(0.71213861), 'valid': array(0.24243712)}, 2: {'train': array(0.71343801), 'valid': array(0.23720634)}}\n"
     ]
    }
   ],
   "source": [
    "loss_train_ep2 = result.losses.get(epoch=2, split=\"train\")\n",
    "print(loss_train_ep2)\n",
    "valid_loss = result.losses.get(split=\"valid\")\n",
    "print(valid_loss)\n",
    "print(result.losses.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this schema works for every TrainingDynamics instance in the results object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Pipeline usage with custom parameters\n",
    "Here we show how to customize the above shown pipeline with a user config or with keyword arguments.\n",
    "In future iterations we want to allow to read a config from a file, this will be also demonstrated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 1.9614873230457306\n",
      "Epoch: 1, Loss: 1.382771223783493\n",
      "Epoch: 2, Loss: 0.977891355752945\n",
      "Epoch: 3, Loss: 0.6883653551340103\n",
      "Epoch: 4, Loss: 0.5179779827594757\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 8780462592.772186\n",
      "Epoch: 1, Loss: 1348435297.7003174\n",
      "Epoch: 2, Loss: 5917.90837097168\n",
      "Epoch: 3, Loss: 10487.504081726074\n",
      "Epoch: 4, Loss: 3092.8131675720215\n"
     ]
    }
   ],
   "source": [
    "# Use Vanillix Pipeline interface\n",
    "# needs to be initialized with data\n",
    "# data should be a numpy array, pandas dataframe or AnnData object\n",
    "# possible to pass a custom Config object\n",
    "van = acx.Vanillix(data=sample_data)\n",
    "# job of old make data\n",
    "# populates self._features attrbute with torch tensor\n",
    "# populates self._datasets attribute with torch dataset\n",
    "# (important for training with dataloader)\n",
    "# possible to pass a custom Config object, or keyword arguments\n",
    "van.preprocess()\n",
    "# job of old make model\n",
    "# calls self.Trainer class to init and train model\n",
    "# populates self._model attribute with trained model\n",
    "# populates self.result attribute with training results (losses, etc)\n",
    "# van.fit()\n",
    "\"\"\" \n",
    "Each step can be run separately, with custom parameters, these parameters\n",
    "can be passed as keyword arguments, or as a Config object\n",
    "\"\"\"\n",
    "van.fit(learning_rate=0.01, batch_size=32, epochs=5)  # or like this:\n",
    "my_config = DefaultConfig(learning_rate=130.0, batch_size=32, epochs=5)\n",
    "van.fit(config=my_config)  # config has to be an keyword argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.1  How to relevant keyword arguments for pipeline methods\n",
    "It can be hard to know what keyword arguments are valid for each step,\n",
    "so we show:\n",
    "- how to get a list of allowed keyword arguments\n",
    "- what happens if you pass non-allowed keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size',\n",
      " 'checkpoint_interval',\n",
      " 'config',\n",
      " 'device',\n",
      " 'epochs',\n",
      " 'global_seed',\n",
      " 'gpu_strategy',\n",
      " 'learning_rate',\n",
      " 'n_gpus',\n",
      " 'n_workers',\n",
      " 'reconstruction_loss',\n",
      " 'reproducible',\n",
      " 'weight_decay'}\n"
     ]
    }
   ],
   "source": [
    "# for each config method, we can call a valid_params method\n",
    "van = acx.Vanillix(data=sample_data)\n",
    "fit_params = (\n",
    "    van.fit.valid_params\n",
    ")  # returns a set of keyword arguments that are actually used in the fit method\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get even more verbose info about the keyword args, you can run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Keyword Arguments:\n",
      "--------------------------------------------------\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "# when you want to have more info about the params, you can get type hints from the config object\n",
    "my_config = DefaultConfig()\n",
    "conig_values = my_config.get_params()\n",
    "my_config.print_schema(filter_params=fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass not supported parameters you get a warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: The following parameters are not valid for fit:\n",
      "Invalid parameters: epochds\n",
      "Valid parameters are: batch_size, checkpoint_interval, config, device, epochs, global_seed, gpu_strategy, learning_rate, n_gpus, n_workers, reconstruction_loss, reproducible, weight_decay\n",
      "cpu not relevant here\n",
      "Epoch: 0, Loss: 2.2837421894073486\n",
      "Epoch: 1, Loss: 2.2954598665237427\n",
      "Epoch: 2, Loss: 2.3972206711769104\n"
     ]
    }
   ],
   "source": [
    "# if you use an unsupported keyword argument, you will get a warning\n",
    "# as you see the default value from the DefaultConfig is not overwritten and the training will take 100 epochs (not 10)\n",
    "van.preprocess()\n",
    "van.fit(epochds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2 How to get information about the default config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DefaultConfig Configuration Parameters:\n",
      "--------------------------------------------------\n",
      "\n",
      "latent_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 16\n",
      "  Description: Dimension of the latent space\n",
      "\n",
      "n_layers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of layers in encoder/decoder\n",
      "\n",
      "enc_factor:\n",
      "  Type: <class 'int'>\n",
      "  Default: 4\n",
      "  Description: Scaling factor for encoder dimensions\n",
      "\n",
      "input_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 10000\n",
      "  Description: Input dimension\n",
      "\n",
      "drop_p:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Dropout probability\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "default_vae_loss:\n",
      "  Type: typing.Literal['kl']\n",
      "  Default: kl\n",
      "  Description: Type of VAE loss\n",
      "\n",
      "min_samples_per_split:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Minimum number of samples per split\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "float_precision:\n",
      "  Type: typing.Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16']\n",
      "  Default: 32\n",
      "  Description: Floating point precision\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "train_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.7\n",
      "  Description: Ratio of data for training\n",
      "\n",
      "test_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.2\n",
      "  Description: Ratio of data for testing\n",
      "\n",
      "valid_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Ratio of data for validation\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "# if you want to see what config parameters are used in the default config you can do it like:\n",
    "default_config = DefaultConfig()\n",
    "default_config.print_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02.3 Documentation Config class\n",
    "You can update the config with your own values by:\n",
    "- passing arguments as:\n",
    "    - dict\n",
    "    - single arguments\n",
    "- passing a file (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "\n",
    "# METHOD 1: override the default config with a dictionary\n",
    "my_args = {\"learning_rate\": 0.0234, \"batch_size\": 13, \"epochs\": 12}\n",
    "my_config = DefaultConfig(**my_args)\n",
    "# METHOD 2: override signle parameters\n",
    "my_new_conig = DefaultConfig(latent_dim=23, n_gpus=13)\n",
    "\n",
    "# METHOD 3: from a file: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Use the Varix model\n",
    "Now we show how easy it is to use a variational autoencoder instead of a vanilla version."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,


    
  
    
    
    
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewald/Github/autoencodix_package/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "[10, 16, 16, 16, 16]\n",
      "Epoch: 0, Loss: 2.198316216468811\n",
      "Epoch: 1, Loss: 1.859285593032837\n",
      "Epoch: 2, Loss: 1.8191585540771484\n",
      "\n",
      "Warning: The following parameters are not valid for predict:\n",
      "Invalid parameters: data\n",
      "Valid parameters are: config\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import autoencodix as acx\n",
    "import numpy as np\n",
    "\n",
    "sample_data = np.random.rand(100, 10)\n",
    "my_config = DefaultConfig(learning_rate=0.001, epochs=3, checkpoint_interval=1)\n",
    "varix = acx.Varix(preprocessed_data=sample_data, config=my_config)\n",
    "result = varix.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine Variational result\n",
    "Here, we have more info in our results object than in the Vanillix case. We have the learned paramters mu and logvar of the normal distirbution, in addition to the losses and reconstructions. We provide also the sampled latentspaces at each epoch and split.\n",
    "\n",
    "You can resample new latenspaces (shown in next section)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 16)\n"
     ]
    }
   ],
   "source": [
    "# we did not train for the test split, so we don't need to pass an epoch\n",
    "# technically the epoch is -1\n",
    "mu_test_ep_last = result.latentspaces.get(split=\"test\")\n",
    "print(mu_test_ep_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.latentspaces.get(split=\"train\", epoch=2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different loss types\n",
    "For our variation autoencoder, the total loss consists of a reconstruction loss and a distribution loss i.e. kl-divergence. To investigate these losses, the result_obj has the attribute `sub_losses`. This is a `LossRegistry` withe the name of the loss as key and the value is of class `TrainingDynamics` and can be accessed as shown for the Vanillix part"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: dict_keys(['recon_loss', 'var_loss'])\n",
      "[0.72250668 0.60946602 0.59697612]\n"
     ]
    }
   ],
   "source": [
    "sub_losses = result.sub_losses\n",
    "print(f\"keys: {sub_losses.keys()}\")\n",
    "recon_dyn = sub_losses.get(key=\"recon_loss\")\n",
    "print(recon_dyn.get(split=\"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample new latentspaces\n",
    "You might want to use the trained model and the fitted parameters mu, and logvar to sample latentspaces. Therefore, the Varix pipeline has the additional method `sample_latent_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4227, -1.1264, -0.5146, -0.6423,  1.3555,  0.1267,  1.1256, -0.8374,\n",
      "          1.2268, -1.7507,  0.9605, -0.4691,  0.9137, -0.8082, -0.5185, -0.1135],\n",
      "        [ 0.0871, -0.7650, -0.7087,  1.9782,  0.5053,  0.0163,  0.5845, -0.4165,\n",
      "          0.2073,  1.6614, -0.8132,  0.6487, -1.5413, -0.4115,  0.0680,  0.1220],\n",
      "        [ 0.5332,  0.1249,  1.5426,  1.3922,  0.3982,  0.5452,  0.5251, -0.1709,\n",
      "          0.2392, -0.6901,  0.6993, -2.4067,  0.7687,  0.4694, -1.3835, -1.3028],\n",
      "        [ 0.4925,  0.2083, -0.3846,  0.7595, -0.3062, -0.2996, -0.4743,  1.3784,\n",
      "          1.0943, -0.0518, -0.3465, -0.3751,  0.3677,  0.3754, -0.2108, -0.4754],\n",
      "        [-0.1330,  1.1649,  0.2671,  0.2378, -3.0322, -1.7903, -0.1169,  1.0738,\n",
      "         -0.9661,  0.0313,  0.2592, -1.3385,  0.7877, -0.0342,  1.4808,  2.4948]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "sampled = varix.sample_latent_space()\n",
    "\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3581,  0.8946,  2.3437, -1.0793,  1.5991, -0.6819,  1.3511,  0.7896,\n",
      "         -0.6627,  1.4723,  1.3740, -0.8405, -0.3541, -0.3976,  1.8037, -0.3309],\n",
      "        [-2.7742,  1.3001, -0.7447, -1.5788, -1.3535,  0.3174, -0.5517,  0.9802,\n",
      "         -1.0824,  1.4315, -0.8219, -1.6757,  0.4232, -1.0295, -1.2279,  0.2959],\n",
      "        [-0.5726,  1.2144,  1.3754, -0.1848,  1.2447, -0.2668, -1.7038,  1.4772,\n",
      "          0.6938,  0.8111,  0.5638, -1.3457,  1.3015, -2.0530, -1.4406, -0.6207],\n",
      "        [-0.5844,  1.0119,  1.3542,  0.8185,  0.4677,  0.6580, -0.4376, -1.5302,\n",
      "          0.3264,  0.5532,  1.9664, -1.2441,  1.4664, -1.4824,  1.2571, -1.7927],\n",
      "        [ 1.2330, -0.1874, -0.8378,  1.5088, -0.8935, -0.0678, -0.0589, -0.2272,\n",
      "          0.4520, -1.1687,  0.4746,  0.1345, -0.5463, -0.4620,  0.9897, -0.3327]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# you can also select a specific epoch and split to sample from (default is last epoch and test split)\n",
    "sampled = varix.sample_latent_space(epoch=2, split=\"valid\")\n",
    "print(sampled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8121, -0.2599, -1.1656],\n",
      "        [-1.5269,  0.5212, -0.3416],\n",
      "        [ 1.1872,  1.8373,  0.4524]], device='mps:0')\n",
      "tensor([[ 2.3787,  0.1305, -0.7975],\n",
      "        [-0.3502, -0.2842,  1.0856],\n",
      "        [-2.3673,  1.2124,  1.5476]], device='mps:0')\n",
      "tensor([[ 0.0609,  2.3645,  0.2055],\n",
      "        [-0.3573, -1.5928,  0.5545],\n",
      "        [-2.5494, -0.6906, -0.8733]], device='mps:0')\n",
      "tensor([[ 0.9513,  1.5320,  1.5767],\n",
      "        [ 0.4684, -1.0381,  0.9011],\n",
      "        [-1.0837,  1.9147,  0.4768]], device='mps:0')\n",
      "tensor([[-0.0046, -1.3439, -0.2800],\n",
      "        [ 1.0443, -0.2889, -0.1052],\n",
      "        [ 0.5079,  1.7101,  0.0815]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# or sample multiple times\n",
    "for _ in range(5):\n",
    "    sampled = varix.sample_latent_space()\n",
    "    print(sampled[:3, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 How to work with custom omics data\n",
    "In the above steps we showed how to use `Autoencodix` with mock data. Nowe we demonstrate how to use real-world data. We'll cover:\n",
    "1. combining multi-omics data from bulk sequencing (e.g. mRNA and methylation)\n",
    "2. combining multi-omics data from single cell sequencing\n",
    "3. \"Translating\" between multi-omics data e.g. scRNA <-> scATAC, or bulkmRNA <-> bulkmiRNA\n",
    "4. Working with image data\n",
    "5. \"translating\" between data-modalities\n",
    "  - one bulk-omics modality to another\n",
    "  - omics to image an vice versa\n",
    "\n",
    "### 04.1 Combining mulit-omics data from bulk-sequencing\n",
    "First we need to prepare our config object. We can (a) directly provide an object in python, or (b) provide an YAML file. We show both\n",
    "\n",
    "#### YAML config\n",
    "Assume we have the file in `./config.yaml`.\n",
    "We can keep the yaml file structure to define our input data like:\n",
    "```yaml\n",
    "data_config: # has to be named data_config\n",
    "  data_info: # has to be named data_infor\n",
    "   RNA: # name can be chosen by user\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   METHYLATION: # can be chosen by user\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false # default false, added for verbosity\n",
    "   CLINICAL: # can be chosen by user\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\" # default NUMERIC (as for RNA and METHYLATION)\n",
    "```\n",
    "ATTENTION:\n",
    "If you use `.txt` or `.csv` files, it is best practice to add the `sep` parameter. If none is given, the reader will try to auto-detect the separator, which is error prone.\n",
    "This would loke like:\n",
    "```YAML\n",
    "    RNA:\n",
    "      ...\n",
    "      sep: \"\\t\" # for tab, \";\" or \",\" would be also possible (as in pandas)\n",
    "\n",
    "```\n",
    "#### IMPORTANT\n",
    "For all your bulk data files, we expect the first column to be some kind of unique sample id. Please prepare the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# this fills the data_config attribute of the DefaultConfig object\n",
    "# we can also change the default values in the config.yaml file\n",
    "# or via the DefaultConfig object\n",
    "data_info = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with custom values\n",
    "custom_config = DefaultConfig.model_validate(\n",
    "    {\n",
    "        **yaml.safe_load(Path(\"configs/multi_bulk.yaml\").read_text()),\n",
    "        \"learning_rate\": 0.77,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_info={'RNA': DataInfo(file_path='data/raw/mini/bulk/rna_sample_data.csv', data_type='NUMERIC', scaling='STANDARD', filtering='VAR', is_single_cell=False, min_cells=1, min_genes=1, k_filter_sc=None, translate_direction=None, img_root=None, is_X=None, sep=',', extra_anno_file=None, img_width_resize=None, img_height_resize=None), 'METHYLATION': DataInfo(file_path='data/raw/mini/bulk/meth_sample_data.tsv', data_type='NUMERIC', scaling='STANDARD', filtering='VAR', is_single_cell=False, min_cells=1, min_genes=1, k_filter_sc=None, translate_direction=None, img_root=None, is_X=None, sep='\\t', extra_anno_file=None, img_width_resize=None, img_height_resize=None), 'CLINICAL': DataInfo(file_path='data/raw/mini/bulk/clinical_sample_data.parquet', data_type='ANNOTATION', scaling='STANDARD', filtering='VAR', is_single_cell=False, min_cells=1, min_genes=1, k_filter_sc=None, translate_direction=None, img_root=None, is_X=None, sep=None, extra_anno_file=None, img_width_resize=None, img_height_resize=None)}\n",
      "0.001\n",
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(data_info.data_config)\n",
    "print(data_info.learning_rate)\n",
    "print(custom_config.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataConfig in Python\n",
    "We will only use one way of config creation for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "root_dir = os.path.join(\"data/raw\")\n",
    "meth_file = \"data_methylation_per_gene_formatted.parquet\"\n",
    "mrna_file = \"data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "clin_file = \"data_clinical_formatted.parquet\"\n",
    "\n",
    "bulk_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"RNA\": DataInfo(file_path=os.path.join(root_dir, mrna_file)),\n",
    "            \"METHYLATION\": DataInfo(file_path=os.path.join(root_dir, meth_file)),\n",
    "            \"CLINICAL\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, clin_file), data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the input data\n",
    "Practically we would be done with the above step. We pass the config to the pipeline as shown multiple times before. For cleared documentation (esepcially for Devs) we show what happens inside the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC\n",
      "NUMERIC\n",
      "ANNOTATION\n",
      "common samples\n",
      "dict_keys(['RNA', 'METHYLATION'])\n",
      "(10013, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autoencodix.utils._bulkreader import BulkDataReader\n",
    "\n",
    "screader = BulkDataReader()\n",
    "bulk_dfs, anno_df = screader.read_data(config=bulk_config)\n",
    "print(bulk_dfs.keys()), print(anno_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How the data is handled internally.\n",
    "The BasePreprocessor class has a `datapackage` attribute. This is a instance of a class that holds, this class holds four attributes:\n",
    "- bulk_dfs_dict (dict with pdDataframes),holding bulk data\n",
    "- anndata: AnnData for singcle cell\n",
    "- annotation: pd.Dataframe (for metadata duplciate with anndata.obs in sc case)\n",
    "- ImgData with list of images and image metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04.2 Working with single cell data from different sequencing processes\n",
    "First we define our config again, then we use the reader object to build the AnnData (this will look more familar for single cell practioners)\n",
    "\n",
    "We can provide a config yaml like:\n",
    "```YAML\n",
    "# config.yaml\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\" # we request h5ad files\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "scconfig = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"configs/largesc.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata after reading: AnnData object with n_obs × n_vars = 45549 × 19475\n",
      "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
      "type of adata after reading: <class 'anndata._core.anndata.AnnData'>\n",
      "type of adata after filtering: <class 'anndata._core.anndata.AnnData'>\n",
      "adata after reading: AnnData object with n_obs × n_vars = 45549 × 30033\n",
      "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
      "type of adata after reading: <class 'anndata._core.anndata.AnnData'>\n",
      "type of adata after filtering: <class 'anndata._core.anndata.AnnData'>\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils._screader import SingleCellDataReader\n",
    "\n",
    "screader = SingleCellDataReader()\n",
    "adata = screader.read_data(config=scconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 45549 × 17425\n",
      "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid', 'RNA_author_cell_type', 'RNA_age_group', 'RNA_donor_id', 'RNA_nCount_RNA', 'RNA_nFeature_RNA', 'RNA_nCount_ATAC', 'RNA_nFeature_ATAC', 'RNA_TSS_percentile', 'RNA_nucleosome_signal', 'RNA_percent_mt', 'RNA_assay_ontology_term_id', 'RNA_cell_type_ontology_term_id', 'RNA_development_stage_ontology_term_id', 'RNA_disease_ontology_term_id', 'RNA_self_reported_ethnicity_ontology_term_id', 'RNA_organism_ontology_term_id', 'RNA_sex_ontology_term_id', 'RNA_tissue_ontology_term_id', 'RNA_suspension_type', 'RNA_is_primary_data', 'RNA_batch', 'RNA_tissue_type', 'RNA_cell_type', 'RNA_assay', 'RNA_disease', 'RNA_organism', 'RNA_sex', 'RNA_tissue', 'RNA_self_reported_ethnicity', 'RNA_development_stage', 'RNA_observation_joinid', 'METH_author_cell_type', 'METH_age_group', 'METH_donor_id', 'METH_nCount_RNA', 'METH_nFeature_RNA', 'METH_nCount_ATAC', 'METH_nFeature_ATAC', 'METH_TSS_percentile', 'METH_nucleosome_signal', 'METH_percent_mt', 'METH_assay_ontology_term_id', 'METH_cell_type_ontology_term_id', 'METH_development_stage_ontology_term_id', 'METH_disease_ontology_term_id', 'METH_self_reported_ethnicity_ontology_term_id', 'METH_organism_ontology_term_id', 'METH_sex_ontology_term_id', 'METH_tissue_ontology_term_id', 'METH_suspension_type', 'METH_is_primary_data', 'METH_batch', 'METH_tissue_type', 'METH_cell_type', 'METH_assay', 'METH_disease', 'METH_organism', 'METH_sex', 'METH_tissue', 'METH_self_reported_ethnicity', 'METH_development_stage', 'METH_observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
      "    layers: 'RNA', 'METH'\n"
     ]
    }
   ],
   "source": [
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04.3 Translating between omics data\n",
    "We only allow bulk to bulk and single-cell to single cell. The config is almost identical to the case before, we only add the direction of the translation like:\n",
    "```YAML\n",
    "data_config:\n",
    " data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/Sc-1.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     min_genes: 0.01\n",
    "     is_X: true\n",
    "     translate_direction: \"FROM\"\n",
    "   METH:\n",
    "     file_path: \"data/raw/Sc-2.h5ad\"\n",
    "     is_single_cell: true\n",
    "     min_cells: 0.01\n",
    "     translate_direction: \"TO\"\n",
    "\n",
    "```\n",
    "\n",
    "For the bulk case we can keep annotation data without including it in the translation like:\n",
    "```YAML\n",
    "# config.yaml\n",
    "data_config:\n",
    "  data_info:\n",
    "   RNA:\n",
    "     file_path: \"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"FROM\"\n",
    "   METHYLATION:\n",
    "     file_path: \"data/raw/data_methylation_per_gene_formatted.parquet\"\n",
    "     is_single_cell: false\n",
    "     translate_direction: \"TO\"\n",
    "   CLINICAL:\n",
    "     file_path: \"data/raw/data_clinical_formatted.parquet\"\n",
    "     data_type: \"ANNOTATION\"\n",
    "     # default translate_direction is  NONE, so we don't need to specify it here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04.4 Working with images\n",
    "When working with images, we need have two cases:\n",
    "- pure image, without translating\n",
    "- translating between omics and images\n",
    "\n",
    "In the first case we need to provide the folder path of the images. In the second case we need to provide the folder path of the images and an annotation file that maps the metadata for the images to the image filenames. In this file we also need to map the sample_ids of the other data modality to the image filename and metadata. Later we will add support for an unpaired case, where we only provide image metadata without mapping to the other data modality.\n",
    "The file should look like this:\n",
    "**important**: this file needs to contain the columns `sample_ids` and `img_paths`\n",
    "```text\n",
    "sample_ids\timg_paths\tMETADATA1\tMETADATA2\n",
    "TCGA-05-4244-01\t0_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4249-01\t1_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4250-01\t2_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4382-01\t3_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4384-01\t4_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4389-01\t5_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4390-01\t6_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4395-01\t7_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "TCGA-05-4396-01\t8_label_1.png\tNon-Small Cell Lung Cancer\tLUAD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image only case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/default_config.py:290: UserWarning: Could not determine data_case: No numeric datasets found in data_info\n",
      "  warnings.warn(f\"Could not determine data_case: {str(e)}\")\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(file_path=\"data/raw/images/tcga_fake\", data_type=\"IMG\"),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\", data_type=\"ANNOTATION\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images and omics data\n",
    "If you want to translate between image and another data modality you need to provide the same files as above. For the Annotation files you have two possibilities: (a) you provide one annotation file (as shown above), in this file you match the metadata of the two data modalites, by an shared sample_id / mapping of sample_id and image_path and other metadata. (b) you can have supply an extra annotation file for the images with the attribute `img_anno_file`. If None is given, we will use the shared file. This is only allowed for unpaired translation.\n",
    "So for the unpaired translation the `DataConfig` should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DataConfig, DataInfo, DefaultConfig\n",
    "\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\",\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\",\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data/raw/tcga_mappings.txt\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading annotation file: data/raw/tcga_mappings.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/src/autoencodix/utils/_imgreader.py:173: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  annotation = pd.read_csv(anno_file, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "\n",
    "imgreader = ImageDataReader()\n",
    "imgdata = imgreader.read_data(config=img_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpaired case\n",
    "This case is not implemented in the old version of `autoencodix` and will be added after the other translating features, we still show how the config can look like:\n",
    "```python\n",
    "from autoencodix.utils.default_config import DataConfig, DataInfo\n",
    "img_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=\"data/raw/images/tcga_fake.txt\",\n",
    "                data_type=\"IMG\",\n",
    "                translate_direction=\"to\"\n",
    "                extra_anno_file=\"path/to/file\"\n",
    "            ),\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=\"data/raw/data_mrna_seq_v2_rsem_formatted.parquet\",\n",
    "                data_type=\"NUMERIC\",\n",
    "                translate_direction=\"from\"\n",
    "            ),\n",
    "            \"ANNO\": DataInfo(\n",
    "                file_path=\"data_clinical_formatted.parquet\",\n",
    "                data_type=\"ANNOTATION\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal handling of image data\n",
    "Image and bulk case (paired)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 How to add a new architecture\n",
    "### High level workflow\n",
    "To add a new autoencoder architecture, you need to at least code two things:\n",
    "- the model architecture itself in  `src/autoencodix/modeling/` - anlogous to `_varix_architecture.py`\n",
    "- the pipeline itself in `src/autoencodix/` - analgous to `varix.py`\n",
    "Depending on the complexity and data requirements you might also want to provide the following:\n",
    "- a new custom dataset class in `src/autoencodix/data` - analogous to `numeric_dataset.py`\n",
    "- a new custom preprocessor in `src/autoencodix/data` - as in `preprocessor.py`\n",
    "- a new custom trainer in `src/autoencodix/trainers` - as in `_general_trainer.py`\n",
    "  - including a custom predict method of your trainer\n",
    "- a custom loss for your model\n",
    "- a custom visualizer (no example implemented yet)\n",
    "- a custom evaluator for downstream tasks (no example implemented yet)\n",
    "- a custom tuner (not sure if this will be part of the package)\n",
    "### High level structure\n",
    "- Each autoencodix model in our family is based on our base classes in `src/autoencodix/base`. Here we have (often abstract) classes that define the general structure of each step (preprocess, fit, predict, evaluate, visualize) in our pipeline, as well as additional classes e.g. losses.\n",
    "- In these base classes we've implemented shared functionalities, like calling the corresponding trainer, or preprocessor.\n",
    "- The base classes also guide you to the structure of your new class. The methods of the base classes should not be changed. Rather overwrite the method in the implementation of your child class in case you need to make changes.\n",
    "\n",
    "### Must-do files details\n",
    "We'll illustrate this by an example. We want to add the new architecture with the name MySpecial to our package. First we add the actual architecture:\n",
    "- create the file `src/autoencodix/modeling/_myspecialix_architecture.py` (note files that should not be imported at end-user lever have a leading underscore).\n",
    "- create the file `tests/test_modelling/test_myspecialix_architecture`\n",
    "- we write the class itself that might look like:\n",
    "```python\n",
    "from autoencodix.base._base_autoencoder import BaseAutoencoder\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "\n",
    "# needs to inherit from BaseAutoencoder\n",
    "class MySpecialArchitecture(BaseAutoencoder):\n",
    "    \"\"\"\n",
    "    MySpecial implementation accroding to (cite paper, yourself, etc)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.input_dim : int\n",
    "        number of input features\n",
    "    self.config: DefaultConfig\n",
    "        Configuration object containing model architecture parameters\n",
    "    self._encoder: nn.Module\n",
    "        Encoder network of the autoencoder\n",
    "    self._decoder: nn.Module\n",
    "        Decoder network of the autoencoder\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    my_super_special_method():\n",
    "        does cool stuff\n",
    "    _build_network()\n",
    "        Construct the encoder and decoder networks via the LayerFactory\n",
    "    encode(x: torch.Tensor) -> torch.Tensor\n",
    "        Encode the input tensor x\n",
    "    decode(x: torch.Tensor) -> torch.Tensor\n",
    "        Decode the latent tensor x\n",
    "    forward(x: torch.Tensor) -> ModelOutput\n",
    "        Forward pass of the model, fills in the reconstruction and latentspace attributes of ModelOutput class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, config: Optional[Union[None, DefaultConfig]], input_dim: int\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = DefaultConfig()\n",
    "        self._config = config\n",
    "        super().__init__(config, input_dim)\n",
    "        self.input_dim = input_dim # we always base the input dimension (usually number of features in your dataset)\n",
    "\n",
    "        # populate self.encoder and self.decoder\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Construct the encoder and decoder networks.\n",
    "        See your _layer_factory.py file that could help you here.\n",
    "        Also check other implementation to see how to use _layer_factory.py\n",
    "        \"\"\"\n",
    "        self._encoder = TODO\n",
    "        self._decoder = TODO\n",
    "\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encode the input tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Encoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        encoded = self._encoder(x)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode the latent tensor x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Latent tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Decoded tensor\n",
    "\n",
    "        \"\"\"\n",
    "        return self._decoder(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> ModelOutput:\n",
    "        \"\"\"\n",
    "        Forward pass of the model, fill\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelOutput\n",
    "            ModelOutput object containing the reconstructed tensor and latent tensor\n",
    "\n",
    "        \"\"\"\n",
    "        latent = self.encode(x)\n",
    "        x_hat = self.decode(z)\n",
    "        # fill model output arcodding to your needs (we need reconstruction and a latentspace, see ModelOuput class for required output)\n",
    "        return ModelOutput(\n",
    "            reconstruction=x_hat,\n",
    "            latentspace=latent\n",
    "            latent_mean=None,\n",
    "            latent_logvar=None,\n",
    "            additional_info=None,\n",
    "        )\n",
    "\n",
    "```\n",
    "- adjust the `__init__.py` in `src/autoencodix/modelling` to import `MySpecialArchitecture\n",
    "- next we write tests for the newly created file in the test file\n",
    "- lastly, we need to create the pipeline file:\n",
    "  - create `src/autoencodix/myspecialix.py`\n",
    "  - create `tests/test_myspecialix.py`\n",
    "- the `myspecialix.py` might look like this\n",
    "```python\n",
    "# your imports\n",
    "# TODO\n",
    "\n",
    "class MySpecialix(BasePipeline): # must inhertit from BasePipeline\n",
    "    \"\"\"\n",
    "    MySpecialix specific version of the BasePipeline class.\n",
    "    Inherits preprocess, fit, predict, evaluate, and visualize methods from BasePipeline.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "        Input data from the user\n",
    "    config : Optional[Union[None, DefaultConfig]]\n",
    "        Configuration object containing customizations for the pipeline\n",
    "    _preprocessor : Preprocessor\n",
    "        Preprocessor object to preprocess the input data (custom for Vanillix)\n",
    "    _visualizer : Visualizer\n",
    "        Visualizer object to visualize the model output (custom for Vanillix)\n",
    "    _trainer : GeneralTrainer\n",
    "        Trainer object that trains the model (custom for Vanillix)\n",
    "    _evaluator : Evaluator\n",
    "        Evaluator object that evaluates the model performance or downstream tasks (custom for Vanillix)\n",
    "    result : Result\n",
    "        Result object to store the pipeline results\n",
    "    _datasets : Optional[DatasetContainer]\n",
    "        Container for train, validation, and test datasets (preprocessed)\n",
    "    data_splitter : DataSplitter\n",
    "        DataSplitter object to split the data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[np.ndarray, AnnData, pd.DataFrame],\n",
    "        # this can be also a custom Type like MySpecialixDataset\n",
    "        dataset_type: Type[BaseDataset] = NumericDataset,\n",
    "        # This will be the Type MySpecialixArchitecture that we created before\n",
    "        model_type: Type[BaseAutoencoder] = MySpecialixArchitecture,\n",
    "        # This can be a custom Loss class, or an exisiting one see _losses.py\n",
    "        loss_type: Type[BaseLoss] = VanillixLoss,\n",
    "        preprocessor: Optional[Preprocessor] = None,\n",
    "        visualizer: Optional[BaseVisualizer] = None,\n",
    "        evaluator: Optional[Evaluator] = None,\n",
    "        result: Optional[Result] = None,\n",
    "        datasplitter_type: Type[DataSplitter] = DataSplitter,\n",
    "        custom_splits: Optional[Dict[str, np.ndarray]] = None,\n",
    "        config: Optional[DefaultConfig] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize MySpecialix pipeline with customizable components.\n",
    "\n",
    "        Some components are passed as types rather than instances because they require\n",
    "        data that is only available after preprocessing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Union[np.ndarray, AnnData, pd.DataFrame]\n",
    "            Input data to be processed\n",
    "        trainer_type : Type[BaseTrainer]\n",
    "            Type of trainer to be instantiated during fit step, default is GeneralTrainer\n",
    "        dataset_type : Type[BaseDataset]\n",
    "            Type of dataset to be instantiated post-preprocessing, default is NumericDataset\n",
    "        loss_type : Type[BaseLoss], which loss to use for Vanillix, default is VanillaAutoencoderLoss\n",
    "        preprocessor : Optional[Preprocessor]\n",
    "            For data preprocessing, default creates new Preprocessor\n",
    "        visualizer : Optional[Visualizer]\n",
    "            For result visualization, default creates new Visualizer\n",
    "        evaluator : Optional[Evaluator]\n",
    "            For model evaluation, default creates new Evaluator\n",
    "        result : Optional[Result]\n",
    "            Container for pipeline results, default creates new Result\n",
    "        datasplitter_type : Type[DataSplitter], optional\n",
    "            Type of splitter to be instantiated during preprocessing, default is DataSplitter\n",
    "        custom_splits : Optional[Dict[str, np.ndarray]]\n",
    "            Custom train/valid/test split indices\n",
    "        config : Optional[DefaultConfig]\n",
    "            Configuration for all pipeline components\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            dataset_type=dataset_type,\n",
    "            trainer_type=trainer_type,\n",
    "            model_type=model_type,\n",
    "            loss_type=loss_type,\n",
    "            preprocessor=preprocessor or Preprocessor(),\n",
    "            visualizer=visualizer or Visualizer(),\n",
    "            evaluator=evaluator or Evaluator(),\n",
    "            result=result or Result(),\n",
    "            datasplitter_type=datasplitter_type,\n",
    "            config=config or DefaultConfig(),\n",
    "            custom_split=custom_splits,\n",
    "        )\n",
    "\n",
    "```\n",
    "##### More explaination to the passing of Types instead of classes:\n",
    "Most functionality of the pipeline comes from the BasePipeline. To make the methods custom to our specific architecture that we use in our `MySpecial` pipeline, we need to pass our specializes subclasses. Since we don't have all required parameters for this subclasses when calling the init method of the parent class, we pass only the type of the subclasses. These types need to be childs of the corresponding base class. Inside the BasePipeline we instantiate the specific classes with the required paramters as soon as we have them\n",
    "### Optional files details\n",
    "The optional files work from the same principle as the mandatory files, so we can always create a special class based on the baseclass and then we pass the type of our special class to our MySpecialix Pipeline e.g MySpecialTrainer n the init mehtod of MySpecialix (same as we did with MySpecialArchitecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- show how to update and work with the config object (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SANDBOX \n",
    "testing Varix and losses, especially sub_losses in result_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### P1 Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from autoencodix.utils._screader import SingleCellDataReader\n",
    "from autoencodix.utils._bulkreader import BulkDataReader\n",
    "from autoencodix.utils._imgreader import ImageDataReader\n",
    "from autoencodix.data._datasplitter import DataSplitter\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "\n",
    "\n",
    "from autoencodix.base._base_preprocessor import BasePreprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### config paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_path = \"configs/largebulk.yaml\"\n",
    "scpath = \"configs/largesc.yaml\"\n",
    "tranpath = \"configs/sc_img_tran_config.yaml\"\n",
    "unpaired_path = \"configs/bulk_img_up.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_config = DefaultConfig.model_validate(yaml.safe_load(Path(bulk_path).read_text()))\n",
    "scconfig = DefaultConfig.model_validate(yaml.safe_load(Path(scpath).read_text()))\n",
    "tranconfig = DefaultConfig.model_validate(yaml.safe_load(Path(tranpath).read_text()))\n",
    "unpaired_config = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(unpaired_path).read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'log_X', 'log2_X']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scconfig.data_config.data_info[\"RNA\"].selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "import mudata as md\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from autoencodix.data._datasetcontainer import DatasetContainer\n",
    "from autoencodix.base._base_preprocessor import BasePreprocessor\n",
    "\n",
    "\n",
    "class GeneralPreprocessor(BasePreprocessor):\n",
    "    \"\"\"\n",
    "    General Preprocessor class that uses the general_preprocessing steps from BasePreprocessor.\n",
    "    It takes the split, cleaned, scaled, and filtered data packages and transforms them into a PyTorch\n",
    "    Dataset that can be used in training. This class is primarily used for the Vanillix and Varix\n",
    "    pipelines for numeric data.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _datapackage : Dict[str, Any]\n",
    "        The processed data package containing split, cleaned, scaled, and filtered data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess()\n",
    "        Executes the general preprocessing steps and returns the processed data package.\n",
    "    _extract_primary_data(modality_data: Any) -> np.ndarray\n",
    "        Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "    _combine_modality_data(mudata: MuData) -> np.ndarray\n",
    "        Combines the primary data matrices (.X) from all modalities in a MuData object.\n",
    "    _create_numeric_dataset(data: np.ndarray, config: Any, split_ids: np.ndarray, metadata: Any, ids: List[str]) -> NumericDataset\n",
    "        Creates a NumericDataset from the given data and metadata.\n",
    "    _process_multi_bulk(data_dict: Dict[str, pd.DataFrame], config: Any, split_ids: np.ndarray, metadata: Any) -> NumericDataset\n",
    "        Processes multi-bulk data by concatenating all dataframes and creating a NumericDataset.\n",
    "    _process_multi_sc(mudata: MuData, config: Any, split_ids: np.ndarray, metadata: Any) -> NumericDataset\n",
    "        Processes multi-single-cell data by combining modalities and creating a NumericDataset.\n",
    "    _process_data_package(data_package: Dict[str, Any], config: Any, split_type: str = \"train\") -> Union[NumericDataset, None]\n",
    "        Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: DefaultConfig):\n",
    "        \"\"\"\n",
    "        Initializes the GeneralPreprocessor with the given configuration.\n",
    "\n",
    "        Args:\n",
    "            config (Any): Configuration for the preprocessor.\n",
    "        \"\"\"\n",
    "        super().__init__(config=config)\n",
    "        self._datapackage = None\n",
    "\n",
    "    def _extract_primary_data(self, modality_data: md.MuData) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "\n",
    "        Args:\n",
    "            modality_data (Any): The modality data (e.g., AnnData object).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The primary data matrix as a dense array.\n",
    "        \"\"\"\n",
    "        primary_data = modality_data.X\n",
    "        if issparse(primary_data):\n",
    "            primary_data = primary_data.toarray()\n",
    "        return primary_data\n",
    "\n",
    "    def _combine_layers(self, modality_name: str, modality_data: Any) -> np.ndarray:\n",
    "        layer_list = []\n",
    "        selected_layers = self.config.data_config.data_info[\n",
    "            modality_name\n",
    "        ].selected_layers\n",
    "\n",
    "        for layer_name in selected_layers:\n",
    "            if layer_name == \"X\":\n",
    "                primary_data = self._extract_primary_data(modality_data)\n",
    "                layer_list.append(primary_data)\n",
    "            elif layer_name in modality_data.layers:\n",
    "                # Handle additional layers\n",
    "                layer_data = modality_data.layers[layer_name]\n",
    "                # Convert sparse matrix to dense if necessary\n",
    "                if issparse(layer_data):\n",
    "                    layer_data = layer_data.toarray()\n",
    "                layer_list.append(layer_data)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Layer '{layer_name}' not found in modality '{modality_name}'. Skipping.\"\n",
    "                )\n",
    "        return layer_list\n",
    "\n",
    "    def _combine_modality_data(self, mudata: md.MuData) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Combines the primary data matrices (.X) and specified layers from all modalities in a MuData object.\n",
    "\n",
    "        Args:\n",
    "            mudata (MuData): The MuData object containing multiple modalities.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The combined data matrix.\n",
    "        \"\"\"\n",
    "        modality_data_list = []\n",
    "\n",
    "        for modality_name, modality_data in mudata.mod.items():\n",
    "            combined_layers = self._combine_layers(\n",
    "                modality_name=modality_name, modality_data=modality_data\n",
    "            )\n",
    "            modality_data_list.extend(combined_layers)\n",
    "\n",
    "        return np.concatenate(modality_data_list, axis=1)\n",
    "\n",
    "    def _create_numeric_dataset(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        config: DefaultConfig,\n",
    "        split_ids: np.ndarray,\n",
    "        metadata: pd.DataFrame,\n",
    "        ids: List[str],\n",
    "    ) -> NumericDataset:\n",
    "        \"\"\"\n",
    "        Creates a NumericDataset from the given data and metadata.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The data matrix.\n",
    "            config (Any): Configuration for the dataset.\n",
    "            split_ids (np.ndarray): Indices for splitting the data.\n",
    "            metadata (Any): Metadata associated with the data.\n",
    "            ids (List[str]): Identifiers for the observations.\n",
    "\n",
    "        Returns:\n",
    "            NumericDataset: The created NumericDataset.\n",
    "        \"\"\"\n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        return NumericDataset(\n",
    "            data=tensor_data,\n",
    "            config=config,\n",
    "            split_ids=split_ids,\n",
    "            metadata=metadata,\n",
    "            ids=ids,\n",
    "        )\n",
    "\n",
    "    def _process_data_package(\n",
    "        self, data_dict: Dict[str, Any]\n",
    "    ) -> Union[NumericDataset, None]:\n",
    "        \"\"\"\n",
    "        Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "\n",
    "        Args:\n",
    "            data_package (Dict[str, Any]): The data package containing data and metadata.\n",
    "            config (Any): Configuration for the dataset.\n",
    "            split_type (str): The type of split to process (e.g., \"train\").\n",
    "\n",
    "        Returns:\n",
    "            Union[NumericDataset, None]: The created NumericDataset or None if the data type is unsupported.\n",
    "        \"\"\"\n",
    "        data, split_ids = data_dict[\"data\"], data_dict[\"indices\"]\n",
    "\n",
    "        for key in data.__annotations__.keys():\n",
    "            attr_val = getattr(data, key)\n",
    "            if key == \"multi_bulk\" and attr_val is not None:\n",
    "                metadata = data.annotation\n",
    "                dfs_to_concat = list(attr_val.values())\n",
    "                combined_df = pd.concat(dfs_to_concat, axis=1)\n",
    "                return self._create_numeric_dataset(\n",
    "                    data=combined_df.values,\n",
    "                    config=self.config,\n",
    "                    split_ids=split_ids,\n",
    "                    metadata=metadata,\n",
    "                    ids=combined_df.index.tolist(),\n",
    "                )\n",
    "\n",
    "            elif key == \"multi_sc\" and attr_val is not None:\n",
    "                combined_data = self._combine_modality_data(attr_val)\n",
    "                combined_obs = pd.concat(\n",
    "                    [modality_data.obs for modality_data in attr_val.mod.values()],\n",
    "                    axis=1,\n",
    "                )\n",
    "                return self._create_numeric_dataset(\n",
    "                    data=combined_data,\n",
    "                    config=self.config,\n",
    "                    split_ids=split_ids,\n",
    "                    metadata=combined_obs,\n",
    "                    ids=attr_val.obs_names.tolist(),\n",
    "                )\n",
    "\n",
    "        return None\n",
    "\n",
    "    def preprocess(self) -> DatasetContainer:\n",
    "        \"\"\"\n",
    "        Executes the general preprocessing steps and returns the processed data package.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The processed data package.\n",
    "        \"\"\"\n",
    "\n",
    "        self._datapackage = self._general_preprocess()\n",
    "        self._dataset_container = DatasetContainer()\n",
    "        for split in [\"train\", \"test\", \"valid\"]:\n",
    "            dataset = self._process_data_package(data_dict=self._datapackage[split])\n",
    "            self._dataset_container[split] = dataset\n",
    "\n",
    "        return self._dataset_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprocessor = GeneralPreprocessor(config=scconfig)\n",
    "bulkprocessor = GeneralPreprocessor(config=bulk_config)\n",
    "tranupprocessor = GeneralPreprocessor(config=unpaired_config)\n",
    "trprocessor = GeneralPreprocessor(config=tranconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape changed from (7008, 16313) to (7008, 16313)\n",
      "Shape changed from (7008, 16313) to (7008, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (7008, 9228) to (7008, 9228)\n",
      "Shape changed from (7008, 9228) to (7008, 9228)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (1002, 16313) to (1002, 16313)\n",
      "Shape changed from (1002, 16313) to (1002, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (1002, 9228) to (1002, 9228)\n",
      "Shape changed from (1002, 9228) to (1002, 9228)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (2003, 16313) to (2003, 16313)\n",
      "Shape changed from (2003, 16313) to (2003, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (2003, 9228) to (2003, 9228)\n",
      "Shape changed from (2003, 9228) to (2003, 9228)\n",
      "Applying STANDARD scaling\n"
     ]
    }
   ],
   "source": [
    "processor = GeneralPreprocessor(config=bulk_config)\n",
    "dp = processor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:449: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common cells: 4554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:449: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape changed from (3187, 8474) to (3187, 8474)\n",
      "Shape changed from (3187, 8474) to (3187, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (3187, 8474) to (3187, 8474)\n",
      "Shape changed from (3187, 8474) to (3187, 8474)\n",
      "Applying STANDARD scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:449: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape changed from (456, 6815) to (456, 6815)\n",
      "Shape changed from (456, 6815) to (456, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (456, 6815) to (456, 6815)\n",
      "Shape changed from (456, 6815) to (456, 6815)\n",
      "Applying STANDARD scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/development/autoencodix_package/.venv/lib/python3.10/site-packages/mudata/_core/mudata.py:449: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VAR filtering\n",
      "Shape changed from (911, 7471) to (911, 7471)\n",
      "Shape changed from (911, 7471) to (911, 100)\n",
      "Applying STANDARD scaling\n",
      "Applying VAR filtering\n",
      "Shape changed from (911, 7471) to (911, 7471)\n",
      "Shape changed from (911, 7471) to (911, 7471)\n",
      "Applying STANDARD scaling\n"
     ]
    }
   ],
   "source": [
    "scprocessor = GeneralPreprocessor(config=scconfig)\n",
    "scdp = scprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mudata = sc.read_h5ad(\"data/raw/Sc-2-mini.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4554 × 30033\n",
       "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
       "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
       "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
       "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
       "    layers: 'log2_X', 'log_X'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mudata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled MuData 1: 4554 cells, 9009 genes\n",
      "Subsampled MuData 2: 4554 cells, 9009 genes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from mudata import MuData\n",
    "\n",
    "def subsample_matched_data(\n",
    "    mdata1: MuData, \n",
    "    mdata2: MuData, \n",
    "    cell_frac: float = 0.1, \n",
    "    gene_frac: float = 0.3, \n",
    "    random_seed: int = 42\n",
    ") -> tuple[MuData, MuData]:\n",
    "    \"\"\"\n",
    "    Subsample matched cells and genes from two MuData objects.\n",
    "\n",
    "    Args:\n",
    "        mdata1 (MuData): The first MuData object.\n",
    "        mdata2 (MuData): The second MuData object.\n",
    "        cell_frac (float): Fraction of cells to keep (default: 0.1).\n",
    "        gene_frac (float): Fraction of genes to keep (default: 0.3).\n",
    "        random_seed (int): Random seed for reproducibility (default: 42).\n",
    "\n",
    "    Returns:\n",
    "        tuple[MuData, MuData]: Subsampled MuData objects.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Ensure both datasets have the same cells and genes\n",
    "    if not np.array_equal(mdata1.obs_names, mdata2.obs_names):\n",
    "        raise ValueError(\"Datasets do not have the same cells.\")\n",
    "    if not np.array_equal(mdata1.var_names, mdata2.var_names):\n",
    "        raise ValueError(\"Datasets do not have the same genes.\")\n",
    "\n",
    "    # Subsample cells\n",
    "    n_cells = int(mdata1.n_obs * cell_frac)\n",
    "    cell_indices = np.random.choice(mdata1.n_obs, size=n_cells, replace=False)\n",
    "\n",
    "    # Subsample genes\n",
    "    n_genes = int(mdata1.n_vars * gene_frac)\n",
    "    gene_indices = np.random.choice(mdata1.n_vars, size=n_genes, replace=False)\n",
    "\n",
    "    # Subset both datasets using the same indices\n",
    "    mdata1_subset = mdata1[cell_indices, gene_indices].copy()\n",
    "    mdata2_subset = mdata2[cell_indices, gene_indices].copy()\n",
    "\n",
    "    # Validate the subsets\n",
    "    print(f\"Subsampled MuData 1: {mdata1_subset.n_obs} cells, {mdata1_subset.n_vars} genes\")\n",
    "    print(f\"Subsampled MuData 2: {mdata2_subset.n_obs} cells, {mdata2_subset.n_vars} genes\")\n",
    "\n",
    "    return mdata1_subset, mdata2_subset\n",
    "\n",
    "# Example usage\n",
    "# Load the datasets\n",
    "mdata1 = sc.read_h5ad(\"data/raw/Sc-1.h5ad\")\n",
    "mdata2 = sc.read_h5ad(\"data/raw/Sc-2.h5ad\")\n",
    "\n",
    "# Subsample matched data (10% of cells and 30% of genes)\n",
    "mdata1_subset, mdata2_subset = subsample_matched_data(mdata1, mdata2, cell_frac=0.1, gene_frac=0.3)\n",
    "\n",
    "# Save the subsets to new files\n",
    "mdata1_subset.write_h5ad(\"data/raw/Sc-1-mini.h5ad\")\n",
    "mdata2_subset.write_h5ad(\"data/raw/Sc-2-mini.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3187, 17248])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scdp.train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9009\n",
      "18018\n",
      "27027\n",
      "36036\n",
      "45045\n",
      "54054\n",
      "63063\n",
      "72072\n",
      "81081\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for i in range(9):\n",
    "    x=9009 +x\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': multi_bulk:\n",
       "   RNA: 7008 samples × 100 features\n",
       "   METHYLATION: 7008 samples × 9228 features\n",
       " annotation:\n",
       "   paired: 7008 samples × 54 features,\n",
       " 'indices': {'paired': {'train': array([8477, 6327, 8356, ..., 6462, 3304, 4973])}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_sc\n",
      "multi_bulk\n",
      "dict_keys(['RNA', 'METHYLATION'])\n",
      "annotation\n",
      "img\n",
      "from_modality\n",
      "to_modality\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "from mudata import MuData\n",
    "\n",
    "data = dp[\"train\"][\"data\"]\n",
    "for k in data.__annotations__.keys():\n",
    "    print(k)\n",
    "\n",
    "    attr_val = getattr(data, k)\n",
    "    if k == \"multi_bulk\":\n",
    "        dfs_to_concat = list(attr_val.values())\n",
    "        df = pd.concat(dfs_to_concat, axis=1)\n",
    "        t = torch.from_numpy(df.values)\n",
    "        dataset = NumericDataset(\n",
    "            data=t,\n",
    "            config=bulk_config,\n",
    "            split_ids=dp[\"train\"][\"indices\"],\n",
    "            metadata=data.annotation,\n",
    "            ids=df.index,\n",
    "        )\n",
    "\n",
    "    elif k == \"multi_sc\":\n",
    "        # Collect all modality data matrices\n",
    "        layer_list = []\n",
    "\n",
    "        # Iterate over modalities in the MuData object\n",
    "        for modality_name, modality_data in attr_val.mod.items():\n",
    "            print(f\"Processing modality: {modality_name}\")\n",
    "            primary_data = modality_data.X\n",
    "            if issparse(primary_data):\n",
    "                primary_data = primary_data.toarray()\n",
    "            layer_list.append(primary_data)\n",
    "\n",
    "        combined_data = np.concatenate(layer_list, axis=1)\n",
    "        t = torch.from_numpy(combined_data)\n",
    "        dataset = NumericDataset(\n",
    "            data=t,\n",
    "            config=sc_config,  # Replace with appropriate config for single-cell data\n",
    "            split_ids=dp[\"train\"][\"indices\"],\n",
    "            metadata=data.annotation,\n",
    "            ids=attr_val.obs_names,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "from mudata import MuData\n",
    "from autoencodix.data._numeric_dataset import NumericDataset\n",
    "\n",
    "\n",
    "def extract_primary_data(modality_data: Any) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts the primary data matrix (.X) from a modality and converts it to a dense array if sparse.\n",
    "\n",
    "    Args:\n",
    "        modality_data: The modality data (e.g., AnnData object).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The primary data matrix as a dense array.\n",
    "    \"\"\"\n",
    "    primary_data = modality_data.X\n",
    "    if issparse(primary_data):\n",
    "        primary_data = primary_data.toarray()\n",
    "    return primary_data\n",
    "\n",
    "\n",
    "def combine_modality_data(mudata: MuData) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Combines the primary data matrices (.X) from all modalities in a MuData object.\n",
    "\n",
    "    Args:\n",
    "        mudata (MuData): The MuData object containing multiple modalities.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The combined data matrix.\n",
    "    \"\"\"\n",
    "    modality_data_list = []\n",
    "    for modality_name, modality_data in mudata.mod.items():\n",
    "        print(f\"Processing modality: {modality_name}\")\n",
    "        primary_data = extract_primary_data(modality_data)\n",
    "        modality_data_list.append(primary_data)\n",
    "    return np.concatenate(modality_data_list, axis=1)\n",
    "\n",
    "\n",
    "def create_numeric_dataset(\n",
    "    data: np.ndarray,\n",
    "    config: Any,\n",
    "    split_ids: np.ndarray,\n",
    "    metadata: Any,\n",
    "    ids: List[str],\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Creates a NumericDataset from the given data and metadata.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The data matrix.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "        ids (List[str]): Identifiers for the observations.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    tensor_data = torch.from_numpy(data)\n",
    "    return NumericDataset(\n",
    "        data=tensor_data,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=ids,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_multi_bulk(\n",
    "    data_dict: Dict[str, pd.DataFrame],\n",
    "    config: Any,\n",
    "    split_ids: np.ndarray,\n",
    "    metadata: Any,\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Processes multi-bulk data by concatenating all dataframes and creating a NumericDataset.\n",
    "\n",
    "    Args:\n",
    "        data_dict (Dict[str, pd.DataFrame]): Dictionary of dataframes.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    dfs_to_concat = list(data_dict.values())\n",
    "    combined_df = pd.concat(dfs_to_concat, axis=1)\n",
    "    return create_numeric_dataset(\n",
    "        data=combined_df.values,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=combined_df.index.tolist(),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_multi_sc(\n",
    "    mudata: MuData, config: Any, split_ids: np.ndarray, metadata: Any\n",
    ") -> NumericDataset:\n",
    "    \"\"\"\n",
    "    Processes multi-single-cell data by combining modalities and creating a NumericDataset.\n",
    "\n",
    "    Args:\n",
    "        mudata (MuData): The MuData object containing multiple modalities.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_ids (np.ndarray): Indices for splitting the data.\n",
    "        metadata (Any): Metadata associated with the data.\n",
    "\n",
    "    Returns:\n",
    "        NumericDataset: The created NumericDataset.\n",
    "    \"\"\"\n",
    "    combined_data = combine_modality_data(mudata)\n",
    "    return create_numeric_dataset(\n",
    "        data=combined_data,\n",
    "        config=config,\n",
    "        split_ids=split_ids,\n",
    "        metadata=metadata,\n",
    "        ids=mudata.obs_names.tolist(),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_data_package(\n",
    "    data_package: Dict[str, Any], config: Any, split_type: str = \"train\"\n",
    ") -> Union[NumericDataset, None]:\n",
    "    \"\"\"\n",
    "    Processes a data package based on its type (multi-bulk or multi-single-cell).\n",
    "\n",
    "    Args:\n",
    "        data_package (Dict[str, Any]): The data package containing data and metadata.\n",
    "        config (Any): Configuration for the dataset.\n",
    "        split_type (str): The type of split to process (e.g., \"train\").\n",
    "\n",
    "    Returns:\n",
    "        Union[NumericDataset, None]: The created NumericDataset or None if the data type is unsupported.\n",
    "    \"\"\"\n",
    "    split = data_package[split_type][\"data\"]\n",
    "    split_ids = data_package[split_type][\"indices\"]\n",
    "    metadata = split.annotation\n",
    "\n",
    "    for key in split.__annotations__.keys():\n",
    "        attr_val = getattr(split, key)\n",
    "        if key == \"multi_bulk\":\n",
    "            return process_multi_bulk(attr_val, config, split_ids, metadata)\n",
    "        elif key == \"multi_sc\":\n",
    "            if isinstance(attr_val, MuData):\n",
    "                return process_multi_sc(attr_val, config, split_ids, metadata)\n",
    "            else:\n",
    "                print(f\"Unexpected type for 'multi_sc': {type(attr_val)}\")\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1535, -0.1718, -0.3358,  ..., -0.7454, -0.2480, -0.9421],\n",
       "        [-0.1535, -0.1719, -0.3789,  ..., -1.0124, -0.6265, -0.4132],\n",
       "        [-0.1535, -0.1718,  1.4046,  ..., -0.2182,  1.3402,  1.7921],\n",
       "        ...,\n",
       "        [-0.1534, -0.1717, -0.2448,  ..., -0.0310,  0.3051,  0.2150],\n",
       "        [-0.1535, -0.1695, -0.2438,  ..., -0.5193,  0.6643,  0.4962],\n",
       "        [-0.1535, -0.1719, -0.3797,  ..., -0.6217, -0.5289, -0.6165]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jggdataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 9328)\n",
      "(7008, 100)\n",
      "(7008, 9228)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(data.multi_bulk[\"RNA\"].shape)\n",
    "print(data.multi_bulk[\"METHYLATION\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid confgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = os.path.join(\"configs/invalid\")\n",
    "invalid_configs = [\n",
    "    \"invalid_modalities_config.yaml\",\n",
    "    \"invalid_one_config.yaml\",\n",
    "    \"invalid_sc_bulk_config.yaml\",\n",
    "    \"invalid_three_config.yaml\",\n",
    "]\n",
    "invalid_config_objects = []\n",
    "for i, c in enumerate(invalid_configs):\n",
    "    print(c)\n",
    "    try:\n",
    "        data_info = DefaultConfig.model_validate(\n",
    "            yaml.safe_load(Path(os.path.join(base_path, c)).read_text())\n",
    "        )\n",
    "        invalid_config_objects.append(data_info)\n",
    "    except Exception as e:\n",
    "        print(invalid_configs[i])\n",
    "        print(e)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "valid_configs = glob.glob(\"configs/*.yaml\")\n",
    "print(valid_configs)\n",
    "valid_config_objects = []\n",
    "\n",
    "print(len(valid_configs))\n",
    "for c in valid_configs:\n",
    "    print(c)\n",
    "    data_info = DefaultConfig.model_validate(yaml.safe_load(Path(c).read_text()))\n",
    "    valid_config_objects.append(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated config structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate from object\n",
    "Alternatively, we can just create our DefaultConfig Object and initialize it with the data info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Single Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"scconfig.yaml\").read_text())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XModalix with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### images and bulk-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add the rest of the code\n",
    "img_folder = \"images/tcga_mini\"\n",
    "xmodal_config = DefaultConfig(\n",
    "    data_config=DataConfig(\n",
    "        data_info={\n",
    "            \"RNA\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, mrna_file),\n",
    "                data_type=DataType.NUMERIC,\n",
    "            ),\n",
    "            \"IMG\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, \"tcga_mappings.txt\"),\n",
    "                data_type=DataType.IMG,\n",
    "                img_root=os.path.join(root_dir, img_folder),\n",
    "            ),\n",
    "            \"CLINICAL\": DataInfo(\n",
    "                file_path=os.path.join(root_dir, clin_file),\n",
    "                data_type=DataType.ANNOTATION,\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNA data from data/raw/data_mrna_seq_v2_rsem_formatted.parquet\n",
      "Loading IMG data from data/raw/tcga_mappings.txt\n",
      "Skipping image data\n",
      "Loading CLINICAL data from data/raw/data_clinical_formatted.parquet\n",
      "10059\n",
      "Skipping image data\n"
     ]
    }
   ],
   "source": [
    "# bulk seq standard\n",
    "common_samples, config_filled = load_and_intersect_bulkdata(config=xmodal_config)\n",
    "print(len(common_samples))\n",
    "adata = build_bulk_anndata(config=config_filled, common_samples=common_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 10059 × 16313\n",
      "    obs: 'PATIENT_ID', 'ONCOTREE_CODE', 'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TUMOR_TYPE', 'GRADE', 'TISSUE_PROSPECTIVE_COLLECTION_INDICATOR', 'TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR', 'TISSUE_SOURCE_SITE_CODE', 'TUMOR_TISSUE_SITE', 'ANEUPLOIDY_SCORE', 'SAMPLE_TYPE', 'MSI_SCORE_MANTIS', 'MSI_SENSOR_SCORE', 'SOMATIC_STATUS', 'TMB_NONSYNONYMOUS', 'TISSUE_SOURCE_SITE', 'SUBTYPE', 'CANCER_TYPE_ACRONYM', 'OTHER_PATIENT_ID', 'AGE', 'SEX', 'AJCC_PATHOLOGIC_TUMOR_STAGE', 'AJCC_STAGING_EDITION', 'DAYS_LAST_FOLLOWUP', 'DAYS_TO_BIRTH', 'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'ETHNICITY', 'FORM_COMPLETION_DATE', 'HISTORY_NEOADJUVANT_TRTYN', 'ICD_10', 'ICD_O_3_HISTOLOGY', 'ICD_O_3_SITE', 'INFORMED_CONSENT_VERIFIED', 'NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT', 'PATH_M_STAGE', 'PATH_N_STAGE', 'PATH_T_STAGE', 'PERSON_NEOPLASM_CANCER_STATUS', 'PRIMARY_LYMPH_NODE_PRESENTATION_ASSESSMENT', 'PRIOR_DX', 'RACE', 'RADIATION_THERAPY', 'WEIGHT', 'IN_PANCANPATHWAYS_FREEZE', 'OS_STATUS', 'OS_MONTHS', 'DSS_STATUS', 'DSS_MONTHS', 'DFS_STATUS', 'DFS_MONTHS', 'PFS_STATUS', 'PFS_MONTHS', 'AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT'\n",
      "    obsm: 'RNA'\n"
     ]
    }
   ],
   "source": [
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 45549 × 19475\n",
      "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
      "    layers: 'RNA'\n"
     ]
    }
   ],
   "source": [
    "print(scadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(file_path):\n",
    "    ext = file_path.split(\".\")[-1]\n",
    "    if not ext in [\"png\", \"jpg\", \"jpeg\"]:\n",
    "        raise ValueError(f\"Unsupported image format: {ext}\")\n",
    "    img = cv2.imread(file_path)\n",
    "    # read image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder: data/raw/images/tcga_mini\n"
     ]
    }
   ],
   "source": [
    "for k, v in xmodal_config.data_config.data_info.items():\n",
    "    if v.data_type == DataType.IMG:\n",
    "        print(f\"Image folder: {v.file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class XModaleData:\n",
    "    mapping_file: str\n",
    "    img_folder: str\n",
    "    _img_array: List[np.ndarray]\n",
    "    _labels: Dict[str, List[Union[str, int, float]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "\n",
    "adata = ad.AnnData()\n",
    "data_dict = defaultdict(dict)\n",
    "adata = ad.AnnData(\n",
    "    X=data_info.data_config.data_info[\"RNA\"]\n",
    "    .data_object.loc[list(common_samples)]\n",
    "    .values,\n",
    "    obs=pd.DataFrame(index=list(common_samples)),\n",
    ")\n",
    "\n",
    "\n",
    "previous = {}\n",
    "for k, v in data_info.data_config.data_info.items():\n",
    "    if v.data_type == DataType.IMG:\n",
    "        img_folder = v.img_root\n",
    "        mappings = pd.read_csv(v.file_path, sep=\"\\t\")\n",
    "        file_paths = list(mappings[\"img_path\"].values)\n",
    "        imgs = [read_img(os.path.join(img_folder, img)) for img in file_paths]\n",
    "        data_info.data_config.data_info[k].data_object = {\n",
    "            \"imgs\": imgs,\n",
    "            \"mappings\": mappings,\n",
    "        }\n",
    "    if v.data_type == DataType.ANNOTATION:\n",
    "        ann_df = pd.read_parquet(os.path.join(v.file_path))\n",
    "        adata.obs = ann_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next TODOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- write docu of new data handling:\n",
    "  - how to fill config\n",
    "  - how different scenarios work\n",
    "  - how to proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### old testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_losses = result.sub_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils._result import Result, LossRegistry\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "from autoencodix.utils._traindynamics import TrainingDynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_result = Result()\n",
    "sample_model = None\n",
    "sample_datasets = {\"train\": None, \"valid\": None, \"test\": None}\n",
    "sample_recon_data = {\n",
    "    0: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},\n",
    "    100: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},\n",
    "}\n",
    "sample_var_loss_data = {\n",
    "    0: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},\n",
    "    2: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},\n",
    "    100: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},\n",
    "}\n",
    "sample_recon_data_dyn = TrainingDynamics(_data=sample_recon_data)\n",
    "sample_var_loss_data_dyn = TrainingDynamics(_data=sample_var_loss_data)\n",
    "sample_losses = LossRegistry(\n",
    "    _losses={\"recon_loss\": sample_recon_data_dyn, \"var_loss\": sample_var_loss_data_dyn}\n",
    ")\n",
    "filled_result = Result(\n",
    "    model=sample_model, datasets=sample_datasets, sub_losses=sample_losses\n",
    ")\n",
    "\n",
    "recon_loss_data1 = {\n",
    "    0: {\"valid\": 0.1, \"train\": 0.2, \"test\": 0.3},\n",
    "    1: {\"valid\": 0.4, \"train\": 0.5, \"test\": 0.6},\n",
    "    2: {\"valid\": 0.7, \"train\": 0.8, \"test\": 0.9},\n",
    "}\n",
    "var_loss_data1 = {\n",
    "    0: {\"valid\": 0.11, \"train\": 0.21, \"test\": 0.31},\n",
    "    1: {\"valid\": 0.31, \"train\": 0.41, \"test\": 0.51},\n",
    "    2: {\"valid\": 0.51, \"train\": 0.61, \"test\": 0.71},\n",
    "}\n",
    "\n",
    "recon_dynamics1 = TrainingDynamics(_data=recon_loss_data1)\n",
    "var_dynamics1 = TrainingDynamics(_data=var_loss_data1)\n",
    "sample_registry = LossRegistry(\n",
    "    _losses={\"recon_loss\": recon_dynamics1, \"var_loss\": var_dynamics1}\n",
    ")\n",
    "sample_result1 = Result(sub_losses=sample_registry)\n",
    "recon_loss_data2 = {\n",
    "    0: {\"valid\": 0.15, \"train\": 0.25},\n",
    "    1: {\"valid\": 0.45, \"train\": 0.55, \"test\": None},\n",
    "    2: {\"valid\": None, \"train\": 0.85, \"test\": 0.95},\n",
    "}\n",
    "var_loss_data2 = {\n",
    "    0: {\"valid\": 0.16, \"train\": 0.26, \"test\": 0.36},\n",
    "    1: {\"valid\": 0.36, \"train\": 0.46},\n",
    "    2: None,\n",
    "}  # should not be updated\n",
    "\n",
    "recon_dynamics2 = TrainingDynamics(_data=recon_loss_data2)\n",
    "var_dynamics2 = TrainingDynamics(_data=var_loss_data2)\n",
    "sample_registry2 = LossRegistry(\n",
    "    _losses={\"recon_loss\": recon_dynamics2, \"var_loss\": var_dynamics2}\n",
    ")\n",
    "sample_result2 = Result(sub_losses=sample_registry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_update = {\n",
    "    0: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},  # totally overwrite\n",
    "    2: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},  # keep all\n",
    "    3: {},  # update with partial data\n",
    "    4: None,  # udate with all\n",
    "    5: {\n",
    "        \"train\": None,\n",
    "        \"valid\": 0.0,\n",
    "        \"test\": 0.0,\n",
    "    },  # update with partial data (keep test)\n",
    "    6: {\"train\": 0.0},  # update with partial data (keep train), add vlaid and test\n",
    "    7: {\"train\": 0},  # update with partial data {train: 0.1}\n",
    "    100: {\"train\": 0.0, \"valid\": 0.0, \"test\": 0.0},  # not in to update\n",
    "}\n",
    "\n",
    "update_with = {\n",
    "    0: {\"train\": 0.1, \"valid\": 0.2, \"test\": 0.3},\n",
    "    1: {\"train\": 0.4, \"valid\": 0.5, \"test\": 0.6},\n",
    "    2: {},\n",
    "    3: {\"train\": 0.7, \"valid\": 0.8},\n",
    "    4: {\"train\": 0.9, \"valid\": 1.0, \"test\": 1.1},\n",
    "    5: {\"train\": 0.12, \"valid\": 0.22},\n",
    "    6: {\"valid\": 0.32, \"test\": 0.42},\n",
    "    7: {\"train\": 0.1},\n",
    "}\n",
    "\n",
    "expected_result = {\n",
    "    0: {\"train\": np.array(0.1), \"valid\": np.array(0.2), \"test\": np.array(0.3)},\n",
    "    1: {\"train\": np.array(0.4), \"valid\": np.array(0.5), \"test\": np.array(0.6)},\n",
    "    2: {\"train\": np.array(0.0), \"valid\": np.array(0.0), \"test\": np.array(0.0)},\n",
    "    3: {\"train\": np.array(0.7), \"valid\": np.array(0.8)},\n",
    "    4: {\"train\": np.array(0.9), \"valid\": np.array(1.0), \"test\": np.array(1.1)},\n",
    "    5: {\"train\": np.array(0.12), \"valid\": np.array(0.22), \"test\": np.array(0.0)},\n",
    "    6: {\"train\": np.array(0.0), \"valid\": np.array(0.32), \"test\": np.array(0.42)},\n",
    "    7: {\"train\": np.array(0.1)},\n",
    "    100: {\"train\": np.array(0.0), \"valid\": np.array(0.0), \"test\": np.array(0.0)},\n",
    "}\n",
    "\n",
    "to_update_dyn = TrainingDynamics(_data=to_update)\n",
    "to_update_registry = LossRegistry(\n",
    "    _losses={\n",
    "        \"recon_loss\": to_update_dyn,\n",
    "        \"var_loss\": to_update_dyn,\n",
    "        \"more_loss\": TrainingDynamics(_data={}),\n",
    "    }\n",
    ")\n",
    "to_update_result = Result(sub_losses=to_update_registry)\n",
    "\n",
    "\n",
    "update_with_dyn = TrainingDynamics(_data=update_with)\n",
    "update_with_registry = LossRegistry(\n",
    "    _losses={\n",
    "        \"recon_loss\": update_with_dyn,\n",
    "        \"var_loss\": TrainingDynamics(_data={}),\n",
    "        \"other_loss\": TrainingDynamics(_data={}),\n",
    "    }\n",
    ")\n",
    "update_with_result = Result(sub_losses=update_with_registry)\n",
    "to_update_result.update(update_with_result)\n",
    "after_update = dict(\n",
    "    sorted(to_update_result.sub_losses.get(key=\"recon_loss\").get().items())\n",
    ")\n",
    "expected_recon_dyn = TrainingDynamics(_data=expected_result)\n",
    "expected_varloss_dyn = TrainingDynamics(_data=to_update)\n",
    "expected_moreloss_dyn = TrainingDynamics(_data={})\n",
    "expected_other_dyn = TrainingDynamics(_data={})\n",
    "expected_loss_registry = LossRegistry(\n",
    "    _losses={\n",
    "        \"recon_loss\": expected_recon_dyn,\n",
    "        \"var_loss\": expected_varloss_dyn,\n",
    "        \"more_loss\": expected_moreloss_dyn,\n",
    "        \"other_loss\": expected_other_dyn,\n",
    "    }\n",
    ")\n",
    "expected_result = Result(sub_losses=expected_loss_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_loss\n",
      "<class 'dict'>\n",
      "var_loss\n",
      "<class 'dict'>\n",
      "more_loss\n",
      "<class 'dict'>\n",
      "other_loss\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "to_update_result.sub_losses._losses\n",
    "for lossname, dynamics in expected_result.sub_losses.losses():\n",
    "    print(lossname)\n",
    "    print(type(dynamics._data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_loss\n",
      "{0: {'train': array(0.1), 'valid': array(0.2), 'test': array(0.3)}, 1: {'train': array(0.4), 'valid': array(0.5), 'test': array(0.6)}, 2: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}, 3: {'valid': array(0.8), 'train': array(0.7)}, 4: {'valid': array(1.), 'test': array(1.1), 'train': array(0.9)}, 5: {'valid': array(0.22), 'test': array(0.), 'train': array(0.12)}, 6: {'train': array(0.), 'valid': array(0.32), 'test': array(0.42)}, 7: {'train': array(0.1)}, 100: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}}\n",
      "var_loss\n",
      "{0: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}, 2: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}, 5: {'valid': array(0.), 'test': array(0.)}, 6: {'train': array(0.)}, 7: {'train': array(0)}, 100: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}}\n",
      "more_loss\n",
      "{}\n",
      "other_loss\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for lossname, dynamics in to_update_result.sub_losses.losses():\n",
    "    print(lossname)\n",
    "    print(dynamics.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_loss\n",
      "{0: {'train': array(0.1), 'valid': array(0.2), 'test': array(0.3)}, 1: {'train': array(0.4), 'valid': array(0.5), 'test': array(0.6)}, 2: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}, 3: {'train': array(0.7), 'valid': array(0.8)}, 4: {'train': array(0.9), 'valid': array(1.), 'test': array(1.1)}, 5: {'train': array(0.12), 'valid': array(0.22), 'test': array(0.)}, 6: {'train': array(0.), 'valid': array(0.32), 'test': array(0.42)}, 7: {'train': array(0.1)}, 100: {'train': array(0.), 'valid': array(0.), 'test': array(0.)}}\n",
      "var_loss\n",
      "{0: {'train': 0.0, 'valid': 0.0, 'test': 0.0}, 2: {'train': 0.0, 'valid': 0.0, 'test': 0.0}, 3: {}, 4: None, 5: {'train': None, 'valid': 0.0, 'test': 0.0}, 6: {'train': 0.0}, 7: {'train': 0}, 100: {'train': 0.0, 'valid': 0.0, 'test': 0.0}}\n",
      "more_loss\n",
      "{}\n",
      "other_loss\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for lossname, dynamics in expected_result.sub_losses.losses():\n",
    "    print(lossname)\n",
    "    print(dynamics.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'train': array(0.26), 'valid': array(0.16), 'test': array(0.36)},\n",
       " 2: {'train': 0.0, 'valid': 0.0, 'test': 0.0},\n",
       " 100: {'train': 0.0, 'valid': 0.0, 'test': 0.0},\n",
       " 1: {'valid': array(0.36), 'train': array(0.46)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(filled_result.sub_losses._losses[\"var_loss\"].get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetContainer(train=<autoencodix.data._numeric_dataset.NumericDataset object at 0x15ff96b30>, valid=<autoencodix.data._numeric_dataset.NumericDataset object at 0x15ff96bc0>, test=<autoencodix.data._numeric_dataset.NumericDataset object at 0x15ff96e00>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty does not overwrite anything\n",
    "result.update(empty_result)\n",
    "result.losses.get()\n",
    "result.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'valid': array(0.1), 'train': array(0.2), 'test': array(0.3)},\n",
       " 1: {'valid': array(0.4), 'train': array(0.5), 'test': array(0.6)},\n",
       " 2: {'valid': array(0.7), 'train': array(0.8), 'test': array(0.9)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# case one update empty result\n",
    "# with: - empty result, - sample result1, - sample result2\n",
    "empty_result.update(other=sample_result1)\n",
    "empty_result.sub_losses._losses[\"recon_loss\"].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_result.update(other=sample_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case two update filled result\n",
    "# with: - filled result, - sample result1, - sample result2, empty result\n",
    "filled_result.update(other=sample_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_losses == updated_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossRegistry(_losses={'recon_loss': TrainingDynamics(), 'var_loss': TrainingDynamics()})\n"
     ]
    }
   ],
   "source": [
    "updated_losses = result.sub_losses\n",
    "print(updated_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_loss: TrainingDynamics()\n",
      "{0: {'train': array(0.44560597), 'valid': array(0.24305786)}, 1: {'train': array(0.40050308), 'valid': array(0.23968849)}, 2: {'train': array(0.39850321), 'valid': array(0.2438124)}}\n",
      "var_loss: TrainingDynamics()\n",
      "{0: {'train': array(0.03078574), 'valid': array(0.00519827)}, 1: {'train': array(0.02884311), 'valid': array(0.00536202)}, 2: {'train': array(0.02645038), 'valid': array(0.00561051)}}\n"
     ]
    }
   ],
   "source": [
    "for name, loss in updated_losses.losses():\n",
    "    print(f\"{name}: {loss}\")\n",
    "    print(loss.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_FabricModule(\n",
       "  (_forward_module): VarixArchitecture(\n",
       "    (_encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (_decoder): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=10, bias=True)\n",
       "    )\n",
       "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (_original_module): VarixArchitecture(\n",
       "    (_encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (_decoder): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=10, bias=True)\n",
       "    )\n",
       "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varix._trainer._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DefaultConfig Configuration Parameters:\n",
      "--------------------------------------------------\n",
      "\n",
      "latent_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 16\n",
      "  Description: Dimension of the latent space\n",
      "\n",
      "n_layers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of layers in encoder/decoder\n",
      "\n",
      "enc_factor:\n",
      "  Type: <class 'int'>\n",
      "  Default: 4\n",
      "  Description: Scaling factor for encoder dimensions\n",
      "\n",
      "input_dim:\n",
      "  Type: <class 'int'>\n",
      "  Default: 10000\n",
      "  Description: Input dimension\n",
      "\n",
      "drop_p:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Dropout probability\n",
      "\n",
      "learning_rate:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.001\n",
      "  Description: Learning rate for optimization\n",
      "\n",
      "batch_size:\n",
      "  Type: <class 'int'>\n",
      "  Default: 32\n",
      "  Description: Number of samples per batch\n",
      "\n",
      "epochs:\n",
      "  Type: <class 'int'>\n",
      "  Default: 3\n",
      "  Description: Number of training epochs\n",
      "\n",
      "weight_decay:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.01\n",
      "  Description: L2 regularization factor\n",
      "\n",
      "reconstruction_loss:\n",
      "  Type: typing.Literal['mse', 'bce']\n",
      "  Default: mse\n",
      "  Description: Type of reconstruction loss\n",
      "\n",
      "default_vae_loss:\n",
      "  Type: typing.Literal['kl', 'mmd']\n",
      "  Default: kl\n",
      "  Description: Type of VAE loss\n",
      "\n",
      "loss_reduction:\n",
      "  Type: typing.Literal['sum', 'mean']\n",
      "  Default: mean\n",
      "  Description: Loss reduction in PyTorch i.e in torch.nn.functional.binary_cross_entropy_with_logits(reduction=loss_reduction)\n",
      "\n",
      "beta:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Beta weighting factor for VAE loss\n",
      "\n",
      "min_samples_per_split:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Minimum number of samples per split\n",
      "\n",
      "device:\n",
      "  Type: typing.Literal['cpu', 'cuda', 'gpu', 'tpu', 'mps', 'auto']\n",
      "  Default: auto\n",
      "  Description: Device to use\n",
      "\n",
      "n_gpus:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Number of GPUs to use\n",
      "\n",
      "n_workers:\n",
      "  Type: <class 'int'>\n",
      "  Default: 2\n",
      "  Description: Number of data loading workers\n",
      "\n",
      "checkpoint_interval:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Interval for saving checkpoints\n",
      "\n",
      "float_precision:\n",
      "  Type: typing.Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16']\n",
      "  Default: 32\n",
      "  Description: Floating point precision\n",
      "\n",
      "gpu_strategy:\n",
      "  Type: typing.Literal['auto', 'dp', 'ddp', 'ddp_spawn', 'ddp_find_unused_parameters_true', 'xla', 'deepspeed', 'fsdp']\n",
      "  Default: auto\n",
      "  Description: GPU parallelization strategy\n",
      "\n",
      "train_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.7\n",
      "  Description: Ratio of data for training\n",
      "\n",
      "test_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.2\n",
      "  Description: Ratio of data for testing\n",
      "\n",
      "valid_ratio:\n",
      "  Type: <class 'float'>\n",
      "  Default: 0.1\n",
      "  Description: Ratio of data for validation\n",
      "\n",
      "reproducible:\n",
      "  Type: <class 'bool'>\n",
      "  Default: True\n",
      "  Description: Whether to ensure reproducibility\n",
      "\n",
      "global_seed:\n",
      "  Type: <class 'int'>\n",
      "  Default: 1\n",
      "  Description: Global random seed\n"
     ]
    }
   ],
   "source": [
    "DefaultConfig().print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = DefaultConfig()\n",
    "data_info.n_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model architecture layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_FabricModule(\n",
       "  (_forward_module): VarixArchitecture(\n",
       "    (_encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (_decoder): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=10, bias=True)\n",
       "    )\n",
       "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (_original_module): VarixArchitecture(\n",
       "    (_encoder): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (_decoder): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Dropout(p=0.1, inplace=False)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=10, bias=True)\n",
       "    )\n",
       "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varix._trainer._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = DefaultConfig()\n",
    "data_info.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n",
      "[100, 50, 25, 12, 2]\n",
      "Epoch: 0, Loss: 0.5027862191200256\n",
      "_FabricModule(\n",
      "  (_forward_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=12, out_features=2, bias=True)\n",
      "    (_logvar): Linear(in_features=12, out_features=2, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "      (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=50, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=25, out_features=12, bias=True)\n",
      "      (9): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Dropout(p=0.1, inplace=False)\n",
      "      (11): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=12, bias=True)\n",
      "      (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=12, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=25, out_features=50, bias=True)\n",
      "      (9): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Dropout(p=0.1, inplace=False)\n",
      "      (11): ReLU()\n",
      "      (12): Linear(in_features=50, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_original_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=12, out_features=2, bias=True)\n",
      "    (_logvar): Linear(in_features=12, out_features=2, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "      (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=50, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=25, out_features=12, bias=True)\n",
      "      (9): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Dropout(p=0.1, inplace=False)\n",
      "      (11): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=12, bias=True)\n",
      "      (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=12, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=25, out_features=50, bias=True)\n",
      "      (9): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Dropout(p=0.1, inplace=False)\n",
      "      (11): ReLU()\n",
      "      (12): Linear(in_features=50, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ENCODER FACTOR: 1\n",
      "cpu not relevant here\n",
      "[100, 100, 100, 16]\n",
      "Epoch: 0, Loss: 0.5166383385658264\n",
      "_FabricModule(\n",
      "  (_forward_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=100, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=100, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=100, bias=True)\n",
      "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_original_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=100, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=100, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=100, bias=True)\n",
      "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ENCODER FACTOR: 2\n",
      "cpu not relevant here\n",
      "[100, 50, 25, 16]\n",
      "Epoch: 0, Loss: 0.46474137902259827\n",
      "_FabricModule(\n",
      "  (_forward_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=25, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=25, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "      (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=50, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=25, bias=True)\n",
      "      (1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=25, out_features=50, bias=True)\n",
      "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=50, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_original_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=25, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=25, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "      (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=50, out_features=25, bias=True)\n",
      "      (5): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=25, bias=True)\n",
      "      (1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=25, out_features=50, bias=True)\n",
      "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=50, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ENCODER FACTOR: 3\n",
      "cpu not relevant here\n",
      "[100, 33, 16, 16]\n",
      "Epoch: 0, Loss: 0.5135508179664612\n",
      "_FabricModule(\n",
      "  (_forward_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=33, bias=True)\n",
      "      (1): BatchNorm1d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=33, out_features=16, bias=True)\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=16, out_features=33, bias=True)\n",
      "      (5): BatchNorm1d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=33, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_original_module): VarixArchitecture(\n",
      "    (_mu): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (_logvar): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=33, bias=True)\n",
      "      (1): BatchNorm1d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=33, out_features=16, bias=True)\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=16, out_features=33, bias=True)\n",
      "      (5): BatchNorm1d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=33, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from autoencodix.trainers._general_trainer import GeneralTrainer\n",
    "import autoencodix as acx\n",
    "from autoencodix.utils.default_config import DefaultConfig\n",
    "import numpy as np\n",
    "\n",
    "sample_data = np.random.rand(10, 100)\n",
    "\n",
    "varix = acx.Varix(\n",
    "    preprocessed_data=sample_data,\n",
    "    config=DefaultConfig(n_layers=3, epochs=1, enc_factor=2, latent_dim=2),\n",
    ")\n",
    "varix.preprocess()\n",
    "varix.fit()\n",
    "print(varix._trainer._model)\n",
    "for enc_factor in [1, 2, 3]:\n",
    "    print(f\"ENCODER FACTOR: {enc_factor}\")\n",
    "    varix = acx.Varix(\n",
    "        preprocessed_data=sample_data,\n",
    "        config=DefaultConfig(n_layers=2, epochs=1, enc_factor=enc_factor),\n",
    "    )\n",
    "    varix.preprocess()\n",
    "    varix.fit()\n",
    "    print(varix._trainer._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(varix._trainer._model._decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "empty = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu not relevant here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5317338109016418\n",
      "_FabricModule(\n",
      "  (_forward_module): VanillixArchitecture(\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=16, bias=True)\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_original_module): VanillixArchitecture(\n",
      "    (_encoder): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=16, bias=True)\n",
      "    )\n",
      "    (_decoder): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "van = acx.Vanillix(data=sample_data, config=DefaultConfig(n_layers=0, epochs=1))\n",
    "van.preprocess()\n",
    "van.fit()\n",
    "print(van._trainer._model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate small test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Select random samples\n",
    "samples = bulk_anndata.obs[\"PATIENT_ID\"]\n",
    "random_samples = np.random.choice(samples, 10)\n",
    "print(random_samples)\n",
    "\n",
    "# Create boolean mask for filtering\n",
    "sample_mask = bulk_anndata.obs[\"PATIENT_ID\"].isin(random_samples)\n",
    "\n",
    "# Subset using the boolean mask\n",
    "sample_clin = bulk_anndata.obs[sample_mask]\n",
    "sample_rna = bulk_anndata.obsm[\"RNA\"][sample_mask]\n",
    "sample_meth = bulk_anndata.obsm[\"METHYLATION\"][sample_mask]\n",
    "\n",
    "# Rest of the code for saving files\n",
    "filte_types = [\"csv\", \"tsv\", \"parquet\"]\n",
    "sample_data = {\"RNA\": sample_rna, \"METH\": sample_meth, \"CLINICAL\": sample_clin}\n",
    "outdir = os.path.join(\"data/raw/mini/bulk\")\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "for ext in filte_types:\n",
    "    if ext == \"parquet\":\n",
    "        pd.DataFrame(sample_data[\"RNA\"]).to_parquet(\n",
    "            os.path.join(outdir, f\"rna_sample_data.{ext}\")\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"METH\"]).to_parquet(\n",
    "            os.path.join(outdir, f\"meth_sample_data.{ext}\")\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"CLINICAL\"]).to_parquet(\n",
    "            os.path.join(outdir, f\"clinical_sample_data.{ext}\")\n",
    "        )\n",
    "    if ext == \"csv\":\n",
    "        pd.DataFrame(sample_data[\"RNA\"]).to_csv(\n",
    "            os.path.join(outdir, f\"rna_sample_data.{ext}\")\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"METH\"]).to_csv(\n",
    "            os.path.join(outdir, f\"meth_sample_data.{ext}\")\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"CLINICAL\"]).to_csv(\n",
    "            os.path.join(outdir, f\"clinical_sample_data.{ext}\")\n",
    "        )\n",
    "    if ext == \"tsv\":\n",
    "        pd.DataFrame(sample_data[\"RNA\"]).to_csv(\n",
    "            os.path.join(outdir, f\"rna_sample_data.{ext}\"), sep=\"\\t\"\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"METH\"]).to_csv(\n",
    "            os.path.join(outdir, f\"meth_sample_data.{ext}\"), sep=\"\\t\"\n",
    "        )\n",
    "        pd.DataFrame(sample_data[\"CLINICAL\"]).to_csv(\n",
    "            os.path.join(outdir, f\"clinical_sample_data.{ext}\"), sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencodix.utils import DefaultConfig\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "scconfig = DefaultConfig.model_validate(\n",
    "    yaml.safe_load(Path(\"scconfig.yaml\").read_text())\n",
    ")\n",
    "from autoencodix.utils._screader import SingleCellDataReader\n",
    "\n",
    "screader = SingleCellDataReader()\n",
    "adata, scconfig = screader.read_data(config=scconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 45549 × 17425\n",
      "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid', 'RNA_author_cell_type', 'RNA_age_group', 'RNA_donor_id', 'RNA_nCount_RNA', 'RNA_nFeature_RNA', 'RNA_nCount_ATAC', 'RNA_nFeature_ATAC', 'RNA_TSS_percentile', 'RNA_nucleosome_signal', 'RNA_percent_mt', 'RNA_assay_ontology_term_id', 'RNA_cell_type_ontology_term_id', 'RNA_development_stage_ontology_term_id', 'RNA_disease_ontology_term_id', 'RNA_self_reported_ethnicity_ontology_term_id', 'RNA_organism_ontology_term_id', 'RNA_sex_ontology_term_id', 'RNA_tissue_ontology_term_id', 'RNA_suspension_type', 'RNA_is_primary_data', 'RNA_batch', 'RNA_tissue_type', 'RNA_cell_type', 'RNA_assay', 'RNA_disease', 'RNA_organism', 'RNA_sex', 'RNA_tissue', 'RNA_self_reported_ethnicity', 'RNA_development_stage', 'RNA_observation_joinid', 'METH_author_cell_type', 'METH_age_group', 'METH_donor_id', 'METH_nCount_RNA', 'METH_nFeature_RNA', 'METH_nCount_ATAC', 'METH_nFeature_ATAC', 'METH_TSS_percentile', 'METH_nucleosome_signal', 'METH_percent_mt', 'METH_assay_ontology_term_id', 'METH_cell_type_ontology_term_id', 'METH_development_stage_ontology_term_id', 'METH_disease_ontology_term_id', 'METH_self_reported_ethnicity_ontology_term_id', 'METH_organism_ontology_term_id', 'METH_sex_ontology_term_id', 'METH_tissue_ontology_term_id', 'METH_suspension_type', 'METH_is_primary_data', 'METH_batch', 'METH_tissue_type', 'METH_cell_type', 'METH_assay', 'METH_disease', 'METH_organism', 'METH_sex', 'METH_tissue', 'METH_self_reported_ethnicity', 'METH_development_stage', 'METH_observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
      "    layers: 'RNA', 'METH'\n"
     ]
    }
   ],
   "source": [
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected donors: ['Adult2' 'LaFet1' 'Child1' 'Child2' 'Inf1' 'Adol1' 'EaFet1' 'LaFet2'\n",
      " 'EaFet2' 'Adol2']\n",
      "\n",
      "RNA file info:\n",
      "Number of cells: 10\n",
      "Number of features: 10\n",
      "\n",
      "METH file info:\n",
      "Number of cells: 10\n",
      "Number of features: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import os\n",
    "\n",
    "sc_anndata = adata\n",
    "# Get unique donor IDs and select 10 random ones\n",
    "unique_donors = sc_anndata.obs[\"donor_id\"].unique()\n",
    "random_donors = np.random.choice(unique_donors, 10, replace=False)\n",
    "\n",
    "# Create mask for the selected donors\n",
    "donor_mask = sc_anndata.obs[\"donor_id\"].isin(random_donors)\n",
    "\n",
    "# Select 10 random cells and 10 random features\n",
    "random_cells = np.random.choice(sc_anndata[donor_mask].obs_names, 10, replace=False)\n",
    "random_features = np.random.choice(sc_anndata.var_names, 10, replace=False)\n",
    "\n",
    "# Create RNA anndata\n",
    "rna_adata = ad.AnnData(\n",
    "    X=sc_anndata[random_cells, :][:, random_features].layers[\"RNA\"],\n",
    "    obs=sc_anndata[random_cells].obs,\n",
    "    var=sc_anndata[:, random_features].var,\n",
    "    uns=sc_anndata.uns,\n",
    ")\n",
    "if \"X_umap\" in sc_anndata.obsm:\n",
    "    rna_adata.obsm[\"X_umap\"] = sc_anndata[random_cells].obsm[\"X_umap\"]\n",
    "\n",
    "# Create METH anndata\n",
    "meth_adata = ad.AnnData(\n",
    "    X=sc_anndata[random_cells, :][:, random_features].layers[\"METH\"],\n",
    "    obs=sc_anndata[random_cells].obs,\n",
    "    var=sc_anndata[:, random_features].var,\n",
    "    uns=sc_anndata.uns,\n",
    ")\n",
    "if \"X_umap\" in sc_anndata.obsm:\n",
    "    meth_adata.obsm[\"X_umap\"] = sc_anndata[random_cells].obsm[\"X_umap\"]\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "outdir = \"data/raw/mini/single_cell\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Save the files\n",
    "rna_adata.write_h5ad(os.path.join(outdir, \"rna_sample_data.h5ad\"))\n",
    "meth_adata.write_h5ad(os.path.join(outdir, \"meth_sample_data.h5ad\"))\n",
    "\n",
    "# Print some information about the saved files\n",
    "print(f\"Selected donors: {random_donors}\")\n",
    "print(f\"\\nRNA file info:\")\n",
    "print(f\"Number of cells: {rna_adata.n_obs}\")\n",
    "print(f\"Number of features: {rna_adata.n_vars}\")\n",
    "print(f\"\\nMETH file info:\")\n",
    "print(f\"Number of cells: {meth_adata.n_obs}\")\n",
    "print(f\"Number of features: {meth_adata.n_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 55)\n",
      "0    TCGA-A5-A0GX-01\n",
      "1    TCGA-AB-2815-03\n",
      "2    TCGA-VN-A943-01\n",
      "3    TCGA-D7-6527-01\n",
      "4    TCGA-AA-3532-01\n",
      "5    TCGA-CA-6715-01\n",
      "6    TCGA-P5-A737-01\n",
      "7    TCGA-WA-A7H4-01\n",
      "8    TCGA-DV-5575-01\n",
      "9    TCGA-HC-A76X-01\n",
      "Name: SAMPLE_ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get samples\n",
    "clin_path = os.path.join(\"data/raw/mini/bulk/clinical_sample_data.csv\")\n",
    "all_img = os.path.join(\"data/raw/images/tcga_fake\")\n",
    "clin_df = pd.read_csv(clin_path)\n",
    "print(clin_df.shape)\n",
    "samples = clin_df[\"SAMPLE_ID\"]\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.read_csv(os.path.join(\"data/raw/tcga_mappings.txt\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ids</th>\n",
       "      <th>img_paths</th>\n",
       "      <th>extra_class_labels</th>\n",
       "      <th>CANCER_TYPE_ACRONYM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-05-4244-01</td>\n",
       "      <td>0_label_1.png</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-05-4249-01</td>\n",
       "      <td>1_label_1.png</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-05-4250-01</td>\n",
       "      <td>2_label_1.png</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-05-4382-01</td>\n",
       "      <td>3_label_1.png</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-05-4384-01</td>\n",
       "      <td>4_label_1.png</td>\n",
       "      <td>Non-Small Cell Lung Cancer</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_ids      img_paths          extra_class_labels  \\\n",
       "0  TCGA-05-4244-01  0_label_1.png  Non-Small Cell Lung Cancer   \n",
       "1  TCGA-05-4249-01  1_label_1.png  Non-Small Cell Lung Cancer   \n",
       "2  TCGA-05-4250-01  2_label_1.png  Non-Small Cell Lung Cancer   \n",
       "3  TCGA-05-4382-01  3_label_1.png  Non-Small Cell Lung Cancer   \n",
       "4  TCGA-05-4384-01  4_label_1.png  Non-Small Cell Lung Cancer   \n",
       "\n",
       "  CANCER_TYPE_ACRONYM  \n",
       "0                LUAD  \n",
       "1                LUAD  \n",
       "2                LUAD  \n",
       "3                LUAD  \n",
       "4                LUAD  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sample_ids         img_paths  extra_class_labels  \\\n",
      "522   TCGA-A5-A0GX-01   591_label_3.png  Endometrial Cancer   \n",
      "1209  TCGA-AA-3532-01  1331_label_2.png   Colorectal Cancer   \n",
      "1358  TCGA-CA-6715-01  1516_label_2.png   Colorectal Cancer   \n",
      "\n",
      "     CANCER_TYPE_ACRONYM  \n",
      "522                 UCEC  \n",
      "1209                COAD  \n",
      "1358                COAD  \n"
     ]
    }
   ],
   "source": [
    "subset_mappings = mappings[mappings[\"sample_ids\"].isin(samples)]\n",
    "print(subset_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_mappings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = subset_mappings[\"img_paths\"].to_list()\n",
    "base_path = \"data/raw/images/tcga_fake\"\n",
    "to_path = \"data/raw/mini/img\"\n",
    "import shutil\n",
    "\n",
    "for p in img_paths:\n",
    "    shutil.copy(os.path.join(base_path, p), to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_mappings.to_csv(\"data/raw/min\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1111_label_2.png' '496_label_1.png' '2039_label_4.png'\n",
      " '2366_label_0.png' '3342_label_0.png' '1719_label_4.png'\n",
      " '3163_label_0.png' '2511_label_0.png' '3506_label_1.png'\n",
      " '1937_label_4.png']\n"
     ]
    }
   ],
   "source": [
    "all_imgs = os.listdir(\"data/raw/images/tcga_fake\")\n",
    "# to the mapping manuall, so just chose 10 random images\n",
    "sample_imgs = np.random.choice(all_imgs, 10, replace=False)\n",
    "print(sample_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           img_path       sample_ids\n",
      "0  1111_label_2.png  TCGA-A5-A0GX-01\n",
      "1   496_label_1.png  TCGA-AB-2815-03\n",
      "2  2039_label_4.png  TCGA-VN-A943-01\n",
      "3  2366_label_0.png  TCGA-D7-6527-01\n",
      "4  3342_label_0.png  TCGA-AA-3532-01\n",
      "5  1719_label_4.png  TCGA-CA-6715-01\n",
      "6  3163_label_0.png  TCGA-P5-A737-01\n",
      "7  2511_label_0.png  TCGA-WA-A7H4-01\n",
      "8  3506_label_1.png  TCGA-DV-5575-01\n",
      "9  1937_label_4.png  TCGA-HC-A76X-01\n"
     ]
    }
   ],
   "source": [
    "# map label to cancer type\n",
    "df = pd.DataFrame({\"img_path\": sample_imgs, \"sample_ids\": samples})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           img_path       sample_ids extra_class_labels\n",
      "0  1111_label_2.png  TCGA-A5-A0GX-01                  2\n",
      "1   496_label_1.png  TCGA-AB-2815-03                  1\n",
      "2  2039_label_4.png  TCGA-VN-A943-01                  4\n",
      "3  2366_label_0.png  TCGA-D7-6527-01                  0\n",
      "4  3342_label_0.png  TCGA-AA-3532-01                  0\n",
      "5  1719_label_4.png  TCGA-CA-6715-01                  4\n",
      "6  3163_label_0.png  TCGA-P5-A737-01                  0\n",
      "7  2511_label_0.png  TCGA-WA-A7H4-01                  0\n",
      "8  3506_label_1.png  TCGA-DV-5575-01                  1\n",
      "9  1937_label_4.png  TCGA-HC-A76X-01                  4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "           img_path       sample_ids\n",
    "0  1111_label_2.png  TCGA-A5-A0GX-01\n",
    "1   496_label_1.png  TCGA-AB-2815-03\n",
    "\"\"\"\n",
    "\n",
    "# map the number in the image file e.g 1111_label_2.png to => 2 to the column \"extra_class_labels\"\n",
    "\n",
    "df[\"extra_class_labels\"] = df[\"img_path\"].apply(\n",
    "    lambda x: x.split(\"_\")[-1].split(\".\")[0]\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>ONCOTREE_CODE</th>\n",
       "      <th>CANCER_TYPE</th>\n",
       "      <th>CANCER_TYPE_DETAILED</th>\n",
       "      <th>TUMOR_TYPE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>TISSUE_PROSPECTIVE_COLLECTION_INDICATOR</th>\n",
       "      <th>TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR</th>\n",
       "      <th>TISSUE_SOURCE_SITE_CODE</th>\n",
       "      <th>...</th>\n",
       "      <th>IN_PANCANPATHWAYS_FREEZE</th>\n",
       "      <th>OS_STATUS</th>\n",
       "      <th>OS_MONTHS</th>\n",
       "      <th>DSS_STATUS</th>\n",
       "      <th>DSS_MONTHS</th>\n",
       "      <th>DFS_STATUS</th>\n",
       "      <th>DFS_MONTHS</th>\n",
       "      <th>PFS_STATUS</th>\n",
       "      <th>PFS_MONTHS</th>\n",
       "      <th>AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-A5-A0GX-01</td>\n",
       "      <td>TCGA-A5-A0GX</td>\n",
       "      <td>UEC</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>Uterine Endometrioid Carcinoma</td>\n",
       "      <td>Endometrioid Endometrial Adenocarcinoma</td>\n",
       "      <td>G2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A5</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0:LIVING</td>\n",
       "      <td>68.645823</td>\n",
       "      <td>0:ALIVE OR DEAD TUMOR FREE</td>\n",
       "      <td>68.645823</td>\n",
       "      <td>0:DiseaseFree</td>\n",
       "      <td>68.645823</td>\n",
       "      <td>0:CENSORED</td>\n",
       "      <td>68.645823</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-AB-2815-03</td>\n",
       "      <td>TCGA-AB-2815</td>\n",
       "      <td>AML</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>Acute Myeloid Leukemia</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>AB</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1:DECEASED</td>\n",
       "      <td>27.024361</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-VN-A943-01</td>\n",
       "      <td>TCGA-VN-A943</td>\n",
       "      <td>PRAD</td>\n",
       "      <td>Prostate Cancer</td>\n",
       "      <td>Prostate Adenocarcinoma</td>\n",
       "      <td>Prostate Adenocarcinoma, Acinar Type</td>\n",
       "      <td>unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>VN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0:LIVING</td>\n",
       "      <td>16.306671</td>\n",
       "      <td>0:ALIVE OR DEAD TUMOR FREE</td>\n",
       "      <td>16.306671</td>\n",
       "      <td>0:DiseaseFree</td>\n",
       "      <td>16.306671</td>\n",
       "      <td>0:CENSORED</td>\n",
       "      <td>16.306671</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-D7-6527-01</td>\n",
       "      <td>TCGA-D7-6527</td>\n",
       "      <td>PSTAD</td>\n",
       "      <td>Esophagogastric Adenocarcinoma</td>\n",
       "      <td>Papillary Stomach Adenocarcinoma</td>\n",
       "      <td>Stomach Intestinal Adenocarcinoma, Papillary Type</td>\n",
       "      <td>G2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>D7</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1:DECEASED</td>\n",
       "      <td>10.257422</td>\n",
       "      <td>1:DEAD WITH TUMOR</td>\n",
       "      <td>10.257422</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:PROGRESSION</td>\n",
       "      <td>2.465726</td>\n",
       "      <td>STAGE II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-AA-3532-01</td>\n",
       "      <td>TCGA-AA-3532</td>\n",
       "      <td>COAD</td>\n",
       "      <td>Colorectal Cancer</td>\n",
       "      <td>Colon Adenocarcinoma</td>\n",
       "      <td>Colon Adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>0:LIVING</td>\n",
       "      <td>28.996942</td>\n",
       "      <td>0:ALIVE OR DEAD TUMOR FREE</td>\n",
       "      <td>28.996942</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:CENSORED</td>\n",
       "      <td>28.996942</td>\n",
       "      <td>STAGE II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SAMPLE_ID    PATIENT_ID ONCOTREE_CODE  \\\n",
       "0  TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC   \n",
       "1  TCGA-AB-2815-03  TCGA-AB-2815           AML   \n",
       "2  TCGA-VN-A943-01  TCGA-VN-A943          PRAD   \n",
       "3  TCGA-D7-6527-01  TCGA-D7-6527         PSTAD   \n",
       "4  TCGA-AA-3532-01  TCGA-AA-3532          COAD   \n",
       "\n",
       "                      CANCER_TYPE              CANCER_TYPE_DETAILED  \\\n",
       "0              Endometrial Cancer    Uterine Endometrioid Carcinoma   \n",
       "1                        Leukemia            Acute Myeloid Leukemia   \n",
       "2                 Prostate Cancer           Prostate Adenocarcinoma   \n",
       "3  Esophagogastric Adenocarcinoma  Papillary Stomach Adenocarcinoma   \n",
       "4               Colorectal Cancer              Colon Adenocarcinoma   \n",
       "\n",
       "                                          TUMOR_TYPE    GRADE  \\\n",
       "0            Endometrioid Endometrial Adenocarcinoma       G2   \n",
       "1                             Acute Myeloid Leukemia  unknown   \n",
       "2               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
       "3  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
       "4                               Colon Adenocarcinoma  unknown   \n",
       "\n",
       "  TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
       "0                                      No   \n",
       "1                                 unknown   \n",
       "2                                      No   \n",
       "3                                     Yes   \n",
       "4                                      No   \n",
       "\n",
       "  TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR TISSUE_SOURCE_SITE_CODE  ...  \\\n",
       "0                                       Yes                      A5  ...   \n",
       "1                                   unknown                      AB  ...   \n",
       "2                                       Yes                      VN  ...   \n",
       "3                                        No                      D7  ...   \n",
       "4                                       Yes                      AA  ...   \n",
       "\n",
       "  IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS                  DSS_STATUS  \\\n",
       "0                      Yes    0:LIVING  68.645823  0:ALIVE OR DEAD TUMOR FREE   \n",
       "1                      Yes  1:DECEASED  27.024361                     unknown   \n",
       "2                      Yes    0:LIVING  16.306671  0:ALIVE OR DEAD TUMOR FREE   \n",
       "3                      Yes  1:DECEASED  10.257422           1:DEAD WITH TUMOR   \n",
       "4                       No    0:LIVING  28.996942  0:ALIVE OR DEAD TUMOR FREE   \n",
       "\n",
       "   DSS_MONTHS     DFS_STATUS  DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
       "0   68.645823  0:DiseaseFree   68.645823     0:CENSORED  68.645823   \n",
       "1         NaN        unknown         NaN        unknown        NaN   \n",
       "2   16.306671  0:DiseaseFree   16.306671     0:CENSORED  16.306671   \n",
       "3   10.257422        unknown         NaN  1:PROGRESSION   2.465726   \n",
       "4   28.996942        unknown         NaN     0:CENSORED  28.996942   \n",
       "\n",
       "  AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
       "0                           unknown  \n",
       "1                           unknown  \n",
       "2                           unknown  \n",
       "3                          STAGE II  \n",
       "4                          STAGE II  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           img_path       sample_ids extra_class_labels  \\\n",
      "0  1111_label_2.png  TCGA-A5-A0GX-01                  2   \n",
      "1   496_label_1.png  TCGA-AB-2815-03                  1   \n",
      "2  2039_label_4.png  TCGA-VN-A943-01                  4   \n",
      "3  2366_label_0.png  TCGA-D7-6527-01                  0   \n",
      "4  3342_label_0.png  TCGA-AA-3532-01                  0   \n",
      "5  1719_label_4.png  TCGA-CA-6715-01                  4   \n",
      "6  3163_label_0.png  TCGA-P5-A737-01                  0   \n",
      "7  2511_label_0.png  TCGA-WA-A7H4-01                  0   \n",
      "8  3506_label_1.png  TCGA-DV-5575-01                  1   \n",
      "9  1937_label_4.png  TCGA-HC-A76X-01                  4   \n",
      "\n",
      "                      CANCER_TYPE  \n",
      "0              Endometrial Cancer  \n",
      "1                        Leukemia  \n",
      "2                 Prostate Cancer  \n",
      "3  Esophagogastric Adenocarcinoma  \n",
      "4               Colorectal Cancer  \n",
      "5               Colorectal Cancer  \n",
      "6                          Glioma  \n",
      "7            Head and Neck Cancer  \n",
      "8      Renal Clear Cell Carcinoma  \n",
      "9                 Prostate Cancer  \n"
     ]
    }
   ],
   "source": [
    "cancer_types = clin_df[\"CANCER_TYPE\"].unique()\n",
    "class_labels = df[\"extra_class_labels\"].unique()\n",
    "# map the cancer type to the class label\n",
    "class_map = {c: l for c, l in zip(cancer_types, class_labels)}\n",
    "# add column\n",
    "df[\"CANCER_TYPE\"] = df[\"sample_ids\"].apply(\n",
    "    lambda x: clin_df[clin_df[\"SAMPLE_ID\"] == x][\"CANCER_TYPE\"].values[0]\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/raw/mini/tcga_mappings.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': multi_sc: 31884 samples × 49508 features,\n",
       " 'valid': multi_sc: 4555 samples × 49508 features,\n",
       " 'test': multi_sc: 9110 samples × 49508 features}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 45549 × 17425\n",
       "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid', 'RNA_author_cell_type', 'RNA_age_group', 'RNA_donor_id', 'RNA_nCount_RNA', 'RNA_nFeature_RNA', 'RNA_nCount_ATAC', 'RNA_nFeature_ATAC', 'RNA_TSS_percentile', 'RNA_nucleosome_signal', 'RNA_percent_mt', 'RNA_assay_ontology_term_id', 'RNA_cell_type_ontology_term_id', 'RNA_development_stage_ontology_term_id', 'RNA_disease_ontology_term_id', 'RNA_self_reported_ethnicity_ontology_term_id', 'RNA_organism_ontology_term_id', 'RNA_sex_ontology_term_id', 'RNA_tissue_ontology_term_id', 'RNA_suspension_type', 'RNA_is_primary_data', 'RNA_batch', 'RNA_tissue_type', 'RNA_cell_type', 'RNA_assay', 'RNA_disease', 'RNA_organism', 'RNA_sex', 'RNA_tissue', 'RNA_self_reported_ethnicity', 'RNA_development_stage', 'RNA_observation_joinid', 'METH_author_cell_type', 'METH_age_group', 'METH_donor_id', 'METH_nCount_RNA', 'METH_nFeature_RNA', 'METH_nCount_ATAC', 'METH_nFeature_ATAC', 'METH_TSS_percentile', 'METH_nucleosome_signal', 'METH_percent_mt', 'METH_assay_ontology_term_id', 'METH_cell_type_ontology_term_id', 'METH_development_stage_ontology_term_id', 'METH_disease_ontology_term_id', 'METH_self_reported_ethnicity_ontology_term_id', 'METH_organism_ontology_term_id', 'METH_sex_ontology_term_id', 'METH_tissue_ontology_term_id', 'METH_suspension_type', 'METH_is_primary_data', 'METH_batch', 'METH_tissue_type', 'METH_cell_type', 'METH_assay', 'METH_disease', 'METH_organism', 'METH_sex', 'METH_tissue', 'METH_self_reported_ethnicity', 'METH_development_stage', 'METH_observation_joinid'\n",
       "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
       "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
       "    obsm: 'X_joint_wnn_umap', 'X_umap'\n",
       "    layers: 'RNA', 'METH'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10 × 10\n",
       "    obs: 'author_cell_type', 'age_group', 'donor_id', 'nCount_RNA', 'nFeature_RNA', 'nCount_ATAC', 'nFeature_ATAC', 'TSS_percentile', 'nucleosome_signal', 'percent_mt', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data', 'batch', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid', 'RNA_author_cell_type', 'RNA_age_group', 'RNA_donor_id', 'RNA_nCount_RNA', 'RNA_nFeature_RNA', 'RNA_nCount_ATAC', 'RNA_nFeature_ATAC', 'RNA_TSS_percentile', 'RNA_nucleosome_signal', 'RNA_percent_mt', 'RNA_assay_ontology_term_id', 'RNA_cell_type_ontology_term_id', 'RNA_development_stage_ontology_term_id', 'RNA_disease_ontology_term_id', 'RNA_self_reported_ethnicity_ontology_term_id', 'RNA_organism_ontology_term_id', 'RNA_sex_ontology_term_id', 'RNA_tissue_ontology_term_id', 'RNA_suspension_type', 'RNA_is_primary_data', 'RNA_batch', 'RNA_tissue_type', 'RNA_cell_type', 'RNA_assay', 'RNA_disease', 'RNA_organism', 'RNA_sex', 'RNA_tissue', 'RNA_self_reported_ethnicity', 'RNA_development_stage', 'RNA_observation_joinid', 'METH_author_cell_type', 'METH_age_group', 'METH_donor_id', 'METH_nCount_RNA', 'METH_nFeature_RNA', 'METH_nCount_ATAC', 'METH_nFeature_ATAC', 'METH_TSS_percentile', 'METH_nucleosome_signal', 'METH_percent_mt', 'METH_assay_ontology_term_id', 'METH_cell_type_ontology_term_id', 'METH_development_stage_ontology_term_id', 'METH_disease_ontology_term_id', 'METH_self_reported_ethnicity_ontology_term_id', 'METH_organism_ontology_term_id', 'METH_sex_ontology_term_id', 'METH_tissue_ontology_term_id', 'METH_suspension_type', 'METH_is_primary_data', 'METH_batch', 'METH_tissue_type', 'METH_cell_type', 'METH_assay', 'METH_disease', 'METH_organism', 'METH_sex', 'METH_tissue', 'METH_self_reported_ethnicity', 'METH_development_stage', 'METH_observation_joinid'\n",
       "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
       "    uns: 'batch_condition', 'citation', 'schema_reference', 'schema_version', 'title'\n",
       "    obsm: 'X_umap'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_cell_type</th>\n",
       "      <th>age_group</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>nCount_ATAC</th>\n",
       "      <th>nFeature_ATAC</th>\n",
       "      <th>TSS_percentile</th>\n",
       "      <th>nucleosome_signal</th>\n",
       "      <th>percent_mt</th>\n",
       "      <th>...</th>\n",
       "      <th>METH_tissue_type</th>\n",
       "      <th>METH_cell_type</th>\n",
       "      <th>METH_assay</th>\n",
       "      <th>METH_disease</th>\n",
       "      <th>METH_organism</th>\n",
       "      <th>METH_sex</th>\n",
       "      <th>METH_tissue</th>\n",
       "      <th>METH_self_reported_ethnicity</th>\n",
       "      <th>METH_development_stage</th>\n",
       "      <th>METH_observation_joinid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8_AAGGATCCAGAGAGCC-1</th>\n",
       "      <td>EN-fetal-late</td>\n",
       "      <td>late fetal</td>\n",
       "      <td>LaFet2</td>\n",
       "      <td>3518</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.127075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>glutamatergic neuron</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>cortical plate</td>\n",
       "      <td>unknown</td>\n",
       "      <td>24th week post-fertilization stage</td>\n",
       "      <td>e;x33fbL}(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150656_CGGGCTTAGGCGCACT-1</th>\n",
       "      <td>OPC</td>\n",
       "      <td>adulthood</td>\n",
       "      <td>Adult2</td>\n",
       "      <td>778</td>\n",
       "      <td>613.0</td>\n",
       "      <td>3612.0</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.772468</td>\n",
       "      <td>0.224972</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>oligodendrocyte precursor cell</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>39-year-old stage</td>\n",
       "      <td>WkKA;Qe{@^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413_AAGACAAGTAACAGGG-1</th>\n",
       "      <td>Microglia</td>\n",
       "      <td>infancy</td>\n",
       "      <td>Inf1</td>\n",
       "      <td>1848</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>2768.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>microglial cell</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>infant stage</td>\n",
       "      <td>!5%a0(I2Gs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936_GAGAACCAGGCTATGT-1</th>\n",
       "      <td>Astrocytes</td>\n",
       "      <td>adolescence</td>\n",
       "      <td>Adol2</td>\n",
       "      <td>17763</td>\n",
       "      <td>5189.0</td>\n",
       "      <td>5062.0</td>\n",
       "      <td>4589.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.059265</td>\n",
       "      <td>0.208914</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>astrocyte</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14-year-old stage</td>\n",
       "      <td>5=ofz(cc|Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032_CATAATGTCCTAATTC-1</th>\n",
       "      <td>OPC</td>\n",
       "      <td>childhood</td>\n",
       "      <td>Child1</td>\n",
       "      <td>8704</td>\n",
       "      <td>3113.0</td>\n",
       "      <td>6891.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.728525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>oligodendrocyte precursor cell</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4-year-old stage</td>\n",
       "      <td>g4!&amp;Oj&amp;UNM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_AATACCGGTTAAGGCC-1</th>\n",
       "      <td>EN-fetal-late</td>\n",
       "      <td>late fetal</td>\n",
       "      <td>LaFet1</td>\n",
       "      <td>1843</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.707332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>glutamatergic neuron</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>cortical plate</td>\n",
       "      <td>unknown</td>\n",
       "      <td>23rd week post-fertilization stage</td>\n",
       "      <td>^T|V&amp;TIMx1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150656_AGTATAGCATCCCGCT-1</th>\n",
       "      <td>EN</td>\n",
       "      <td>adulthood</td>\n",
       "      <td>Adult2</td>\n",
       "      <td>5827</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>3563.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.576855</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>glutamatergic neuron</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>39-year-old stage</td>\n",
       "      <td>r=A6C-|tsS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150656_CGAGGAAGTATTTGCC-1</th>\n",
       "      <td>Oligodendrocytes</td>\n",
       "      <td>adulthood</td>\n",
       "      <td>Adult2</td>\n",
       "      <td>1771</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.789610</td>\n",
       "      <td>0.203311</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>oligodendrocyte</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>39-year-old stage</td>\n",
       "      <td>l{a;&lt;k1%R)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007_AATAGAGGTTGCCTCA-1</th>\n",
       "      <td>Microglia</td>\n",
       "      <td>adolescence</td>\n",
       "      <td>Adol1</td>\n",
       "      <td>1740</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>2288.0</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.007075</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>microglial cell</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14-year-old stage</td>\n",
       "      <td>|M%+0#6Cm_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007_TGTTGTGCACCTGCCT-1</th>\n",
       "      <td>OPC</td>\n",
       "      <td>adolescence</td>\n",
       "      <td>Adol1</td>\n",
       "      <td>3937</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>9256.0</td>\n",
       "      <td>7854.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.910165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>oligodendrocyte precursor cell</td>\n",
       "      <td>10x multiome</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>dorsolateral prefrontal cortex</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14-year-old stage</td>\n",
       "      <td>aQiZS=7UhC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author_cell_type    age_group donor_id  nCount_RNA  \\\n",
       "index                                                                           \n",
       "8_AAGGATCCAGAGAGCC-1          EN-fetal-late   late fetal   LaFet2        3518   \n",
       "150656_CGGGCTTAGGCGCACT-1               OPC    adulthood   Adult2         778   \n",
       "4413_AAGACAAGTAACAGGG-1           Microglia      infancy     Inf1        1848   \n",
       "5936_GAGAACCAGGCTATGT-1          Astrocytes  adolescence    Adol2       17763   \n",
       "6032_CATAATGTCCTAATTC-1                 OPC    childhood   Child1        8704   \n",
       "4_AATACCGGTTAAGGCC-1          EN-fetal-late   late fetal   LaFet1        1843   \n",
       "150656_AGTATAGCATCCCGCT-1                EN    adulthood   Adult2        5827   \n",
       "150656_CGAGGAAGTATTTGCC-1  Oligodendrocytes    adulthood   Adult2        1771   \n",
       "6007_AATAGAGGTTGCCTCA-1           Microglia  adolescence    Adol1        1740   \n",
       "6007_TGTTGTGCACCTGCCT-1                 OPC  adolescence    Adol1        3937   \n",
       "\n",
       "                           nFeature_RNA  nCount_ATAC  nFeature_ATAC  \\\n",
       "index                                                                 \n",
       "8_AAGGATCCAGAGAGCC-1             1770.0       1284.0         1220.0   \n",
       "150656_CGGGCTTAGGCGCACT-1         613.0       3612.0         3326.0   \n",
       "4413_AAGACAAGTAACAGGG-1          1149.0       2768.0         2487.0   \n",
       "5936_GAGAACCAGGCTATGT-1          5189.0       5062.0         4589.0   \n",
       "6032_CATAATGTCCTAATTC-1          3113.0       6891.0         6006.0   \n",
       "4_AATACCGGTTAAGGCC-1             1093.0       1840.0         1767.0   \n",
       "150656_AGTATAGCATCCCGCT-1        2864.0       3878.0         3563.0   \n",
       "150656_CGAGGAAGTATTTGCC-1        1117.0        971.0          938.0   \n",
       "6007_AATAGAGGTTGCCTCA-1          1156.0       2288.0         2150.0   \n",
       "6007_TGTTGTGCACCTGCCT-1          2005.0       9256.0         7854.0   \n",
       "\n",
       "                           TSS_percentile  nucleosome_signal  percent_mt  ...  \\\n",
       "index                                                                     ...   \n",
       "8_AAGGATCCAGAGAGCC-1                 0.03           1.127075    0.000000  ...   \n",
       "150656_CGGGCTTAGGCGCACT-1            0.54           0.772468    0.224972  ...   \n",
       "4413_AAGACAAGTAACAGGG-1              0.82           0.834646    0.000000  ...   \n",
       "5936_GAGAACCAGGCTATGT-1              0.74           1.059265    0.208914  ...   \n",
       "6032_CATAATGTCCTAATTC-1              0.37           0.728525    0.000000  ...   \n",
       "4_AATACCGGTTAAGGCC-1                 0.10           0.707332    0.000000  ...   \n",
       "150656_AGTATAGCATCCCGCT-1            0.10           0.576855    0.041876  ...   \n",
       "150656_CGAGGAAGTATTTGCC-1            0.79           0.789610    0.203311  ...   \n",
       "6007_AATAGAGGTTGCCTCA-1              0.63           1.007075    0.841346  ...   \n",
       "6007_TGTTGTGCACCTGCCT-1              0.63           0.910165    0.000000  ...   \n",
       "\n",
       "                          METH_tissue_type                  METH_cell_type  \\\n",
       "index                                                                        \n",
       "8_AAGGATCCAGAGAGCC-1                tissue            glutamatergic neuron   \n",
       "150656_CGGGCTTAGGCGCACT-1           tissue  oligodendrocyte precursor cell   \n",
       "4413_AAGACAAGTAACAGGG-1             tissue                 microglial cell   \n",
       "5936_GAGAACCAGGCTATGT-1             tissue                       astrocyte   \n",
       "6032_CATAATGTCCTAATTC-1             tissue  oligodendrocyte precursor cell   \n",
       "4_AATACCGGTTAAGGCC-1                tissue            glutamatergic neuron   \n",
       "150656_AGTATAGCATCCCGCT-1           tissue            glutamatergic neuron   \n",
       "150656_CGAGGAAGTATTTGCC-1           tissue                 oligodendrocyte   \n",
       "6007_AATAGAGGTTGCCTCA-1             tissue                 microglial cell   \n",
       "6007_TGTTGTGCACCTGCCT-1             tissue  oligodendrocyte precursor cell   \n",
       "\n",
       "                             METH_assay METH_disease METH_organism METH_sex  \\\n",
       "index                                                                         \n",
       "8_AAGGATCCAGAGAGCC-1       10x multiome       normal  Homo sapiens   female   \n",
       "150656_CGGGCTTAGGCGCACT-1  10x multiome       normal  Homo sapiens     male   \n",
       "4413_AAGACAAGTAACAGGG-1    10x multiome       normal  Homo sapiens   female   \n",
       "5936_GAGAACCAGGCTATGT-1    10x multiome       normal  Homo sapiens   female   \n",
       "6032_CATAATGTCCTAATTC-1    10x multiome       normal  Homo sapiens     male   \n",
       "4_AATACCGGTTAAGGCC-1       10x multiome       normal  Homo sapiens     male   \n",
       "150656_AGTATAGCATCCCGCT-1  10x multiome       normal  Homo sapiens     male   \n",
       "150656_CGAGGAAGTATTTGCC-1  10x multiome       normal  Homo sapiens     male   \n",
       "6007_AATAGAGGTTGCCTCA-1    10x multiome       normal  Homo sapiens     male   \n",
       "6007_TGTTGTGCACCTGCCT-1    10x multiome       normal  Homo sapiens     male   \n",
       "\n",
       "                                              METH_tissue  \\\n",
       "index                                                       \n",
       "8_AAGGATCCAGAGAGCC-1                       cortical plate   \n",
       "150656_CGGGCTTAGGCGCACT-1  dorsolateral prefrontal cortex   \n",
       "4413_AAGACAAGTAACAGGG-1    dorsolateral prefrontal cortex   \n",
       "5936_GAGAACCAGGCTATGT-1    dorsolateral prefrontal cortex   \n",
       "6032_CATAATGTCCTAATTC-1    dorsolateral prefrontal cortex   \n",
       "4_AATACCGGTTAAGGCC-1                       cortical plate   \n",
       "150656_AGTATAGCATCCCGCT-1  dorsolateral prefrontal cortex   \n",
       "150656_CGAGGAAGTATTTGCC-1  dorsolateral prefrontal cortex   \n",
       "6007_AATAGAGGTTGCCTCA-1    dorsolateral prefrontal cortex   \n",
       "6007_TGTTGTGCACCTGCCT-1    dorsolateral prefrontal cortex   \n",
       "\n",
       "                          METH_self_reported_ethnicity  \\\n",
       "index                                                    \n",
       "8_AAGGATCCAGAGAGCC-1                           unknown   \n",
       "150656_CGGGCTTAGGCGCACT-1                      unknown   \n",
       "4413_AAGACAAGTAACAGGG-1                        unknown   \n",
       "5936_GAGAACCAGGCTATGT-1                        unknown   \n",
       "6032_CATAATGTCCTAATTC-1                        unknown   \n",
       "4_AATACCGGTTAAGGCC-1                           unknown   \n",
       "150656_AGTATAGCATCCCGCT-1                      unknown   \n",
       "150656_CGAGGAAGTATTTGCC-1                      unknown   \n",
       "6007_AATAGAGGTTGCCTCA-1                        unknown   \n",
       "6007_TGTTGTGCACCTGCCT-1                        unknown   \n",
       "\n",
       "                                       METH_development_stage  \\\n",
       "index                                                           \n",
       "8_AAGGATCCAGAGAGCC-1       24th week post-fertilization stage   \n",
       "150656_CGGGCTTAGGCGCACT-1                   39-year-old stage   \n",
       "4413_AAGACAAGTAACAGGG-1                          infant stage   \n",
       "5936_GAGAACCAGGCTATGT-1                     14-year-old stage   \n",
       "6032_CATAATGTCCTAATTC-1                      4-year-old stage   \n",
       "4_AATACCGGTTAAGGCC-1       23rd week post-fertilization stage   \n",
       "150656_AGTATAGCATCCCGCT-1                   39-year-old stage   \n",
       "150656_CGAGGAAGTATTTGCC-1                   39-year-old stage   \n",
       "6007_AATAGAGGTTGCCTCA-1                     14-year-old stage   \n",
       "6007_TGTTGTGCACCTGCCT-1                     14-year-old stage   \n",
       "\n",
       "                           METH_observation_joinid  \n",
       "index                                               \n",
       "8_AAGGATCCAGAGAGCC-1                    e;x33fbL}(  \n",
       "150656_CGGGCTTAGGCGCACT-1               WkKA;Qe{@^  \n",
       "4413_AAGACAAGTAACAGGG-1                 !5%a0(I2Gs  \n",
       "5936_GAGAACCAGGCTATGT-1                 5=ofz(cc|Q  \n",
       "6032_CATAATGTCCTAATTC-1                 g4!&Oj&UNM  \n",
       "4_AATACCGGTTAAGGCC-1                    ^T|V&TIMx1  \n",
       "150656_AGTATAGCATCCCGCT-1               r=A6C-|tsS  \n",
       "150656_CGAGGAAGTATTTGCC-1               l{a;<k1%R)  \n",
       "6007_AATAGAGGTTGCCTCA-1                 |M%+0#6Cm_  \n",
       "6007_TGTTGTGCACCTGCCT-1                 aQiZS=7UhC  \n",
       "\n",
       "[10 rows x 93 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# match authot_cell_type to image\n",
    "sc_df = df.copy()\n",
    "sc_df.index = rna_adata.obs.index\n",
    "cell_types = rna_adata.obs[\"author_cell_type\"].unique()\n",
    "# map the cell type to the class label\n",
    "class_labels = df[\"extra_class_labels\"].unique()\n",
    "print(len(cell_types))\n",
    "print(len(class_labels))\n",
    "# we have 6 cell types and 4 class labels so we map 2 cell types to the same class label\n",
    "class_map = {c: l for c, l in zip(cell_types, class_labels)}\n",
    "reverse_map = {v: k for k, v in class_map.items()}\n",
    "sc_df[\"author_cell_type\"] = sc_df[\"extra_class_labels\"].apply(lambda x: reverse_map[x])\n",
    "del sc_df[\"CANCER_TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   img_path       sample_ids  \\\n",
      "index                                                          \n",
      "8_AAGGATCCAGAGAGCC-1       1111_label_2.png  TCGA-A5-A0GX-01   \n",
      "150656_CGGGCTTAGGCGCACT-1   496_label_1.png  TCGA-AB-2815-03   \n",
      "4413_AAGACAAGTAACAGGG-1    2039_label_4.png  TCGA-VN-A943-01   \n",
      "5936_GAGAACCAGGCTATGT-1    2366_label_0.png  TCGA-D7-6527-01   \n",
      "6032_CATAATGTCCTAATTC-1    3342_label_0.png  TCGA-AA-3532-01   \n",
      "4_AATACCGGTTAAGGCC-1       1719_label_4.png  TCGA-CA-6715-01   \n",
      "150656_AGTATAGCATCCCGCT-1  3163_label_0.png  TCGA-P5-A737-01   \n",
      "150656_CGAGGAAGTATTTGCC-1  2511_label_0.png  TCGA-WA-A7H4-01   \n",
      "6007_AATAGAGGTTGCCTCA-1    3506_label_1.png  TCGA-DV-5575-01   \n",
      "6007_TGTTGTGCACCTGCCT-1    1937_label_4.png  TCGA-HC-A76X-01   \n",
      "\n",
      "                          extra_class_labels author_cell_type  \n",
      "index                                                          \n",
      "8_AAGGATCCAGAGAGCC-1                       2    EN-fetal-late  \n",
      "150656_CGGGCTTAGGCGCACT-1                  1              OPC  \n",
      "4413_AAGACAAGTAACAGGG-1                    4        Microglia  \n",
      "5936_GAGAACCAGGCTATGT-1                    0       Astrocytes  \n",
      "6032_CATAATGTCCTAATTC-1                    0       Astrocytes  \n",
      "4_AATACCGGTTAAGGCC-1                       4        Microglia  \n",
      "150656_AGTATAGCATCCCGCT-1                  0       Astrocytes  \n",
      "150656_CGAGGAAGTATTTGCC-1                  0       Astrocytes  \n",
      "6007_AATAGAGGTTGCCTCA-1                    1              OPC  \n",
      "6007_TGTTGTGCACCTGCCT-1                    4        Microglia  \n"
     ]
    }
   ],
   "source": [
    "print(sc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df.to_csv(\"data/raw/mini/sc_mappings.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all images in img_path from data/raw/images/tcga_fake to data/raw/mini/img\n",
    "import shutil\n",
    "\n",
    "imgs = sc_df[\"img_path\"].to_list()\n",
    "to_folder = \"data/raw/mini/img\"\n",
    "from_folder = \"data/raw/images/tcga_fake\"\n",
    "for img in imgs:\n",
    "    shutil.copy(os.path.join(from_folder, img), to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sc', 'bulk', 'images', 'img', 'single_cell', 'tcga_mappings.txt', 'sc_mappings.txt']\n",
      "[]\n",
      "meth_sample_data.csv\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789  0.039560   \n",
      "1  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669  0.044344   \n",
      "2  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076  0.035845   \n",
      "3  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749  0.048614   \n",
      "4  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670  0.035541   \n",
      "\n",
      "          7         8         9  ...      9218      9219      9220      9221  \\\n",
      "0  0.247788  0.683242  0.491715  ...  0.352372  0.127597  0.044314  0.037877   \n",
      "1  0.341094  0.040689  0.061997  ...  0.519684  0.029984  0.033249  0.041586   \n",
      "2  0.132343  0.535857  0.082010  ...  0.452271  0.018452  0.034082  0.038566   \n",
      "3  0.219340  0.108956  0.090093  ...  0.403294  0.049470  0.041010  0.041364   \n",
      "4  0.109170  0.062473  0.025606  ...  0.215619  0.011806  0.027319  0.023646   \n",
      "\n",
      "       9222      9223      9224      9225      9226      9227  \n",
      "0  0.072173  0.093309  0.047474  0.037088  0.070449  0.042182  \n",
      "1  0.042256  0.336860  0.030585  0.037901  0.047995  0.049501  \n",
      "2  0.029709  0.055071  0.025691  0.039963  0.047558  0.029063  \n",
      "3  0.048847  0.137246  0.031557  0.034625  0.074690  0.041795  \n",
      "4  0.036950  0.126191  0.025326  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "meth_sample_data.parquet\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789  0.039560   \n",
      "1  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669  0.044344   \n",
      "2  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076  0.035845   \n",
      "3  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749  0.048614   \n",
      "4  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670  0.035541   \n",
      "\n",
      "       7         8         9     ...      9218      9219      9220      9221  \\\n",
      "0  0.247788  0.683242  0.491715  ...  0.352372  0.127597  0.044314  0.037877   \n",
      "1  0.341094  0.040689  0.061997  ...  0.519684  0.029984  0.033249  0.041586   \n",
      "2  0.132343  0.535857  0.082010  ...  0.452271  0.018452  0.034082  0.038566   \n",
      "3  0.219340  0.108956  0.090093  ...  0.403294  0.049470  0.041010  0.041364   \n",
      "4  0.109170  0.062473  0.025606  ...  0.215619  0.011806  0.027319  0.023646   \n",
      "\n",
      "       9222      9223      9224      9225      9226      9227  \n",
      "0  0.072173  0.093309  0.047474  0.037088  0.070449  0.042182  \n",
      "1  0.042256  0.336860  0.030585  0.037901  0.047995  0.049501  \n",
      "2  0.029709  0.055071  0.025691  0.039963  0.047558  0.029063  \n",
      "3  0.048847  0.137246  0.031557  0.034625  0.074690  0.041795  \n",
      "4  0.036950  0.126191  0.025326  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "clinical_sample_data.tsv\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "rna_sample_data.csv\n",
      "           0          1           2            3           4         5  \\\n",
      "0  17.955979  12.172974   63.841777   500.046741  562.353025 -0.362744   \n",
      "1   1.061107   1.656913  470.571633   614.350373  354.803772 -0.255074   \n",
      "2  11.996400   8.093300   57.865500   591.928000  332.915000  0.717500   \n",
      "3   6.942676   8.237000   20.523927   663.796380   69.258261  0.853124   \n",
      "4   4.154408   3.912016  656.250913  1199.334795  112.057230  2.557914   \n",
      "\n",
      "          6            7           8            9  ...       16303  \\\n",
      "0  3.354920   184.341274    2.431059  1736.932648  ...  150.200838   \n",
      "1  3.491314  1343.894373  132.388873    74.394155  ...  757.532446   \n",
      "2  2.870000   107.623000    3.587400    89.686100  ...  255.720000   \n",
      "3  2.961608   514.022887    3.817601   241.635769  ...  362.347319   \n",
      "4  6.965178   373.960797   10.836752   100.341457  ...  723.346520   \n",
      "\n",
      "         16304       16305       16306        16307      16308        16309  \\\n",
      "0   240.933551   35.320841  130.728261   874.378242   7.466345   245.075563   \n",
      "1  1311.226041   36.435370  274.195767  2787.139759  16.550917  1076.202487   \n",
      "2   190.852000   66.726500  505.830000  1054.710000  34.439500   967.892000   \n",
      "3   897.239967  115.141051  696.550054  1073.536154  15.106769   543.030762   \n",
      "4  1102.882155   64.724384  432.528666   820.255562  -0.402069   886.793096   \n",
      "\n",
      "          16310        16311        16312  \n",
      "0  11066.197277  1113.282393   279.970457  \n",
      "1   7960.106840  3287.971623  1465.133041  \n",
      "2    860.986000  1262.780000   721.076000  \n",
      "3   3326.150859  1101.114198   610.186604  \n",
      "4   4322.864422   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "rna_sample_data.tsv\n",
      "           0          1           2            3           4         5  \\\n",
      "0  17.955979  12.172974   63.841777   500.046741  562.353025 -0.362744   \n",
      "1   1.061107   1.656913  470.571633   614.350373  354.803772 -0.255074   \n",
      "2  11.996400   8.093300   57.865500   591.928000  332.915000  0.717500   \n",
      "3   6.942676   8.237000   20.523927   663.796380   69.258261  0.853124   \n",
      "4   4.154408   3.912016  656.250913  1199.334795  112.057230  2.557914   \n",
      "\n",
      "          6            7           8            9  ...       16303  \\\n",
      "0  3.354920   184.341274    2.431059  1736.932648  ...  150.200838   \n",
      "1  3.491314  1343.894373  132.388873    74.394155  ...  757.532446   \n",
      "2  2.870000   107.623000    3.587400    89.686100  ...  255.720000   \n",
      "3  2.961608   514.022887    3.817601   241.635769  ...  362.347319   \n",
      "4  6.965178   373.960797   10.836752   100.341457  ...  723.346520   \n",
      "\n",
      "         16304       16305       16306        16307      16308        16309  \\\n",
      "0   240.933551   35.320841  130.728261   874.378242   7.466345   245.075563   \n",
      "1  1311.226041   36.435370  274.195767  2787.139759  16.550917  1076.202487   \n",
      "2   190.852000   66.726500  505.830000  1054.710000  34.439500   967.892000   \n",
      "3   897.239967  115.141051  696.550054  1073.536154  15.106769   543.030762   \n",
      "4  1102.882155   64.724384  432.528666   820.255562  -0.402069   886.793096   \n",
      "\n",
      "          16310        16311        16312  \n",
      "0  11066.197277  1113.282393   279.970457  \n",
      "1   7960.106840  3287.971623  1465.133041  \n",
      "2    860.986000  1262.780000   721.076000  \n",
      "3   3326.150859  1101.114198   610.186604  \n",
      "4   4322.864422   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "clinical_sample_data.csv\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "rna_sample_data.parquet\n",
      "       0          1           2            3           4         5      \\\n",
      "0  17.955979  12.172974   63.841777   500.046741  562.353025 -0.362744   \n",
      "1   1.061107   1.656913  470.571633   614.350373  354.803772 -0.255074   \n",
      "2  11.996400   8.093300   57.865500   591.928000  332.915000  0.717500   \n",
      "3   6.942676   8.237000   20.523927   663.796380   69.258261  0.853124   \n",
      "4   4.154408   3.912016  656.250913  1199.334795  112.057230  2.557914   \n",
      "\n",
      "      6            7           8            9      ...       16303  \\\n",
      "0  3.354920   184.341274    2.431059  1736.932648  ...  150.200838   \n",
      "1  3.491314  1343.894373  132.388873    74.394155  ...  757.532446   \n",
      "2  2.870000   107.623000    3.587400    89.686100  ...  255.720000   \n",
      "3  2.961608   514.022887    3.817601   241.635769  ...  362.347319   \n",
      "4  6.965178   373.960797   10.836752   100.341457  ...  723.346520   \n",
      "\n",
      "         16304       16305       16306        16307      16308        16309  \\\n",
      "0   240.933551   35.320841  130.728261   874.378242   7.466345   245.075563   \n",
      "1  1311.226041   36.435370  274.195767  2787.139759  16.550917  1076.202487   \n",
      "2   190.852000   66.726500  505.830000  1054.710000  34.439500   967.892000   \n",
      "3   897.239967  115.141051  696.550054  1073.536154  15.106769   543.030762   \n",
      "4  1102.882155   64.724384  432.528666   820.255562  -0.402069   886.793096   \n",
      "\n",
      "          16310        16311        16312  \n",
      "0  11066.197277  1113.282393   279.970457  \n",
      "1   7960.106840  3287.971623  1465.133041  \n",
      "2    860.986000  1262.780000   721.076000  \n",
      "3   3326.150859  1101.114198   610.186604  \n",
      "4   4322.864422   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "meth_sample_data.tsv\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789  0.039560   \n",
      "1  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669  0.044344   \n",
      "2  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076  0.035845   \n",
      "3  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749  0.048614   \n",
      "4  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670  0.035541   \n",
      "\n",
      "          7         8         9  ...      9218      9219      9220      9221  \\\n",
      "0  0.247788  0.683242  0.491715  ...  0.352372  0.127597  0.044314  0.037877   \n",
      "1  0.341094  0.040689  0.061997  ...  0.519684  0.029984  0.033249  0.041586   \n",
      "2  0.132343  0.535857  0.082010  ...  0.452271  0.018452  0.034082  0.038566   \n",
      "3  0.219340  0.108956  0.090093  ...  0.403294  0.049470  0.041010  0.041364   \n",
      "4  0.109170  0.062473  0.025606  ...  0.215619  0.011806  0.027319  0.023646   \n",
      "\n",
      "       9222      9223      9224      9225      9226      9227  \n",
      "0  0.072173  0.093309  0.047474  0.037088  0.070449  0.042182  \n",
      "1  0.042256  0.336860  0.030585  0.037901  0.047995  0.049501  \n",
      "2  0.029709  0.055071  0.025691  0.039963  0.047558  0.029063  \n",
      "3  0.048847  0.137246  0.031557  0.034625  0.074690  0.041795  \n",
      "4  0.036950  0.126191  0.025326  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "clinical_sample_data.parquet\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "meth_sample_data.csv\n",
      "meth_sample_data.parquet\n",
      "clinical_sample_data.tsv\n",
      "rna_sample_data.csv\n",
      "rna_sample_data.tsv\n",
      "clinical_sample_data.csv\n",
      "rna_sample_data.parquet\n",
      "meth_sample_data.tsv\n",
      "clinical_sample_data.parquet\n",
      "['meth_sample_data.csv', 'meth_sample_data.parquet', 'clinical_sample_data.tsv', 'rna_sample_data.csv', 'rna_sample_data.tsv', 'clinical_sample_data.csv', 'rna_sample_data.parquet', 'meth_sample_data.tsv', 'clinical_sample_data.parquet']\n",
      "no files in directory\n",
      "['3163_label_0.png', '3506_label_1.png', '1516_label_2.png', '2039_label_4.png', '3342_label_0.png', '1937_label_4.png', '1331_label_2.png', '1111_label_2.png', '2366_label_0.png', '496_label_1.png', '591_label_3.png', '1719_label_4.png', '2511_label_0.png']\n",
      "['meth_sample_data.h5ad', 'rna_sample_data.h5ad']\n",
      "no files in directory\n",
      "no files in directory\n"
     ]
    }
   ],
   "source": [
    "dirs = os.listdir(\"data/raw/mini/\")\n",
    "print(dirs)\n",
    "dfs = []\n",
    "for d in dirs:\n",
    "    if d == \"bulk\":\n",
    "        bulk_files = os.listdir(os.path.join(\"data/raw/mini/\", d))\n",
    "        for f in bulk_files:\n",
    "            file_extension = f.split(\".\")[-1]\n",
    "            if file_extension == \"parquet\":\n",
    "                print(f)\n",
    "                df = pd.read_parquet(os.path.join(\"data/raw/mini/\", d, f))\n",
    "                print(df.head())\n",
    "            elif file_extension == \"csv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(os.path.join(\"data/raw/mini/\", d, f), index_col=0)\n",
    "                print(df.head())\n",
    "            elif file_extension == \"tsv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(\n",
    "                    os.path.join(\"data/raw/mini/\", d, f), sep=\"\\t\", index_col=0\n",
    "                )\n",
    "                print(df.head())\n",
    "            if f == \"clinical_sample_data.csv\":\n",
    "                indices = df.index\n",
    "            dfs.append(df)\n",
    "\n",
    "        for f in bulk_files:\n",
    "            file_extension = f.split(\".\")[-1]\n",
    "            if file_extension == \"parquet\":\n",
    "                print(f)\n",
    "                df = pd.read_parquet(os.path.join(\"data/raw/mini/\", d, f))\n",
    "                df.index = indices\n",
    "                df.to_parquet(os.path.join(\"data/raw/mini/\", d, f))\n",
    "            elif file_extension == \"csv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(os.path.join(\"data/raw/mini/\", d, f), index_col=0)\n",
    "                df.index = indices\n",
    "                df.to_csv(os.path.join(\"data/raw/mini/\", d, f), index=True)\n",
    "\n",
    "            elif file_extension == \"tsv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(\n",
    "                    os.path.join(\"data/raw/mini/\", d, f), sep=\"\\t\", index_col=0\n",
    "                )\n",
    "                df.index = indices\n",
    "                df.to_csv(os.path.join(\"data/raw/mini/\", d, f), sep=\"\\t\", index=True)\n",
    "\n",
    "    try:\n",
    "        print(os.listdir(os.path.join(\"data/raw/mini/\", d)))\n",
    "    except:\n",
    "        print(\"no files in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meth_sample_data.csv\n",
      "                        0         1         2         3         4         5  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789   \n",
      "TCGA-AB-2815-03  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669   \n",
      "TCGA-VN-A943-01  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076   \n",
      "TCGA-D7-6527-01  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749   \n",
      "TCGA-AA-3532-01  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670   \n",
      "\n",
      "                        6         7         8         9  ...      9218  \\\n",
      "SAMPLE_ID                                                ...             \n",
      "TCGA-A5-A0GX-01  0.039560  0.247788  0.683242  0.491715  ...  0.352372   \n",
      "TCGA-AB-2815-03  0.044344  0.341094  0.040689  0.061997  ...  0.519684   \n",
      "TCGA-VN-A943-01  0.035845  0.132343  0.535857  0.082010  ...  0.452271   \n",
      "TCGA-D7-6527-01  0.048614  0.219340  0.108956  0.090093  ...  0.403294   \n",
      "TCGA-AA-3532-01  0.035541  0.109170  0.062473  0.025606  ...  0.215619   \n",
      "\n",
      "                     9219      9220      9221      9222      9223      9224  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.127597  0.044314  0.037877  0.072173  0.093309  0.047474   \n",
      "TCGA-AB-2815-03  0.029984  0.033249  0.041586  0.042256  0.336860  0.030585   \n",
      "TCGA-VN-A943-01  0.018452  0.034082  0.038566  0.029709  0.055071  0.025691   \n",
      "TCGA-D7-6527-01  0.049470  0.041010  0.041364  0.048847  0.137246  0.031557   \n",
      "TCGA-AA-3532-01  0.011806  0.027319  0.023646  0.036950  0.126191  0.025326   \n",
      "\n",
      "                     9225      9226      9227  \n",
      "SAMPLE_ID                                      \n",
      "TCGA-A5-A0GX-01  0.037088  0.070449  0.042182  \n",
      "TCGA-AB-2815-03  0.037901  0.047995  0.049501  \n",
      "TCGA-VN-A943-01  0.039963  0.047558  0.029063  \n",
      "TCGA-D7-6527-01  0.034625  0.074690  0.041795  \n",
      "TCGA-AA-3532-01  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "meth_sample_data.parquet\n",
      "                     0         1         2         3         4         5     \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789   \n",
      "TCGA-AB-2815-03  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669   \n",
      "TCGA-VN-A943-01  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076   \n",
      "TCGA-D7-6527-01  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749   \n",
      "TCGA-AA-3532-01  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670   \n",
      "\n",
      "                     6         7         8         9     ...      9218  \\\n",
      "SAMPLE_ID                                                ...             \n",
      "TCGA-A5-A0GX-01  0.039560  0.247788  0.683242  0.491715  ...  0.352372   \n",
      "TCGA-AB-2815-03  0.044344  0.341094  0.040689  0.061997  ...  0.519684   \n",
      "TCGA-VN-A943-01  0.035845  0.132343  0.535857  0.082010  ...  0.452271   \n",
      "TCGA-D7-6527-01  0.048614  0.219340  0.108956  0.090093  ...  0.403294   \n",
      "TCGA-AA-3532-01  0.035541  0.109170  0.062473  0.025606  ...  0.215619   \n",
      "\n",
      "                     9219      9220      9221      9222      9223      9224  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.127597  0.044314  0.037877  0.072173  0.093309  0.047474   \n",
      "TCGA-AB-2815-03  0.029984  0.033249  0.041586  0.042256  0.336860  0.030585   \n",
      "TCGA-VN-A943-01  0.018452  0.034082  0.038566  0.029709  0.055071  0.025691   \n",
      "TCGA-D7-6527-01  0.049470  0.041010  0.041364  0.048847  0.137246  0.031557   \n",
      "TCGA-AA-3532-01  0.011806  0.027319  0.023646  0.036950  0.126191  0.025326   \n",
      "\n",
      "                     9225      9226      9227  \n",
      "SAMPLE_ID                                      \n",
      "TCGA-A5-A0GX-01  0.037088  0.070449  0.042182  \n",
      "TCGA-AB-2815-03  0.037901  0.047995  0.049501  \n",
      "TCGA-VN-A943-01  0.039963  0.047558  0.029063  \n",
      "TCGA-D7-6527-01  0.034625  0.074690  0.041795  \n",
      "TCGA-AA-3532-01  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "clinical_sample_data.tsv\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "rna_sample_data.csv\n",
      "                         0          1           2            3           4  \\\n",
      "SAMPLE_ID                                                                    \n",
      "TCGA-A5-A0GX-01  17.955979  12.172974   63.841777   500.046741  562.353025   \n",
      "TCGA-AB-2815-03   1.061107   1.656913  470.571633   614.350373  354.803772   \n",
      "TCGA-VN-A943-01  11.996400   8.093300   57.865500   591.928000  332.915000   \n",
      "TCGA-D7-6527-01   6.942676   8.237000   20.523927   663.796380   69.258261   \n",
      "TCGA-AA-3532-01   4.154408   3.912016  656.250913  1199.334795  112.057230   \n",
      "\n",
      "                        5         6            7           8            9  \\\n",
      "SAMPLE_ID                                                                   \n",
      "TCGA-A5-A0GX-01 -0.362744  3.354920   184.341274    2.431059  1736.932648   \n",
      "TCGA-AB-2815-03 -0.255074  3.491314  1343.894373  132.388873    74.394155   \n",
      "TCGA-VN-A943-01  0.717500  2.870000   107.623000    3.587400    89.686100   \n",
      "TCGA-D7-6527-01  0.853124  2.961608   514.022887    3.817601   241.635769   \n",
      "TCGA-AA-3532-01  2.557914  6.965178   373.960797   10.836752   100.341457   \n",
      "\n",
      "                 ...       16303        16304       16305       16306  \\\n",
      "SAMPLE_ID        ...                                                    \n",
      "TCGA-A5-A0GX-01  ...  150.200838   240.933551   35.320841  130.728261   \n",
      "TCGA-AB-2815-03  ...  757.532446  1311.226041   36.435370  274.195767   \n",
      "TCGA-VN-A943-01  ...  255.720000   190.852000   66.726500  505.830000   \n",
      "TCGA-D7-6527-01  ...  362.347319   897.239967  115.141051  696.550054   \n",
      "TCGA-AA-3532-01  ...  723.346520  1102.882155   64.724384  432.528666   \n",
      "\n",
      "                       16307      16308        16309         16310  \\\n",
      "SAMPLE_ID                                                            \n",
      "TCGA-A5-A0GX-01   874.378242   7.466345   245.075563  11066.197277   \n",
      "TCGA-AB-2815-03  2787.139759  16.550917  1076.202487   7960.106840   \n",
      "TCGA-VN-A943-01  1054.710000  34.439500   967.892000    860.986000   \n",
      "TCGA-D7-6527-01  1073.536154  15.106769   543.030762   3326.150859   \n",
      "TCGA-AA-3532-01   820.255562  -0.402069   886.793096   4322.864422   \n",
      "\n",
      "                       16311        16312  \n",
      "SAMPLE_ID                                  \n",
      "TCGA-A5-A0GX-01  1113.282393   279.970457  \n",
      "TCGA-AB-2815-03  3287.971623  1465.133041  \n",
      "TCGA-VN-A943-01  1262.780000   721.076000  \n",
      "TCGA-D7-6527-01  1101.114198   610.186604  \n",
      "TCGA-AA-3532-01   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "rna_sample_data.tsv\n",
      "                         0          1           2            3           4  \\\n",
      "SAMPLE_ID                                                                    \n",
      "TCGA-A5-A0GX-01  17.955979  12.172974   63.841777   500.046741  562.353025   \n",
      "TCGA-AB-2815-03   1.061107   1.656913  470.571633   614.350373  354.803772   \n",
      "TCGA-VN-A943-01  11.996400   8.093300   57.865500   591.928000  332.915000   \n",
      "TCGA-D7-6527-01   6.942676   8.237000   20.523927   663.796380   69.258261   \n",
      "TCGA-AA-3532-01   4.154408   3.912016  656.250913  1199.334795  112.057230   \n",
      "\n",
      "                        5         6            7           8            9  \\\n",
      "SAMPLE_ID                                                                   \n",
      "TCGA-A5-A0GX-01 -0.362744  3.354920   184.341274    2.431059  1736.932648   \n",
      "TCGA-AB-2815-03 -0.255074  3.491314  1343.894373  132.388873    74.394155   \n",
      "TCGA-VN-A943-01  0.717500  2.870000   107.623000    3.587400    89.686100   \n",
      "TCGA-D7-6527-01  0.853124  2.961608   514.022887    3.817601   241.635769   \n",
      "TCGA-AA-3532-01  2.557914  6.965178   373.960797   10.836752   100.341457   \n",
      "\n",
      "                 ...       16303        16304       16305       16306  \\\n",
      "SAMPLE_ID        ...                                                    \n",
      "TCGA-A5-A0GX-01  ...  150.200838   240.933551   35.320841  130.728261   \n",
      "TCGA-AB-2815-03  ...  757.532446  1311.226041   36.435370  274.195767   \n",
      "TCGA-VN-A943-01  ...  255.720000   190.852000   66.726500  505.830000   \n",
      "TCGA-D7-6527-01  ...  362.347319   897.239967  115.141051  696.550054   \n",
      "TCGA-AA-3532-01  ...  723.346520  1102.882155   64.724384  432.528666   \n",
      "\n",
      "                       16307      16308        16309         16310  \\\n",
      "SAMPLE_ID                                                            \n",
      "TCGA-A5-A0GX-01   874.378242   7.466345   245.075563  11066.197277   \n",
      "TCGA-AB-2815-03  2787.139759  16.550917  1076.202487   7960.106840   \n",
      "TCGA-VN-A943-01  1054.710000  34.439500   967.892000    860.986000   \n",
      "TCGA-D7-6527-01  1073.536154  15.106769   543.030762   3326.150859   \n",
      "TCGA-AA-3532-01   820.255562  -0.402069   886.793096   4322.864422   \n",
      "\n",
      "                       16311        16312  \n",
      "SAMPLE_ID                                  \n",
      "TCGA-A5-A0GX-01  1113.282393   279.970457  \n",
      "TCGA-AB-2815-03  3287.971623  1465.133041  \n",
      "TCGA-VN-A943-01  1262.780000   721.076000  \n",
      "TCGA-D7-6527-01  1101.114198   610.186604  \n",
      "TCGA-AA-3532-01   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "clinical_sample_data.csv\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "rna_sample_data.parquet\n",
      "                     0          1           2            3           4      \\\n",
      "SAMPLE_ID                                                                    \n",
      "TCGA-A5-A0GX-01  17.955979  12.172974   63.841777   500.046741  562.353025   \n",
      "TCGA-AB-2815-03   1.061107   1.656913  470.571633   614.350373  354.803772   \n",
      "TCGA-VN-A943-01  11.996400   8.093300   57.865500   591.928000  332.915000   \n",
      "TCGA-D7-6527-01   6.942676   8.237000   20.523927   663.796380   69.258261   \n",
      "TCGA-AA-3532-01   4.154408   3.912016  656.250913  1199.334795  112.057230   \n",
      "\n",
      "                    5         6            7           8            9      \\\n",
      "SAMPLE_ID                                                                   \n",
      "TCGA-A5-A0GX-01 -0.362744  3.354920   184.341274    2.431059  1736.932648   \n",
      "TCGA-AB-2815-03 -0.255074  3.491314  1343.894373  132.388873    74.394155   \n",
      "TCGA-VN-A943-01  0.717500  2.870000   107.623000    3.587400    89.686100   \n",
      "TCGA-D7-6527-01  0.853124  2.961608   514.022887    3.817601   241.635769   \n",
      "TCGA-AA-3532-01  2.557914  6.965178   373.960797   10.836752   100.341457   \n",
      "\n",
      "                 ...       16303        16304       16305       16306  \\\n",
      "SAMPLE_ID        ...                                                    \n",
      "TCGA-A5-A0GX-01  ...  150.200838   240.933551   35.320841  130.728261   \n",
      "TCGA-AB-2815-03  ...  757.532446  1311.226041   36.435370  274.195767   \n",
      "TCGA-VN-A943-01  ...  255.720000   190.852000   66.726500  505.830000   \n",
      "TCGA-D7-6527-01  ...  362.347319   897.239967  115.141051  696.550054   \n",
      "TCGA-AA-3532-01  ...  723.346520  1102.882155   64.724384  432.528666   \n",
      "\n",
      "                       16307      16308        16309         16310  \\\n",
      "SAMPLE_ID                                                            \n",
      "TCGA-A5-A0GX-01   874.378242   7.466345   245.075563  11066.197277   \n",
      "TCGA-AB-2815-03  2787.139759  16.550917  1076.202487   7960.106840   \n",
      "TCGA-VN-A943-01  1054.710000  34.439500   967.892000    860.986000   \n",
      "TCGA-D7-6527-01  1073.536154  15.106769   543.030762   3326.150859   \n",
      "TCGA-AA-3532-01   820.255562  -0.402069   886.793096   4322.864422   \n",
      "\n",
      "                       16311        16312  \n",
      "SAMPLE_ID                                  \n",
      "TCGA-A5-A0GX-01  1113.282393   279.970457  \n",
      "TCGA-AB-2815-03  3287.971623  1465.133041  \n",
      "TCGA-VN-A943-01  1262.780000   721.076000  \n",
      "TCGA-D7-6527-01  1101.114198   610.186604  \n",
      "TCGA-AA-3532-01   993.739692   743.633035  \n",
      "\n",
      "[5 rows x 16313 columns]\n",
      "meth_sample_data.tsv\n",
      "                        0         1         2         3         4         5  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.839167  0.060268  0.057504  0.782557  0.068412  0.801789   \n",
      "TCGA-AB-2815-03  0.056277  0.063611  0.032029  0.883914  0.329893  0.895669   \n",
      "TCGA-VN-A943-01  0.533199  0.042316  0.030181  0.733911  0.101098  0.798076   \n",
      "TCGA-D7-6527-01  0.340243  0.088684  0.042730  0.471534  0.144958  0.387749   \n",
      "TCGA-AA-3532-01  0.187656  0.195934  0.027865  0.417685  0.368614  0.732670   \n",
      "\n",
      "                        6         7         8         9  ...      9218  \\\n",
      "SAMPLE_ID                                                ...             \n",
      "TCGA-A5-A0GX-01  0.039560  0.247788  0.683242  0.491715  ...  0.352372   \n",
      "TCGA-AB-2815-03  0.044344  0.341094  0.040689  0.061997  ...  0.519684   \n",
      "TCGA-VN-A943-01  0.035845  0.132343  0.535857  0.082010  ...  0.452271   \n",
      "TCGA-D7-6527-01  0.048614  0.219340  0.108956  0.090093  ...  0.403294   \n",
      "TCGA-AA-3532-01  0.035541  0.109170  0.062473  0.025606  ...  0.215619   \n",
      "\n",
      "                     9219      9220      9221      9222      9223      9224  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  0.127597  0.044314  0.037877  0.072173  0.093309  0.047474   \n",
      "TCGA-AB-2815-03  0.029984  0.033249  0.041586  0.042256  0.336860  0.030585   \n",
      "TCGA-VN-A943-01  0.018452  0.034082  0.038566  0.029709  0.055071  0.025691   \n",
      "TCGA-D7-6527-01  0.049470  0.041010  0.041364  0.048847  0.137246  0.031557   \n",
      "TCGA-AA-3532-01  0.011806  0.027319  0.023646  0.036950  0.126191  0.025326   \n",
      "\n",
      "                     9225      9226      9227  \n",
      "SAMPLE_ID                                      \n",
      "TCGA-A5-A0GX-01  0.037088  0.070449  0.042182  \n",
      "TCGA-AB-2815-03  0.037901  0.047995  0.049501  \n",
      "TCGA-VN-A943-01  0.039963  0.047558  0.029063  \n",
      "TCGA-D7-6527-01  0.034625  0.074690  0.041795  \n",
      "TCGA-AA-3532-01  0.109990  0.043094  0.039499  \n",
      "\n",
      "[5 rows x 9228 columns]\n",
      "clinical_sample_data.parquet\n",
      "                   PATIENT_ID ONCOTREE_CODE                     CANCER_TYPE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01  TCGA-A5-A0GX           UEC              Endometrial Cancer   \n",
      "TCGA-AB-2815-03  TCGA-AB-2815           AML                        Leukemia   \n",
      "TCGA-VN-A943-01  TCGA-VN-A943          PRAD                 Prostate Cancer   \n",
      "TCGA-D7-6527-01  TCGA-D7-6527         PSTAD  Esophagogastric Adenocarcinoma   \n",
      "TCGA-AA-3532-01  TCGA-AA-3532          COAD               Colorectal Cancer   \n",
      "\n",
      "                             CANCER_TYPE_DETAILED  \\\n",
      "SAMPLE_ID                                           \n",
      "TCGA-A5-A0GX-01    Uterine Endometrioid Carcinoma   \n",
      "TCGA-AB-2815-03            Acute Myeloid Leukemia   \n",
      "TCGA-VN-A943-01           Prostate Adenocarcinoma   \n",
      "TCGA-D7-6527-01  Papillary Stomach Adenocarcinoma   \n",
      "TCGA-AA-3532-01              Colon Adenocarcinoma   \n",
      "\n",
      "                                                        TUMOR_TYPE    GRADE  \\\n",
      "SAMPLE_ID                                                                     \n",
      "TCGA-A5-A0GX-01            Endometrioid Endometrial Adenocarcinoma       G2   \n",
      "TCGA-AB-2815-03                             Acute Myeloid Leukemia  unknown   \n",
      "TCGA-VN-A943-01               Prostate Adenocarcinoma, Acinar Type  unknown   \n",
      "TCGA-D7-6527-01  Stomach Intestinal Adenocarcinoma, Papillary Type       G2   \n",
      "TCGA-AA-3532-01                               Colon Adenocarcinoma  unknown   \n",
      "\n",
      "                TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                 \n",
      "TCGA-A5-A0GX-01                                      No   \n",
      "TCGA-AB-2815-03                                 unknown   \n",
      "TCGA-VN-A943-01                                      No   \n",
      "TCGA-D7-6527-01                                     Yes   \n",
      "TCGA-AA-3532-01                                      No   \n",
      "\n",
      "                TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "SAMPLE_ID                                                   \n",
      "TCGA-A5-A0GX-01                                       Yes   \n",
      "TCGA-AB-2815-03                                   unknown   \n",
      "TCGA-VN-A943-01                                       Yes   \n",
      "TCGA-D7-6527-01                                        No   \n",
      "TCGA-AA-3532-01                                       Yes   \n",
      "\n",
      "                TISSUE_SOURCE_SITE_CODE TUMOR_TISSUE_SITE  ...  \\\n",
      "SAMPLE_ID                                                  ...   \n",
      "TCGA-A5-A0GX-01                      A5            Uterus  ...   \n",
      "TCGA-AB-2815-03                      AB           unknown  ...   \n",
      "TCGA-VN-A943-01                      VN          Prostate  ...   \n",
      "TCGA-D7-6527-01                      D7           Stomach  ...   \n",
      "TCGA-AA-3532-01                      AA             Colon  ...   \n",
      "\n",
      "                 IN_PANCANPATHWAYS_FREEZE   OS_STATUS  OS_MONTHS  \\\n",
      "SAMPLE_ID                                                          \n",
      "TCGA-A5-A0GX-01                       Yes    0:LIVING  68.645823   \n",
      "TCGA-AB-2815-03                       Yes  1:DECEASED  27.024361   \n",
      "TCGA-VN-A943-01                       Yes    0:LIVING  16.306671   \n",
      "TCGA-D7-6527-01                       Yes  1:DECEASED  10.257422   \n",
      "TCGA-AA-3532-01                        No    0:LIVING  28.996942   \n",
      "\n",
      "                                 DSS_STATUS DSS_MONTHS     DFS_STATUS  \\\n",
      "SAMPLE_ID                                                               \n",
      "TCGA-A5-A0GX-01  0:ALIVE OR DEAD TUMOR FREE  68.645823  0:DiseaseFree   \n",
      "TCGA-AB-2815-03                     unknown        NaN        unknown   \n",
      "TCGA-VN-A943-01  0:ALIVE OR DEAD TUMOR FREE  16.306671  0:DiseaseFree   \n",
      "TCGA-D7-6527-01           1:DEAD WITH TUMOR  10.257422        unknown   \n",
      "TCGA-AA-3532-01  0:ALIVE OR DEAD TUMOR FREE  28.996942        unknown   \n",
      "\n",
      "                DFS_MONTHS     PFS_STATUS PFS_MONTHS  \\\n",
      "SAMPLE_ID                                              \n",
      "TCGA-A5-A0GX-01  68.645823     0:CENSORED  68.645823   \n",
      "TCGA-AB-2815-03        NaN        unknown        NaN   \n",
      "TCGA-VN-A943-01  16.306671     0:CENSORED  16.306671   \n",
      "TCGA-D7-6527-01        NaN  1:PROGRESSION   2.465726   \n",
      "TCGA-AA-3532-01        NaN     0:CENSORED  28.996942   \n",
      "\n",
      "                AJCC_PATHOLOGIC_TUMOR_STAGE_SHORT  \n",
      "SAMPLE_ID                                          \n",
      "TCGA-A5-A0GX-01                           unknown  \n",
      "TCGA-AB-2815-03                           unknown  \n",
      "TCGA-VN-A943-01                           unknown  \n",
      "TCGA-D7-6527-01                          STAGE II  \n",
      "TCGA-AA-3532-01                          STAGE II  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "for d in dirs:\n",
    "    if d == \"bulk\":\n",
    "        bulk_files = os.listdir(os.path.join(\"data/raw/mini/\", d))\n",
    "        for f in bulk_files:\n",
    "            file_extension = f.split(\".\")[-1]\n",
    "            if file_extension == \"parquet\":\n",
    "                print(f)\n",
    "                df = pd.read_parquet(os.path.join(\"data/raw/mini/\", d, f))\n",
    "                print(df.head())\n",
    "            elif file_extension == \"csv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(os.path.join(\"data/raw/mini/\", d, f), index_col=0)\n",
    "                print(df.head())\n",
    "            elif file_extension == \"tsv\":\n",
    "                print(f)\n",
    "                df = pd.read_csv(\n",
    "                    os.path.join(\"data/raw/mini/\", d, f), sep=\"\\t\", index_col=0\n",
    "                )\n",
    "                print(df.head())\n",
    "            if f == \"clinical_sample_data.csv\":\n",
    "                indices = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
